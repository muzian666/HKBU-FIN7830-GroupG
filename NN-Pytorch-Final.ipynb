{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:48:41.540375Z",
     "start_time": "2023-11-01T05:48:41.251631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 49\u001B[0m\n\u001B[0;32m     47\u001B[0m model \u001B[38;5;241m=\u001B[39m EnhancedNN()\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel Summary:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 49\u001B[0m summary(model, input_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m34\u001B[39m))\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Initialize K-Fold cross-validation\u001B[39;00m\n\u001B[0;32m     52\u001B[0m skf \u001B[38;5;241m=\u001B[39m StratifiedKFold(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torchsummary\\torchsummary.py:72\u001B[0m, in \u001B[0;36msummary\u001B[1;34m(model, input_size, batch_size, device)\u001B[0m\n\u001B[0;32m     68\u001B[0m model\u001B[38;5;241m.\u001B[39mapply(register_hook)\n\u001B[0;32m     70\u001B[0m \u001B[38;5;66;03m# make a forward pass\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# print(x.shape)\u001B[39;00m\n\u001B[1;32m---> 72\u001B[0m model(\u001B[38;5;241m*\u001B[39mx)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# remove these hooks\u001B[39;00m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m h \u001B[38;5;129;01min\u001B[39;00m hooks:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[2], line 36\u001B[0m, in \u001B[0;36mEnhancedNN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 36\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(x))\n\u001B[0;32m     37\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout1(x)\n\u001B[0;32m     38\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(x))\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1568\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1565\u001B[0m     bw_hook \u001B[38;5;241m=\u001B[39m hooks\u001B[38;5;241m.\u001B[39mBackwardHook(\u001B[38;5;28mself\u001B[39m, full_backward_hooks, backward_pre_hooks)\n\u001B[0;32m   1566\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[1;32m-> 1568\u001B[0m result \u001B[38;5;241m=\u001B[39m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1569\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n\u001B[0;32m   1570\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook_id, hook \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[0;32m   1571\u001B[0m         \u001B[38;5;241m*\u001B[39m_global_forward_hooks\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[0;32m   1572\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[0;32m   1573\u001B[0m     ):\n\u001B[0;32m   1574\u001B[0m         \u001B[38;5;66;03m# mark that always called hook is run\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Resources/Data/Encoded_Resampled_HR_Analytics.csv')\n",
    "X = df.drop('Attrition', axis=1).values\n",
    "y = df['Attrition'].values\n",
    "\n",
    "# Data Preprocessing\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Define the Neural Network model with more layers\n",
    "class EnhancedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(34, 64)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "# Display model summary\n",
    "model = EnhancedNN()\n",
    "print(\"Model Summary:\")\n",
    "summary(model, input_size=(1, 34))\n",
    "\n",
    "# Initialize K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_accuracies, fold_f1s, fold_roc_aucs = [], [], []\n",
    "\n",
    "# To store training loss for visualization\n",
    "all_train_loss = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize the model, loss, and optimizer\n",
    "    model = EnhancedNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training the model\n",
    "    train_loss = []\n",
    "    for epoch in range(500):\n",
    "        for batch in train_loader:\n",
    "            X_batch, y_batch = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Add to overall training loss for visualization\n",
    "    all_train_loss.append(train_loss)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            X_batch, y_batch = batch\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            y_true.extend(y_batch.tolist())\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_f1s.append(f1)\n",
    "    fold_roc_aucs.append(roc_auc)\n",
    "\n",
    "# Average metrics over all folds\n",
    "print(f\"Average Accuracy: {np.mean(fold_accuracies)}, Average F1 Score: {np.mean(fold_f1s)}, Average ROC AUC: {np.mean(fold_roc_aucs)}\")\n",
    "\n",
    "# Visualize the training loss\n",
    "for i, train_loss in enumerate(all_train_loss):\n",
    "    plt.plot(train_loss, label=f\"Fold {i+1}\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss for Each Fold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]           2,240\n",
      "           Dropout-2                [-1, 1, 64]               0\n",
      "            Linear-3               [-1, 1, 128]           8,320\n",
      "           Dropout-4               [-1, 1, 128]               0\n",
      "            Linear-5               [-1, 1, 256]          33,024\n",
      "            Linear-6               [-1, 1, 128]          32,896\n",
      "            Linear-7                [-1, 1, 64]           8,256\n",
      "            Linear-8                [-1, 1, 32]           2,080\n",
      "            Linear-9                 [-1, 1, 2]              66\n",
      "================================================================\n",
      "Total params: 86,882\n",
      "Trainable params: 86,882\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 0.34\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, Loss: 0.5029380917549133\n",
      "Epoch 2, Loss: 0.4398672580718994\n",
      "Epoch 3, Loss: 0.6557711362838745\n",
      "Epoch 4, Loss: 0.6204776763916016\n",
      "Epoch 5, Loss: 0.4609614312648773\n",
      "Epoch 6, Loss: 0.35848572850227356\n",
      "Epoch 7, Loss: 0.580618143081665\n",
      "Epoch 8, Loss: 0.37537074089050293\n",
      "Epoch 9, Loss: 0.18120642006397247\n",
      "Epoch 10, Loss: 0.33413034677505493\n",
      "Epoch 11, Loss: 0.19389399886131287\n",
      "Epoch 12, Loss: 0.37692171335220337\n",
      "Epoch 13, Loss: 0.3205234408378601\n",
      "Epoch 14, Loss: 0.6144797205924988\n",
      "Epoch 15, Loss: 0.12852126359939575\n",
      "Epoch 16, Loss: 0.35209959745407104\n",
      "Epoch 17, Loss: 0.6318800449371338\n",
      "Epoch 18, Loss: 0.29691705107688904\n",
      "Epoch 19, Loss: 0.26589515805244446\n",
      "Epoch 20, Loss: 0.2684289515018463\n",
      "Epoch 21, Loss: 0.5775928497314453\n",
      "Epoch 22, Loss: 0.4431007504463196\n",
      "Epoch 23, Loss: 0.186888188123703\n",
      "Epoch 24, Loss: 0.544812798500061\n",
      "Epoch 25, Loss: 0.3628966808319092\n",
      "Epoch 26, Loss: 0.26326555013656616\n",
      "Epoch 27, Loss: 0.12611024081707\n",
      "Epoch 28, Loss: 0.3961165249347687\n",
      "Epoch 29, Loss: 0.3429185748100281\n",
      "Epoch 30, Loss: 0.23104552924633026\n",
      "Epoch 31, Loss: 0.16880780458450317\n",
      "Epoch 32, Loss: 0.2827177941799164\n",
      "Epoch 33, Loss: 0.24037404358386993\n",
      "Epoch 34, Loss: 0.11165925115346909\n",
      "Epoch 35, Loss: 0.4388735890388489\n",
      "Epoch 36, Loss: 0.16482524573802948\n",
      "Epoch 37, Loss: 0.34548860788345337\n",
      "Epoch 38, Loss: 0.36637353897094727\n",
      "Epoch 39, Loss: 0.3316534161567688\n",
      "Epoch 40, Loss: 0.2421524077653885\n",
      "Epoch 41, Loss: 0.10541055351495743\n",
      "Epoch 42, Loss: 0.07795189321041107\n",
      "Epoch 43, Loss: 0.3625405728816986\n",
      "Epoch 44, Loss: 0.27525222301483154\n",
      "Epoch 45, Loss: 0.21423272788524628\n",
      "Epoch 46, Loss: 0.216478630900383\n",
      "Epoch 47, Loss: 0.20987458527088165\n",
      "Epoch 48, Loss: 0.2235773354768753\n",
      "Epoch 49, Loss: 0.09189112484455109\n",
      "Epoch 50, Loss: 0.15202072262763977\n",
      "Epoch 51, Loss: 0.04446016997098923\n",
      "Epoch 52, Loss: 0.28854280710220337\n",
      "Epoch 53, Loss: 0.24355678260326385\n",
      "Epoch 54, Loss: 0.3709009289741516\n",
      "Epoch 55, Loss: 0.04702051728963852\n",
      "Epoch 56, Loss: 0.05056595802307129\n",
      "Epoch 57, Loss: 0.02004602923989296\n",
      "Epoch 58, Loss: 0.0726427435874939\n",
      "Epoch 59, Loss: 0.178873211145401\n",
      "Epoch 60, Loss: 0.03092617727816105\n",
      "Epoch 61, Loss: 0.05807385966181755\n",
      "Epoch 62, Loss: 0.14567941427230835\n",
      "Epoch 63, Loss: 0.3477092683315277\n",
      "Epoch 64, Loss: 0.21498875319957733\n",
      "Epoch 65, Loss: 0.2795075476169586\n",
      "Epoch 66, Loss: 0.07016295194625854\n",
      "Epoch 67, Loss: 0.04597734659910202\n",
      "Epoch 68, Loss: 0.31528666615486145\n",
      "Epoch 69, Loss: 0.12087863683700562\n",
      "Epoch 70, Loss: 0.07595722377300262\n",
      "Epoch 71, Loss: 0.07865436375141144\n",
      "Epoch 72, Loss: 0.18482086062431335\n",
      "Epoch 73, Loss: 0.11372504383325577\n",
      "Epoch 74, Loss: 0.08177599310874939\n",
      "Epoch 75, Loss: 0.45259571075439453\n",
      "Epoch 76, Loss: 0.11272357404232025\n",
      "Epoch 77, Loss: 0.1618397980928421\n",
      "Epoch 78, Loss: 0.12027209997177124\n",
      "Epoch 79, Loss: 0.07883209735155106\n",
      "Epoch 80, Loss: 0.2829788327217102\n",
      "Epoch 81, Loss: 0.44779330492019653\n",
      "Epoch 82, Loss: 0.13298678398132324\n",
      "Epoch 83, Loss: 0.21060355007648468\n",
      "Epoch 84, Loss: 0.20444849133491516\n",
      "Epoch 85, Loss: 0.09735386073589325\n",
      "Epoch 86, Loss: 0.10265780985355377\n",
      "Epoch 87, Loss: 0.2075343132019043\n",
      "Epoch 88, Loss: 0.26190075278282166\n",
      "Epoch 89, Loss: 0.15949568152427673\n",
      "Epoch 90, Loss: 0.10432268679141998\n",
      "Epoch 91, Loss: 0.2320728302001953\n",
      "Epoch 92, Loss: 0.13330583274364471\n",
      "Epoch 93, Loss: 0.25985127687454224\n",
      "Epoch 94, Loss: 0.12497682869434357\n",
      "Epoch 95, Loss: 0.10141108185052872\n",
      "Epoch 96, Loss: 0.052598435431718826\n",
      "Epoch 97, Loss: 0.15017448365688324\n",
      "Epoch 98, Loss: 0.07719878107309341\n",
      "Epoch 99, Loss: 0.12841644883155823\n",
      "Epoch 100, Loss: 0.005021066404879093\n",
      "Epoch 101, Loss: 0.04120969399809837\n",
      "Epoch 102, Loss: 0.08957698196172714\n",
      "Epoch 103, Loss: 0.08303575962781906\n",
      "Epoch 104, Loss: 0.04670922830700874\n",
      "Epoch 105, Loss: 0.23725822567939758\n",
      "Epoch 106, Loss: 0.34743231534957886\n",
      "Epoch 107, Loss: 0.20502381026744843\n",
      "Epoch 108, Loss: 0.11607597023248672\n",
      "Epoch 109, Loss: 0.20316609740257263\n",
      "Epoch 110, Loss: 0.010574562475085258\n",
      "Epoch 111, Loss: 0.2605000436306\n",
      "Epoch 112, Loss: 0.03831320255994797\n",
      "Epoch 113, Loss: 0.11718392372131348\n",
      "Epoch 114, Loss: 0.06689409911632538\n",
      "Epoch 115, Loss: 0.17193162441253662\n",
      "Epoch 116, Loss: 0.23692984879016876\n",
      "Epoch 117, Loss: 0.053723763674497604\n",
      "Epoch 118, Loss: 0.11035163700580597\n",
      "Epoch 119, Loss: 0.1351243257522583\n",
      "Epoch 120, Loss: 0.14742901921272278\n",
      "Epoch 121, Loss: 0.19638662040233612\n",
      "Epoch 122, Loss: 0.011396655812859535\n",
      "Epoch 123, Loss: 0.0713919848203659\n",
      "Epoch 124, Loss: 0.030869167298078537\n",
      "Epoch 125, Loss: 0.37568455934524536\n",
      "Epoch 126, Loss: 0.08669771999120712\n",
      "Epoch 127, Loss: 0.09037744253873825\n",
      "Epoch 128, Loss: 0.17488941550254822\n",
      "Epoch 129, Loss: 0.05816482752561569\n",
      "Epoch 130, Loss: 0.13274718821048737\n",
      "Epoch 131, Loss: 0.14389485120773315\n",
      "Epoch 132, Loss: 0.1977573037147522\n",
      "Epoch 133, Loss: 0.37039294838905334\n",
      "Epoch 134, Loss: 0.054609108716249466\n",
      "Epoch 135, Loss: 0.3662465214729309\n",
      "Epoch 136, Loss: 0.029645513743162155\n",
      "Epoch 137, Loss: 0.1556112915277481\n",
      "Epoch 138, Loss: 0.07167120277881622\n",
      "Epoch 139, Loss: 0.04299499839544296\n",
      "Epoch 140, Loss: 0.06780019402503967\n",
      "Epoch 141, Loss: 0.03713181987404823\n",
      "Epoch 142, Loss: 0.08627664297819138\n",
      "Epoch 143, Loss: 0.15316924452781677\n",
      "Epoch 144, Loss: 0.015789564698934555\n",
      "Epoch 145, Loss: 0.08584772050380707\n",
      "Epoch 146, Loss: 0.09240216761827469\n",
      "Epoch 147, Loss: 0.0978422611951828\n",
      "Epoch 148, Loss: 0.36665457487106323\n",
      "Epoch 149, Loss: 0.013809548690915108\n",
      "Epoch 150, Loss: 0.1283390074968338\n",
      "Epoch 151, Loss: 0.22555384039878845\n",
      "Epoch 152, Loss: 0.0932668074965477\n",
      "Epoch 153, Loss: 0.03606811910867691\n",
      "Epoch 154, Loss: 0.1232912689447403\n",
      "Epoch 155, Loss: 0.10957815498113632\n",
      "Epoch 156, Loss: 0.17527416348457336\n",
      "Epoch 157, Loss: 0.21049699187278748\n",
      "Epoch 158, Loss: 0.05989112704992294\n",
      "Epoch 159, Loss: 0.0719471424818039\n",
      "Epoch 160, Loss: 0.01491501647979021\n",
      "Epoch 161, Loss: 0.20818865299224854\n",
      "Epoch 162, Loss: 0.2213500291109085\n",
      "Epoch 163, Loss: 0.030148416757583618\n",
      "Epoch 164, Loss: 0.01426437683403492\n",
      "Epoch 165, Loss: 0.07538808137178421\n",
      "Epoch 166, Loss: 0.036614157259464264\n",
      "Epoch 167, Loss: 0.07973890751600266\n",
      "Epoch 168, Loss: 0.20040781795978546\n",
      "Epoch 169, Loss: 0.11794004589319229\n",
      "Epoch 170, Loss: 0.12698835134506226\n",
      "Epoch 171, Loss: 0.2710229456424713\n",
      "Epoch 172, Loss: 0.1541915237903595\n",
      "Epoch 173, Loss: 0.07663298398256302\n",
      "Epoch 174, Loss: 0.04129885882139206\n",
      "Epoch 175, Loss: 0.3152060806751251\n",
      "Epoch 176, Loss: 0.1564968079328537\n",
      "Epoch 177, Loss: 0.06543862074613571\n",
      "Epoch 178, Loss: 0.01744754984974861\n",
      "Epoch 179, Loss: 0.28383803367614746\n",
      "Epoch 180, Loss: 0.0759255662560463\n",
      "Epoch 181, Loss: 0.15216104686260223\n",
      "Epoch 182, Loss: 0.18087686598300934\n",
      "Epoch 183, Loss: 0.08362136781215668\n",
      "Epoch 184, Loss: 0.015323539264500141\n",
      "Epoch 185, Loss: 0.008314445614814758\n",
      "Epoch 186, Loss: 0.07010253518819809\n",
      "Epoch 187, Loss: 0.04839272424578667\n",
      "Epoch 188, Loss: 0.15371406078338623\n",
      "Epoch 189, Loss: 0.07091961055994034\n",
      "Epoch 190, Loss: 0.18532975018024445\n",
      "Epoch 191, Loss: 0.023414066061377525\n",
      "Epoch 192, Loss: 0.02412371151149273\n",
      "Epoch 193, Loss: 0.04702712595462799\n",
      "Epoch 194, Loss: 0.0960036963224411\n",
      "Epoch 195, Loss: 0.0344083197414875\n",
      "Epoch 196, Loss: 0.04521366208791733\n",
      "Epoch 197, Loss: 0.18371674418449402\n",
      "Epoch 198, Loss: 0.1950748711824417\n",
      "Epoch 199, Loss: 0.14829705655574799\n",
      "Epoch 200, Loss: 0.03296381235122681\n",
      "Epoch 201, Loss: 0.0796051174402237\n",
      "Epoch 202, Loss: 0.09038716554641724\n",
      "Epoch 203, Loss: 0.16450951993465424\n",
      "Epoch 204, Loss: 0.3516920804977417\n",
      "Epoch 205, Loss: 0.10844199359416962\n",
      "Epoch 206, Loss: 0.05130962282419205\n",
      "Epoch 207, Loss: 0.04893336817622185\n",
      "Epoch 208, Loss: 0.02100253477692604\n",
      "Epoch 209, Loss: 0.2753443121910095\n",
      "Epoch 210, Loss: 0.05685565993189812\n",
      "Epoch 211, Loss: 0.011089315637946129\n",
      "Epoch 212, Loss: 0.026841413229703903\n",
      "Epoch 213, Loss: 0.14815101027488708\n",
      "Epoch 214, Loss: 0.06329292804002762\n",
      "Epoch 215, Loss: 0.07528712600469589\n",
      "Epoch 216, Loss: 0.0948287695646286\n",
      "Epoch 217, Loss: 0.3137405812740326\n",
      "Epoch 218, Loss: 0.11055558919906616\n",
      "Epoch 219, Loss: 0.3177173137664795\n",
      "Epoch 220, Loss: 0.08416424691677094\n",
      "Epoch 221, Loss: 0.04670228436589241\n",
      "Epoch 222, Loss: 0.15602262318134308\n",
      "Epoch 223, Loss: 0.09527938067913055\n",
      "Epoch 224, Loss: 0.018255287781357765\n",
      "Epoch 225, Loss: 0.3148624002933502\n",
      "Epoch 226, Loss: 0.006740041077136993\n",
      "Epoch 227, Loss: 0.22831015288829803\n",
      "Epoch 228, Loss: 0.08537854254245758\n",
      "Epoch 229, Loss: 0.1643402874469757\n",
      "Epoch 230, Loss: 0.1115681529045105\n",
      "Epoch 231, Loss: 0.13650044798851013\n",
      "Epoch 232, Loss: 0.015538373962044716\n",
      "Epoch 233, Loss: 0.23742055892944336\n",
      "Epoch 234, Loss: 0.25891217589378357\n",
      "Epoch 235, Loss: 0.11989106982946396\n",
      "Epoch 236, Loss: 0.04203333333134651\n",
      "Epoch 237, Loss: 0.11239238828420639\n",
      "Epoch 238, Loss: 0.07479553669691086\n",
      "Epoch 239, Loss: 0.02434585988521576\n",
      "Epoch 240, Loss: 0.23803181946277618\n",
      "Epoch 241, Loss: 0.04813080281019211\n",
      "Epoch 242, Loss: 0.06353867799043655\n",
      "Epoch 243, Loss: 0.029842469841241837\n",
      "Epoch 244, Loss: 0.0621066614985466\n",
      "Epoch 245, Loss: 0.05443640798330307\n",
      "Epoch 246, Loss: 0.15449084341526031\n",
      "Epoch 247, Loss: 0.1999727040529251\n",
      "Epoch 248, Loss: 0.18082785606384277\n",
      "Epoch 249, Loss: 0.045961715281009674\n",
      "Epoch 250, Loss: 0.011796470731496811\n",
      "Epoch 251, Loss: 0.03181526064872742\n",
      "Epoch 252, Loss: 0.028387567028403282\n",
      "Epoch 253, Loss: 0.10434530675411224\n",
      "Epoch 254, Loss: 0.2327914535999298\n",
      "Epoch 255, Loss: 0.014903183095157146\n",
      "Epoch 256, Loss: 0.08592554926872253\n",
      "Epoch 257, Loss: 0.08392034471035004\n",
      "Epoch 258, Loss: 0.1339026689529419\n",
      "Epoch 259, Loss: 0.010566603392362595\n",
      "Epoch 260, Loss: 0.0923033207654953\n",
      "Epoch 261, Loss: 0.05097276717424393\n",
      "Epoch 262, Loss: 0.0718727558851242\n",
      "Epoch 263, Loss: 0.15022997558116913\n",
      "Epoch 264, Loss: 0.05114838480949402\n",
      "Epoch 265, Loss: 0.02272927761077881\n",
      "Epoch 266, Loss: 0.008143054321408272\n",
      "Epoch 267, Loss: 0.027425521984696388\n",
      "Epoch 268, Loss: 0.15097185969352722\n",
      "Epoch 269, Loss: 0.04803530499339104\n",
      "Epoch 270, Loss: 0.02848942019045353\n",
      "Epoch 271, Loss: 0.012253997847437859\n",
      "Epoch 272, Loss: 0.022198325023055077\n",
      "Epoch 273, Loss: 0.06335176527500153\n",
      "Epoch 274, Loss: 0.09204535186290741\n",
      "Epoch 275, Loss: 0.05645665526390076\n",
      "Epoch 276, Loss: 0.23982462286949158\n",
      "Epoch 277, Loss: 0.13515308499336243\n",
      "Epoch 278, Loss: 0.024687938392162323\n",
      "Epoch 279, Loss: 0.02568451501429081\n",
      "Epoch 280, Loss: 0.043618448078632355\n",
      "Epoch 281, Loss: 0.006419462151825428\n",
      "Epoch 282, Loss: 0.006935189012438059\n",
      "Epoch 283, Loss: 0.030749265104532242\n",
      "Epoch 284, Loss: 0.03005209192633629\n",
      "Epoch 285, Loss: 0.17073751986026764\n",
      "Epoch 286, Loss: 0.03361516445875168\n",
      "Epoch 287, Loss: 0.14415936172008514\n",
      "Epoch 288, Loss: 0.036598023027181625\n",
      "Epoch 289, Loss: 0.006524176336824894\n",
      "Epoch 290, Loss: 0.17931470274925232\n",
      "Epoch 291, Loss: 0.017195237800478935\n",
      "Epoch 292, Loss: 0.07353837788105011\n",
      "Epoch 293, Loss: 0.013182039372622967\n",
      "Epoch 294, Loss: 0.03744693100452423\n",
      "Epoch 295, Loss: 0.05586453527212143\n",
      "Epoch 296, Loss: 0.029427459463477135\n",
      "Epoch 297, Loss: 0.027746135368943214\n",
      "Epoch 298, Loss: 0.06151096895337105\n",
      "Epoch 299, Loss: 0.02526606060564518\n",
      "Epoch 300, Loss: 0.10638781636953354\n",
      "Epoch 301, Loss: 0.08300522714853287\n",
      "Epoch 302, Loss: 0.2581893801689148\n",
      "Epoch 303, Loss: 0.053282249718904495\n",
      "Epoch 304, Loss: 0.053890328854322433\n",
      "Epoch 305, Loss: 0.035663727670907974\n",
      "Epoch 306, Loss: 0.010144151747226715\n",
      "Epoch 307, Loss: 0.0074760825373232365\n",
      "Epoch 308, Loss: 0.15961773693561554\n",
      "Epoch 309, Loss: 0.03899296373128891\n",
      "Epoch 310, Loss: 0.0394124761223793\n",
      "Epoch 311, Loss: 0.01690315455198288\n",
      "Epoch 312, Loss: 0.1423914134502411\n",
      "Epoch 313, Loss: 0.04045044258236885\n",
      "Epoch 314, Loss: 0.013691313564777374\n",
      "Epoch 315, Loss: 0.0073362356051802635\n",
      "Epoch 316, Loss: 0.05775582790374756\n",
      "Epoch 317, Loss: 0.03276965394616127\n",
      "Epoch 318, Loss: 0.0050051333382725716\n",
      "Epoch 319, Loss: 0.33423689007759094\n",
      "Epoch 320, Loss: 0.23908109962940216\n",
      "Epoch 321, Loss: 0.11644110828638077\n",
      "Epoch 322, Loss: 0.0892903134226799\n",
      "Epoch 323, Loss: 0.025613674893975258\n",
      "Epoch 324, Loss: 0.012419209815561771\n",
      "Epoch 325, Loss: 0.03254836052656174\n",
      "Epoch 326, Loss: 0.030291814357042313\n",
      "Epoch 327, Loss: 0.004725518170744181\n",
      "Epoch 328, Loss: 0.042540229856967926\n",
      "Epoch 329, Loss: 0.11230502277612686\n",
      "Epoch 330, Loss: 0.08473683893680573\n",
      "Epoch 331, Loss: 0.2417842596769333\n",
      "Epoch 332, Loss: 0.024918800219893456\n",
      "Epoch 333, Loss: 0.027381906285881996\n",
      "Epoch 334, Loss: 0.0067431190982460976\n",
      "Epoch 335, Loss: 0.2031784951686859\n",
      "Epoch 336, Loss: 0.18197432160377502\n",
      "Epoch 337, Loss: 0.02462102100253105\n",
      "Epoch 338, Loss: 0.14152821898460388\n",
      "Epoch 339, Loss: 0.015245470218360424\n",
      "Epoch 340, Loss: 0.09328503906726837\n",
      "Epoch 341, Loss: 0.09030400216579437\n",
      "Epoch 342, Loss: 0.017206331714987755\n",
      "Epoch 343, Loss: 0.16116110980510712\n",
      "Epoch 344, Loss: 0.13178057968616486\n",
      "Epoch 345, Loss: 0.09771634638309479\n",
      "Epoch 346, Loss: 0.14315351843833923\n",
      "Epoch 347, Loss: 0.04346608370542526\n",
      "Epoch 348, Loss: 0.3285577595233917\n",
      "Epoch 349, Loss: 0.18327990174293518\n",
      "Epoch 350, Loss: 0.18491777777671814\n",
      "Epoch 351, Loss: 0.016775287687778473\n",
      "Epoch 352, Loss: 0.03101223148405552\n",
      "Epoch 353, Loss: 0.09005622565746307\n",
      "Epoch 354, Loss: 0.015445591881871223\n",
      "Epoch 355, Loss: 0.08497820049524307\n",
      "Epoch 356, Loss: 0.04774872958660126\n",
      "Epoch 357, Loss: 0.01412502396851778\n",
      "Epoch 358, Loss: 0.25084152817726135\n",
      "Epoch 359, Loss: 0.4182720184326172\n",
      "Epoch 360, Loss: 0.254524827003479\n",
      "Epoch 361, Loss: 0.05887381359934807\n",
      "Epoch 362, Loss: 0.19150760769844055\n",
      "Epoch 363, Loss: 0.011662876233458519\n",
      "Epoch 364, Loss: 0.1861073076725006\n",
      "Epoch 365, Loss: 0.04340314865112305\n",
      "Epoch 366, Loss: 0.02120821550488472\n",
      "Epoch 367, Loss: 0.0774257555603981\n",
      "Epoch 368, Loss: 0.00553672481328249\n",
      "Epoch 369, Loss: 0.15271034836769104\n",
      "Epoch 370, Loss: 0.06250341236591339\n",
      "Epoch 371, Loss: 0.015757983550429344\n",
      "Epoch 372, Loss: 0.06303035467863083\n",
      "Epoch 373, Loss: 0.16557393968105316\n",
      "Epoch 374, Loss: 0.1149974912405014\n",
      "Epoch 375, Loss: 0.017314402386546135\n",
      "Epoch 376, Loss: 0.17794835567474365\n",
      "Epoch 377, Loss: 0.006252489052712917\n",
      "Epoch 378, Loss: 0.053870320320129395\n",
      "Epoch 379, Loss: 0.029765883460640907\n",
      "Epoch 380, Loss: 0.00837976299226284\n",
      "Epoch 381, Loss: 0.017834318801760674\n",
      "Epoch 382, Loss: 0.020940814167261124\n",
      "Epoch 383, Loss: 0.06876422464847565\n",
      "Epoch 384, Loss: 0.23752811551094055\n",
      "Epoch 385, Loss: 0.020560411736369133\n",
      "Epoch 386, Loss: 0.2570840120315552\n",
      "Epoch 387, Loss: 0.04496637359261513\n",
      "Epoch 388, Loss: 0.00809528399258852\n",
      "Epoch 389, Loss: 0.16238127648830414\n",
      "Epoch 390, Loss: 0.17482374608516693\n",
      "Epoch 391, Loss: 0.01153846736997366\n",
      "Epoch 392, Loss: 0.020674586296081543\n",
      "Epoch 393, Loss: 0.04421710968017578\n",
      "Epoch 394, Loss: 0.018623877316713333\n",
      "Epoch 395, Loss: 0.032009705901145935\n",
      "Epoch 396, Loss: 0.012156021781265736\n",
      "Epoch 397, Loss: 0.16913992166519165\n",
      "Epoch 398, Loss: 0.027640830725431442\n",
      "Epoch 399, Loss: 0.008638476952910423\n",
      "Epoch 400, Loss: 0.005402803421020508\n",
      "Epoch 401, Loss: 0.0649077445268631\n",
      "Epoch 402, Loss: 0.16942501068115234\n",
      "Epoch 403, Loss: 0.010418565943837166\n",
      "Epoch 404, Loss: 0.08293724805116653\n",
      "Epoch 405, Loss: 0.13188163936138153\n",
      "Epoch 406, Loss: 0.13894636929035187\n",
      "Epoch 407, Loss: 0.050079066306352615\n",
      "Epoch 408, Loss: 0.0808018371462822\n",
      "Epoch 409, Loss: 0.18408869206905365\n",
      "Epoch 410, Loss: 0.03229598328471184\n",
      "Epoch 411, Loss: 0.17918714880943298\n",
      "Epoch 412, Loss: 0.017379337921738625\n",
      "Epoch 413, Loss: 0.021911537274718285\n",
      "Epoch 414, Loss: 0.02551168203353882\n",
      "Epoch 415, Loss: 0.030781885609030724\n",
      "Epoch 416, Loss: 0.04697877913713455\n",
      "Epoch 417, Loss: 0.014477664604783058\n",
      "Epoch 418, Loss: 0.013642502017319202\n",
      "Epoch 419, Loss: 0.0251653790473938\n",
      "Epoch 420, Loss: 0.005923242773860693\n",
      "Epoch 421, Loss: 0.07965867221355438\n",
      "Epoch 422, Loss: 0.01905454322695732\n",
      "Epoch 423, Loss: 0.032939642667770386\n",
      "Epoch 424, Loss: 0.12209321558475494\n",
      "Epoch 425, Loss: 0.11639612913131714\n",
      "Epoch 426, Loss: 0.1700706034898758\n",
      "Epoch 427, Loss: 0.03352956101298332\n",
      "Epoch 428, Loss: 0.0453081950545311\n",
      "Epoch 429, Loss: 0.004726889077574015\n",
      "Epoch 430, Loss: 0.04937291517853737\n",
      "Epoch 431, Loss: 0.038086287677288055\n",
      "Epoch 432, Loss: 0.011210495606064796\n",
      "Epoch 433, Loss: 0.166794553399086\n",
      "Epoch 434, Loss: 0.07278353720903397\n",
      "Epoch 435, Loss: 0.02112322673201561\n",
      "Epoch 436, Loss: 0.025498682633042336\n",
      "Epoch 437, Loss: 0.035427141934633255\n",
      "Epoch 438, Loss: 0.07839460670948029\n",
      "Epoch 439, Loss: 0.01177173387259245\n",
      "Epoch 440, Loss: 0.04763518646359444\n",
      "Epoch 441, Loss: 0.006671098526567221\n",
      "Epoch 442, Loss: 0.05275709554553032\n",
      "Epoch 443, Loss: 0.12683580815792084\n",
      "Epoch 444, Loss: 0.029217112809419632\n",
      "Epoch 445, Loss: 0.07481981068849564\n",
      "Epoch 446, Loss: 0.18719837069511414\n",
      "Epoch 447, Loss: 0.09305165708065033\n",
      "Epoch 448, Loss: 0.011235442012548447\n",
      "Epoch 449, Loss: 0.3242684304714203\n",
      "Epoch 450, Loss: 0.0015156952431425452\n",
      "Epoch 451, Loss: 0.003813625779002905\n",
      "Epoch 452, Loss: 0.03633887693285942\n",
      "Epoch 453, Loss: 0.002383022801950574\n",
      "Epoch 454, Loss: 0.02391759119927883\n",
      "Epoch 455, Loss: 0.040169090032577515\n",
      "Epoch 456, Loss: 0.025589868426322937\n",
      "Epoch 457, Loss: 0.02446156181395054\n",
      "Epoch 458, Loss: 0.12849044799804688\n",
      "Epoch 459, Loss: 0.1570962816476822\n",
      "Epoch 460, Loss: 0.1566285789012909\n",
      "Epoch 461, Loss: 0.034681614488363266\n",
      "Epoch 462, Loss: 0.30271849036216736\n",
      "Epoch 463, Loss: 0.014200541190803051\n",
      "Epoch 464, Loss: 0.007360734045505524\n",
      "Epoch 465, Loss: 0.02306382916867733\n",
      "Epoch 466, Loss: 0.023187529295682907\n",
      "Epoch 467, Loss: 0.02145988494157791\n",
      "Epoch 468, Loss: 0.09642714262008667\n",
      "Epoch 469, Loss: 0.006408512592315674\n",
      "Epoch 470, Loss: 0.006560037843883038\n",
      "Epoch 471, Loss: 0.10411979258060455\n",
      "Epoch 472, Loss: 0.17694666981697083\n",
      "Epoch 473, Loss: 0.013357734307646751\n",
      "Epoch 474, Loss: 0.09463156759738922\n",
      "Epoch 475, Loss: 0.05148293450474739\n",
      "Epoch 476, Loss: 0.12420866638422012\n",
      "Epoch 477, Loss: 0.01745799370110035\n",
      "Epoch 478, Loss: 0.021210558712482452\n",
      "Epoch 479, Loss: 0.030176615342497826\n",
      "Epoch 480, Loss: 0.01392454095184803\n",
      "Epoch 481, Loss: 0.013886911794543266\n",
      "Epoch 482, Loss: 0.1109502762556076\n",
      "Epoch 483, Loss: 0.028711622580885887\n",
      "Epoch 484, Loss: 0.012690586969256401\n",
      "Epoch 485, Loss: 0.05675450712442398\n",
      "Epoch 486, Loss: 0.25646111369132996\n",
      "Epoch 487, Loss: 0.2035326510667801\n",
      "Epoch 488, Loss: 0.05103711411356926\n",
      "Epoch 489, Loss: 0.01746033877134323\n",
      "Epoch 490, Loss: 0.004155898001044989\n",
      "Epoch 491, Loss: 0.15356072783470154\n",
      "Epoch 492, Loss: 0.01437741331756115\n",
      "Epoch 493, Loss: 0.305480033159256\n",
      "Epoch 494, Loss: 0.022634124383330345\n",
      "Epoch 495, Loss: 0.05242316052317619\n",
      "Epoch 496, Loss: 0.01250402070581913\n",
      "Epoch 497, Loss: 0.00943642295897007\n",
      "Epoch 498, Loss: 0.011395489796996117\n",
      "Epoch 499, Loss: 0.033773086965084076\n",
      "Epoch 500, Loss: 0.02289336547255516\n",
      "Epoch 501, Loss: 0.03713533282279968\n",
      "Epoch 502, Loss: 0.030214305967092514\n",
      "Epoch 503, Loss: 0.05596427246928215\n",
      "Epoch 504, Loss: 0.18141600489616394\n",
      "Epoch 505, Loss: 0.0349624827504158\n",
      "Epoch 506, Loss: 0.08076685667037964\n",
      "Epoch 507, Loss: 0.0536351278424263\n",
      "Epoch 508, Loss: 0.03586098924279213\n",
      "Epoch 509, Loss: 0.024198953062295914\n",
      "Epoch 510, Loss: 0.00700831413269043\n",
      "Epoch 511, Loss: 0.02003733068704605\n",
      "Epoch 512, Loss: 0.008737265132367611\n",
      "Epoch 513, Loss: 0.06443215906620026\n",
      "Epoch 514, Loss: 0.13674023747444153\n",
      "Epoch 515, Loss: 0.09001357853412628\n",
      "Epoch 516, Loss: 0.06480808556079865\n",
      "Epoch 517, Loss: 0.24251151084899902\n",
      "Epoch 518, Loss: 0.21693149209022522\n",
      "Epoch 519, Loss: 0.014680666849017143\n",
      "Epoch 520, Loss: 0.02141730673611164\n",
      "Epoch 521, Loss: 0.008079072460532188\n",
      "Epoch 522, Loss: 0.06483326852321625\n",
      "Epoch 523, Loss: 0.010855177417397499\n",
      "Epoch 524, Loss: 0.11485765129327774\n",
      "Epoch 525, Loss: 0.009399976581335068\n",
      "Epoch 526, Loss: 0.020136265084147453\n",
      "Epoch 527, Loss: 0.024582864716649055\n",
      "Epoch 528, Loss: 0.012527924962341785\n",
      "Epoch 529, Loss: 0.054147519171237946\n",
      "Epoch 530, Loss: 0.00828828476369381\n",
      "Epoch 531, Loss: 0.12190181016921997\n",
      "Epoch 532, Loss: 0.01289583183825016\n",
      "Epoch 533, Loss: 0.03939563035964966\n",
      "Epoch 534, Loss: 0.022641461342573166\n",
      "Epoch 535, Loss: 0.008548032492399216\n",
      "Epoch 536, Loss: 0.005595927592366934\n",
      "Epoch 537, Loss: 0.083645761013031\n",
      "Epoch 538, Loss: 0.02388288639485836\n",
      "Epoch 539, Loss: 0.016651878133416176\n",
      "Epoch 540, Loss: 0.03133869916200638\n",
      "Epoch 541, Loss: 0.0982413962483406\n",
      "Epoch 542, Loss: 0.12053068727254868\n",
      "Epoch 543, Loss: 0.0576915368437767\n",
      "Epoch 544, Loss: 0.013087545521557331\n",
      "Epoch 545, Loss: 0.11024951934814453\n",
      "Epoch 546, Loss: 0.0018414994701743126\n",
      "Epoch 547, Loss: 0.02360021136701107\n",
      "Epoch 548, Loss: 0.00661205779761076\n",
      "Epoch 549, Loss: 0.019052185118198395\n",
      "Epoch 550, Loss: 0.027445698156952858\n",
      "Epoch 551, Loss: 0.016458194702863693\n",
      "Epoch 552, Loss: 0.002407263731583953\n",
      "Epoch 553, Loss: 0.0034729347098618746\n",
      "Epoch 554, Loss: 0.08800160139799118\n",
      "Epoch 555, Loss: 0.05747683718800545\n",
      "Epoch 556, Loss: 0.08696621656417847\n",
      "Epoch 557, Loss: 0.020826861262321472\n",
      "Epoch 558, Loss: 0.05748320370912552\n",
      "Epoch 559, Loss: 0.014980445615947247\n",
      "Epoch 560, Loss: 0.2139466106891632\n",
      "Epoch 561, Loss: 0.11143946647644043\n",
      "Epoch 562, Loss: 0.04181339591741562\n",
      "Epoch 563, Loss: 0.01816347986459732\n",
      "Epoch 564, Loss: 0.05678170174360275\n",
      "Epoch 565, Loss: 0.22341661155223846\n",
      "Epoch 566, Loss: 0.03990434110164642\n",
      "Epoch 567, Loss: 0.09666687250137329\n",
      "Epoch 568, Loss: 0.0022023555357009172\n",
      "Epoch 569, Loss: 0.013517106883227825\n",
      "Epoch 570, Loss: 0.12065015733242035\n",
      "Epoch 571, Loss: 0.11962591111660004\n",
      "Epoch 572, Loss: 0.07593613862991333\n",
      "Epoch 573, Loss: 0.03865621238946915\n",
      "Epoch 574, Loss: 0.0035902056843042374\n",
      "Epoch 575, Loss: 0.014723392203450203\n",
      "Epoch 576, Loss: 0.03960449993610382\n",
      "Epoch 577, Loss: 0.02619646117091179\n",
      "Epoch 578, Loss: 0.007448617368936539\n",
      "Epoch 579, Loss: 0.09729397296905518\n",
      "Epoch 580, Loss: 0.022731328383088112\n",
      "Epoch 581, Loss: 0.029918890446424484\n",
      "Epoch 582, Loss: 0.030938465148210526\n",
      "Epoch 583, Loss: 0.16069723665714264\n",
      "Epoch 584, Loss: 0.014693386852741241\n",
      "Epoch 585, Loss: 0.01254785805940628\n",
      "Epoch 586, Loss: 0.010124879889190197\n",
      "Epoch 587, Loss: 0.13881847262382507\n",
      "Epoch 588, Loss: 0.3659251928329468\n",
      "Epoch 589, Loss: 0.20116202533245087\n",
      "Epoch 590, Loss: 0.014076048508286476\n",
      "Epoch 591, Loss: 0.024172991514205933\n",
      "Epoch 592, Loss: 0.036938875913619995\n",
      "Epoch 593, Loss: 0.012616842985153198\n",
      "Epoch 594, Loss: 0.04350544512271881\n",
      "Epoch 595, Loss: 0.055192094296216965\n",
      "Epoch 596, Loss: 0.07475994527339935\n",
      "Epoch 597, Loss: 0.004580698441714048\n",
      "Epoch 598, Loss: 0.0022469053510576487\n",
      "Epoch 599, Loss: 0.040605224668979645\n",
      "Epoch 600, Loss: 0.00962094496935606\n",
      "Epoch 601, Loss: 0.019286902621388435\n",
      "Epoch 602, Loss: 0.013728094287216663\n",
      "Epoch 603, Loss: 0.021496903151273727\n",
      "Epoch 604, Loss: 0.09423800557851791\n",
      "Epoch 605, Loss: 0.020726341754198074\n",
      "Epoch 606, Loss: 0.19818073511123657\n",
      "Epoch 607, Loss: 0.02335597202181816\n",
      "Epoch 608, Loss: 0.00559497345238924\n",
      "Epoch 609, Loss: 0.08391901850700378\n",
      "Epoch 610, Loss: 0.05255373567342758\n",
      "Epoch 611, Loss: 0.04008527472615242\n",
      "Epoch 612, Loss: 0.07296474277973175\n",
      "Epoch 613, Loss: 0.16413794457912445\n",
      "Epoch 614, Loss: 0.06096283346414566\n",
      "Epoch 615, Loss: 0.049014925956726074\n",
      "Epoch 616, Loss: 0.016693618148565292\n",
      "Epoch 617, Loss: 0.09217454493045807\n",
      "Epoch 618, Loss: 0.014240654185414314\n",
      "Epoch 619, Loss: 0.013844652101397514\n",
      "Epoch 620, Loss: 0.05174599215388298\n",
      "Epoch 621, Loss: 0.02846395969390869\n",
      "Epoch 622, Loss: 0.10048868507146835\n",
      "Epoch 623, Loss: 0.007319950498640537\n",
      "Epoch 624, Loss: 0.015790488570928574\n",
      "Epoch 625, Loss: 0.044440921396017075\n",
      "Epoch 626, Loss: 0.1663673222064972\n",
      "Epoch 627, Loss: 0.17289313673973083\n",
      "Epoch 628, Loss: 0.03772377967834473\n",
      "Epoch 629, Loss: 0.15885701775550842\n",
      "Epoch 630, Loss: 0.2702972888946533\n",
      "Epoch 631, Loss: 0.035204920917749405\n",
      "Epoch 632, Loss: 0.005119393114000559\n",
      "Epoch 633, Loss: 0.005004893988370895\n",
      "Epoch 634, Loss: 0.05825056508183479\n",
      "Epoch 635, Loss: 0.01465102843940258\n",
      "Epoch 636, Loss: 0.0063213324174284935\n",
      "Epoch 637, Loss: 0.08242843300104141\n",
      "Epoch 638, Loss: 0.025829385966062546\n",
      "Epoch 639, Loss: 0.00928969494998455\n",
      "Epoch 640, Loss: 0.05006946250796318\n",
      "Epoch 641, Loss: 0.10750313103199005\n",
      "Epoch 642, Loss: 0.016271324828267097\n",
      "Epoch 643, Loss: 0.03973400220274925\n",
      "Epoch 644, Loss: 0.037655625492334366\n",
      "Epoch 645, Loss: 0.09553573280572891\n",
      "Epoch 646, Loss: 0.006936403922736645\n",
      "Epoch 647, Loss: 0.09617842733860016\n",
      "Epoch 648, Loss: 0.008499362505972385\n",
      "Epoch 649, Loss: 0.009271292015910149\n",
      "Epoch 650, Loss: 0.04573281854391098\n",
      "Epoch 651, Loss: 0.0702696368098259\n",
      "Epoch 652, Loss: 0.03772077336907387\n",
      "Epoch 653, Loss: 0.00704785343259573\n",
      "Epoch 654, Loss: 0.19447067379951477\n",
      "Epoch 655, Loss: 0.0046916259452700615\n",
      "Epoch 656, Loss: 0.015064246952533722\n",
      "Epoch 657, Loss: 0.017936157062649727\n",
      "Epoch 658, Loss: 0.004181858152151108\n",
      "Epoch 659, Loss: 0.008251175284385681\n",
      "Epoch 660, Loss: 0.018998686224222183\n",
      "Epoch 661, Loss: 0.07462640851736069\n",
      "Epoch 662, Loss: 0.010697539895772934\n",
      "Epoch 663, Loss: 0.16028860211372375\n",
      "Epoch 664, Loss: 0.018339764326810837\n",
      "Epoch 665, Loss: 0.015185724012553692\n",
      "Epoch 666, Loss: 0.053412068635225296\n",
      "Epoch 667, Loss: 0.018521906808018684\n",
      "Epoch 668, Loss: 0.07193104177713394\n",
      "Epoch 669, Loss: 0.05769095942378044\n",
      "Epoch 670, Loss: 0.06444115936756134\n",
      "Epoch 671, Loss: 0.04198120906949043\n",
      "Epoch 672, Loss: 0.021800542250275612\n",
      "Epoch 673, Loss: 0.008472551591694355\n",
      "Epoch 674, Loss: 0.03479355201125145\n",
      "Epoch 675, Loss: 0.12858903408050537\n",
      "Epoch 676, Loss: 0.02300417236983776\n",
      "Epoch 677, Loss: 0.02896367385983467\n",
      "Epoch 678, Loss: 0.12173837423324585\n",
      "Epoch 679, Loss: 0.021193822845816612\n",
      "Epoch 680, Loss: 0.011742711998522282\n",
      "Epoch 681, Loss: 0.0293784998357296\n",
      "Epoch 682, Loss: 0.09093212336301804\n",
      "Epoch 683, Loss: 0.12641984224319458\n",
      "Epoch 684, Loss: 0.0149250328540802\n",
      "Epoch 685, Loss: 0.016462046653032303\n",
      "Epoch 686, Loss: 0.006110690534114838\n",
      "Epoch 687, Loss: 0.00651139672845602\n",
      "Epoch 688, Loss: 0.035105928778648376\n",
      "Epoch 689, Loss: 0.004767353646457195\n",
      "Epoch 690, Loss: 0.11323763430118561\n",
      "Epoch 691, Loss: 0.01794406957924366\n",
      "Epoch 692, Loss: 0.031677838414907455\n",
      "Epoch 693, Loss: 0.009204589761793613\n",
      "Epoch 694, Loss: 0.2665996253490448\n",
      "Epoch 695, Loss: 0.016466284170746803\n",
      "Epoch 696, Loss: 0.07958318293094635\n",
      "Epoch 697, Loss: 0.06028057262301445\n",
      "Epoch 698, Loss: 0.0146699920296669\n",
      "Epoch 699, Loss: 0.006154126022011042\n",
      "Epoch 700, Loss: 0.11134181916713715\n",
      "Epoch 701, Loss: 0.1363380253314972\n",
      "Epoch 702, Loss: 0.016815226525068283\n",
      "Epoch 703, Loss: 0.04073140025138855\n",
      "Epoch 704, Loss: 0.020114198327064514\n",
      "Epoch 705, Loss: 0.04411165416240692\n",
      "Epoch 706, Loss: 0.023292478173971176\n",
      "Epoch 707, Loss: 0.013823673129081726\n",
      "Epoch 708, Loss: 0.02901846170425415\n",
      "Epoch 709, Loss: 0.011237654834985733\n",
      "Epoch 710, Loss: 0.10587570816278458\n",
      "Epoch 711, Loss: 0.06806614995002747\n",
      "Epoch 712, Loss: 0.10912810266017914\n",
      "Epoch 713, Loss: 0.00692472979426384\n",
      "Epoch 714, Loss: 0.018641483038663864\n",
      "Epoch 715, Loss: 0.10705672204494476\n",
      "Epoch 716, Loss: 0.02963339164853096\n",
      "Epoch 717, Loss: 0.0026123742572963238\n",
      "Epoch 718, Loss: 0.014925110153853893\n",
      "Epoch 719, Loss: 0.0860685184597969\n",
      "Epoch 720, Loss: 0.2006758153438568\n",
      "Epoch 721, Loss: 0.012799957767128944\n",
      "Epoch 722, Loss: 0.029580941423773766\n",
      "Epoch 723, Loss: 0.012205591425299644\n",
      "Epoch 724, Loss: 0.001137299695983529\n",
      "Epoch 725, Loss: 0.1084422692656517\n",
      "Epoch 726, Loss: 0.1049136146903038\n",
      "Epoch 727, Loss: 0.10760563611984253\n",
      "Epoch 728, Loss: 0.12713012099266052\n",
      "Epoch 729, Loss: 0.11169765144586563\n",
      "Epoch 730, Loss: 0.0058519793674349785\n",
      "Epoch 731, Loss: 0.004337345249950886\n",
      "Epoch 732, Loss: 0.012353351339697838\n",
      "Epoch 733, Loss: 0.04684415087103844\n",
      "Epoch 734, Loss: 0.10026867687702179\n",
      "Epoch 735, Loss: 0.08671139925718307\n",
      "Epoch 736, Loss: 0.04260536655783653\n",
      "Epoch 737, Loss: 0.015389998443424702\n",
      "Epoch 738, Loss: 0.017832327634096146\n",
      "Epoch 739, Loss: 0.040793709456920624\n",
      "Epoch 740, Loss: 0.002354583702981472\n",
      "Epoch 741, Loss: 0.013666549697518349\n",
      "Epoch 742, Loss: 0.2182702273130417\n",
      "Epoch 743, Loss: 0.10720449686050415\n",
      "Epoch 744, Loss: 0.0006998979370109737\n",
      "Epoch 745, Loss: 0.021741459146142006\n",
      "Epoch 746, Loss: 0.015499715693295002\n",
      "Epoch 747, Loss: 0.002395994495600462\n",
      "Epoch 748, Loss: 0.01825540140271187\n",
      "Epoch 749, Loss: 0.02282615937292576\n",
      "Epoch 750, Loss: 0.0025407022330909967\n",
      "Epoch 751, Loss: 0.11307211965322495\n",
      "Epoch 752, Loss: 0.11249128729104996\n",
      "Epoch 753, Loss: 0.022664405405521393\n",
      "Epoch 754, Loss: 0.0015947401989251375\n",
      "Epoch 755, Loss: 0.012026512995362282\n",
      "Epoch 756, Loss: 0.18303975462913513\n",
      "Epoch 757, Loss: 0.0062629422172904015\n",
      "Epoch 758, Loss: 0.008243084885179996\n",
      "Epoch 759, Loss: 0.13286510109901428\n",
      "Epoch 760, Loss: 0.039344288408756256\n",
      "Epoch 761, Loss: 0.018135223537683487\n",
      "Epoch 762, Loss: 0.24924392998218536\n",
      "Epoch 763, Loss: 0.06495998799800873\n",
      "Epoch 764, Loss: 0.18310220539569855\n",
      "Epoch 765, Loss: 0.0827036052942276\n",
      "Epoch 766, Loss: 0.05324485898017883\n",
      "Epoch 767, Loss: 0.36725568771362305\n",
      "Epoch 768, Loss: 0.008688438683748245\n",
      "Epoch 769, Loss: 0.015981290489435196\n",
      "Epoch 770, Loss: 0.06857176125049591\n",
      "Epoch 771, Loss: 0.08334698528051376\n",
      "Epoch 772, Loss: 0.10011039674282074\n",
      "Epoch 773, Loss: 0.010737137869000435\n",
      "Epoch 774, Loss: 0.007141930051147938\n",
      "Epoch 775, Loss: 0.18408803641796112\n",
      "Epoch 776, Loss: 0.06809176504611969\n",
      "Epoch 777, Loss: 0.005054553970694542\n",
      "Epoch 778, Loss: 0.11154468357563019\n",
      "Epoch 779, Loss: 0.005094489548355341\n",
      "Epoch 780, Loss: 0.04384529963135719\n",
      "Epoch 781, Loss: 0.03266338258981705\n",
      "Epoch 782, Loss: 0.11488880962133408\n",
      "Epoch 783, Loss: 0.010150420479476452\n",
      "Epoch 784, Loss: 0.18258097767829895\n",
      "Epoch 785, Loss: 0.00937585812062025\n",
      "Epoch 786, Loss: 0.052253544330596924\n",
      "Epoch 787, Loss: 0.0076783811673521996\n",
      "Epoch 788, Loss: 0.008385729975998402\n",
      "Epoch 789, Loss: 0.015712270513176918\n",
      "Epoch 790, Loss: 0.015776006504893303\n",
      "Epoch 791, Loss: 0.012237301096320152\n",
      "Epoch 792, Loss: 0.20055513083934784\n",
      "Epoch 793, Loss: 0.026782259345054626\n",
      "Epoch 794, Loss: 0.016067592427134514\n",
      "Epoch 795, Loss: 0.14524590969085693\n",
      "Epoch 796, Loss: 0.32558509707450867\n",
      "Epoch 797, Loss: 0.0026064831763505936\n",
      "Epoch 798, Loss: 0.0019912244752049446\n",
      "Epoch 799, Loss: 0.009290802292525768\n",
      "Epoch 800, Loss: 0.1766526997089386\n",
      "Epoch 801, Loss: 0.022426966577768326\n",
      "Epoch 802, Loss: 0.027368027716875076\n",
      "Epoch 803, Loss: 0.02126052975654602\n",
      "Epoch 804, Loss: 0.05437064170837402\n",
      "Epoch 805, Loss: 0.0030321930535137653\n",
      "Epoch 806, Loss: 0.021002147346735\n",
      "Epoch 807, Loss: 0.00794411264359951\n",
      "Epoch 808, Loss: 0.2906155288219452\n",
      "Epoch 809, Loss: 0.007568325847387314\n",
      "Epoch 810, Loss: 0.0653267353773117\n",
      "Epoch 811, Loss: 0.004688591696321964\n",
      "Epoch 812, Loss: 0.012567257508635521\n",
      "Epoch 813, Loss: 0.02043413743376732\n",
      "Epoch 814, Loss: 0.10060044378042221\n",
      "Epoch 815, Loss: 0.004101918078958988\n",
      "Epoch 816, Loss: 0.014393819496035576\n",
      "Epoch 817, Loss: 0.029220420867204666\n",
      "Epoch 818, Loss: 0.20005688071250916\n",
      "Epoch 819, Loss: 0.0031943481881171465\n",
      "Epoch 820, Loss: 0.016683261841535568\n",
      "Epoch 821, Loss: 0.0022711812052875757\n",
      "Epoch 822, Loss: 0.02342216484248638\n",
      "Epoch 823, Loss: 0.146439328789711\n",
      "Epoch 824, Loss: 0.02540327049791813\n",
      "Epoch 825, Loss: 0.03904690593481064\n",
      "Epoch 826, Loss: 0.013873888179659843\n",
      "Epoch 827, Loss: 0.08909134566783905\n",
      "Epoch 828, Loss: 0.05743052810430527\n",
      "Epoch 829, Loss: 0.038168031722307205\n",
      "Epoch 830, Loss: 0.020366357639431953\n",
      "Epoch 831, Loss: 0.00110275496263057\n",
      "Epoch 832, Loss: 0.11356554925441742\n",
      "Epoch 833, Loss: 0.026707585901021957\n",
      "Epoch 834, Loss: 0.11552991718053818\n",
      "Epoch 835, Loss: 0.001054065185599029\n",
      "Epoch 836, Loss: 0.07665537297725677\n",
      "Epoch 837, Loss: 0.06941995769739151\n",
      "Epoch 838, Loss: 0.2318231612443924\n",
      "Epoch 839, Loss: 0.10709990561008453\n",
      "Epoch 840, Loss: 0.14777423441410065\n",
      "Epoch 841, Loss: 0.0060847168788313866\n",
      "Epoch 842, Loss: 0.0015642864163964987\n",
      "Epoch 843, Loss: 0.008535720407962799\n",
      "Epoch 844, Loss: 0.028498217463493347\n",
      "Epoch 845, Loss: 0.08471032232046127\n",
      "Epoch 846, Loss: 0.1954716593027115\n",
      "Epoch 847, Loss: 0.1327822506427765\n",
      "Epoch 848, Loss: 0.020955080166459084\n",
      "Epoch 849, Loss: 0.007553085684776306\n",
      "Epoch 850, Loss: 0.001345410943031311\n",
      "Epoch 851, Loss: 0.09344566613435745\n",
      "Epoch 852, Loss: 0.01642153225839138\n",
      "Epoch 853, Loss: 0.002697102725505829\n",
      "Epoch 854, Loss: 0.009523093700408936\n",
      "Epoch 855, Loss: 0.12055790424346924\n",
      "Epoch 856, Loss: 0.00106435630004853\n",
      "Epoch 857, Loss: 0.31174367666244507\n",
      "Epoch 858, Loss: 0.02608257159590721\n",
      "Epoch 859, Loss: 0.005294124595820904\n",
      "Epoch 860, Loss: 0.04784749448299408\n",
      "Epoch 861, Loss: 0.002723714802414179\n",
      "Epoch 862, Loss: 0.026996847242116928\n",
      "Epoch 863, Loss: 0.07815197855234146\n",
      "Epoch 864, Loss: 0.03009633719921112\n",
      "Epoch 865, Loss: 0.011468900367617607\n",
      "Epoch 866, Loss: 0.2577715516090393\n",
      "Epoch 867, Loss: 0.02873896434903145\n",
      "Epoch 868, Loss: 0.007105787750333548\n",
      "Epoch 869, Loss: 0.2566426694393158\n",
      "Epoch 870, Loss: 0.012232156470417976\n",
      "Epoch 871, Loss: 0.008447783067822456\n",
      "Epoch 872, Loss: 0.0213306937366724\n",
      "Epoch 873, Loss: 0.0005467465380206704\n",
      "Epoch 874, Loss: 0.09350098669528961\n",
      "Epoch 875, Loss: 0.019367890432476997\n",
      "Epoch 876, Loss: 0.009079978801310062\n",
      "Epoch 877, Loss: 0.021079784259200096\n",
      "Epoch 878, Loss: 0.010271605104207993\n",
      "Epoch 879, Loss: 0.0072029209695756435\n",
      "Epoch 880, Loss: 0.1644664704799652\n",
      "Epoch 881, Loss: 0.016705889254808426\n",
      "Epoch 882, Loss: 0.10705380141735077\n",
      "Epoch 883, Loss: 0.2379971295595169\n",
      "Epoch 884, Loss: 0.28873544931411743\n",
      "Epoch 885, Loss: 0.008356858976185322\n",
      "Epoch 886, Loss: 0.003576087998226285\n",
      "Epoch 887, Loss: 0.03708191588521004\n",
      "Epoch 888, Loss: 0.07644973695278168\n",
      "Epoch 889, Loss: 0.006754252128303051\n",
      "Epoch 890, Loss: 0.08195547014474869\n",
      "Epoch 891, Loss: 0.006100165192037821\n",
      "Epoch 892, Loss: 0.09872959554195404\n",
      "Epoch 893, Loss: 0.008113827556371689\n",
      "Epoch 894, Loss: 0.01914704032242298\n",
      "Epoch 895, Loss: 0.022286858409643173\n",
      "Epoch 896, Loss: 0.009608792141079903\n",
      "Epoch 897, Loss: 0.0035931419115513563\n",
      "Epoch 898, Loss: 0.0037746517919003963\n",
      "Epoch 899, Loss: 0.004944268614053726\n",
      "Epoch 900, Loss: 0.003765517147257924\n",
      "Epoch 901, Loss: 0.0020657654386013746\n",
      "Epoch 902, Loss: 0.020165378227829933\n",
      "Epoch 903, Loss: 0.04093732684850693\n",
      "Epoch 904, Loss: 0.006596726831048727\n",
      "Epoch 905, Loss: 0.14429913461208344\n",
      "Epoch 906, Loss: 0.20935752987861633\n",
      "Epoch 907, Loss: 0.22037211060523987\n",
      "Epoch 908, Loss: 0.008322995156049728\n",
      "Epoch 909, Loss: 0.05329563468694687\n",
      "Epoch 910, Loss: 0.027562862262129784\n",
      "Epoch 911, Loss: 0.2481611669063568\n",
      "Epoch 912, Loss: 0.01898658089339733\n",
      "Epoch 913, Loss: 0.02437622658908367\n",
      "Epoch 914, Loss: 0.01144385151565075\n",
      "Epoch 915, Loss: 0.005554769188165665\n",
      "Epoch 916, Loss: 0.006780183874070644\n",
      "Epoch 917, Loss: 0.45306140184402466\n",
      "Epoch 918, Loss: 0.06303929537534714\n",
      "Epoch 919, Loss: 0.012550944462418556\n",
      "Epoch 920, Loss: 0.02629510499536991\n",
      "Epoch 921, Loss: 0.008502498269081116\n",
      "Epoch 922, Loss: 0.0030123484320938587\n",
      "Epoch 923, Loss: 0.1690262258052826\n",
      "Epoch 924, Loss: 0.03202841058373451\n",
      "Epoch 925, Loss: 0.19730553030967712\n",
      "Epoch 926, Loss: 0.08591645956039429\n",
      "Epoch 927, Loss: 0.06528329849243164\n",
      "Epoch 928, Loss: 0.5731016397476196\n",
      "Epoch 929, Loss: 0.035826411098241806\n",
      "Epoch 930, Loss: 0.11470164358615875\n",
      "Epoch 931, Loss: 0.10696981847286224\n",
      "Epoch 932, Loss: 0.0023591089993715286\n",
      "Epoch 933, Loss: 0.008208615705370903\n",
      "Epoch 934, Loss: 0.0617021806538105\n",
      "Epoch 935, Loss: 0.0051016309298574924\n",
      "Epoch 936, Loss: 0.011235242709517479\n",
      "Epoch 937, Loss: 0.09184110164642334\n",
      "Epoch 938, Loss: 0.3200550973415375\n",
      "Epoch 939, Loss: 0.10863705724477768\n",
      "Epoch 940, Loss: 0.043021418154239655\n",
      "Epoch 941, Loss: 0.003915571141988039\n",
      "Epoch 942, Loss: 0.09301715344190598\n",
      "Epoch 943, Loss: 0.012928071431815624\n",
      "Epoch 944, Loss: 0.14654988050460815\n",
      "Epoch 945, Loss: 0.011266726069152355\n",
      "Epoch 946, Loss: 0.16580958664417267\n",
      "Epoch 947, Loss: 0.10290209203958511\n",
      "Epoch 948, Loss: 0.007927929051220417\n",
      "Epoch 949, Loss: 0.014194823801517487\n",
      "Epoch 950, Loss: 0.01761620305478573\n",
      "Epoch 951, Loss: 0.02867896296083927\n",
      "Epoch 952, Loss: 0.009675705805420876\n",
      "Epoch 953, Loss: 0.01229102723300457\n",
      "Epoch 954, Loss: 0.020464126020669937\n",
      "Epoch 955, Loss: 0.0031203157268464565\n",
      "Epoch 956, Loss: 0.0013294646050781012\n",
      "Epoch 957, Loss: 0.09983005374670029\n",
      "Epoch 958, Loss: 0.015504573471844196\n",
      "Epoch 959, Loss: 0.0020557779353111982\n",
      "Epoch 960, Loss: 0.008987178094685078\n",
      "Epoch 961, Loss: 0.2480597198009491\n",
      "Epoch 962, Loss: 0.004325308836996555\n",
      "Epoch 963, Loss: 0.004183728713542223\n",
      "Epoch 964, Loss: 0.012770970351994038\n",
      "Epoch 965, Loss: 0.02246490679681301\n",
      "Epoch 966, Loss: 0.0014011309249326587\n",
      "Epoch 967, Loss: 0.013528361916542053\n",
      "Epoch 968, Loss: 0.0625893697142601\n",
      "Epoch 969, Loss: 0.02648938074707985\n",
      "Epoch 970, Loss: 0.007882020436227322\n",
      "Epoch 971, Loss: 0.014685598202049732\n",
      "Epoch 972, Loss: 0.010442566126585007\n",
      "Epoch 973, Loss: 0.09210566431283951\n",
      "Epoch 974, Loss: 0.01919487491250038\n",
      "Epoch 975, Loss: 0.19542942941188812\n",
      "Epoch 976, Loss: 0.012361573055386543\n",
      "Epoch 977, Loss: 0.06365840137004852\n",
      "Epoch 978, Loss: 0.042994625866413116\n",
      "Epoch 979, Loss: 0.093417227268219\n",
      "Epoch 980, Loss: 0.0567958727478981\n",
      "Epoch 981, Loss: 0.03512882441282272\n",
      "Epoch 982, Loss: 0.016105175018310547\n",
      "Epoch 983, Loss: 0.008018182590603828\n",
      "Epoch 984, Loss: 0.13857311010360718\n",
      "Epoch 985, Loss: 0.04735240340232849\n",
      "Epoch 986, Loss: 0.13200251758098602\n",
      "Epoch 987, Loss: 0.04499131813645363\n",
      "Epoch 988, Loss: 0.20068521797657013\n",
      "Epoch 989, Loss: 0.00812462717294693\n",
      "Epoch 990, Loss: 0.008632301352918148\n",
      "Epoch 991, Loss: 0.005453322548419237\n",
      "Epoch 992, Loss: 0.03828379884362221\n",
      "Epoch 993, Loss: 0.0033771067392081022\n",
      "Epoch 994, Loss: 0.02282951958477497\n",
      "Epoch 995, Loss: 0.00953610334545374\n",
      "Epoch 996, Loss: 0.005874174181371927\n",
      "Epoch 997, Loss: 0.0022639634553343058\n",
      "Epoch 998, Loss: 0.07081569731235504\n",
      "Epoch 999, Loss: 0.12310377508401871\n",
      "Epoch 1000, Loss: 0.07515083998441696\n",
      "Epoch 1001, Loss: 0.021476615220308304\n",
      "Epoch 1002, Loss: 0.010515077970921993\n",
      "Epoch 1003, Loss: 0.0354267843067646\n",
      "Epoch 1004, Loss: 0.096401147544384\n",
      "Epoch 1005, Loss: 0.020040113478899002\n",
      "Epoch 1006, Loss: 0.021326187998056412\n",
      "Epoch 1007, Loss: 0.01613161712884903\n",
      "Epoch 1008, Loss: 0.02000674046576023\n",
      "Epoch 1009, Loss: 0.05020841211080551\n",
      "Epoch 1010, Loss: 0.4293442368507385\n",
      "Epoch 1011, Loss: 0.0045426287688314915\n",
      "Epoch 1012, Loss: 0.008102023042738438\n",
      "Epoch 1013, Loss: 0.07099536061286926\n",
      "Epoch 1014, Loss: 0.052228767424821854\n",
      "Epoch 1015, Loss: 0.011981680057942867\n",
      "Epoch 1016, Loss: 0.005353544373065233\n",
      "Epoch 1017, Loss: 0.1123720034956932\n",
      "Epoch 1018, Loss: 0.004353082273155451\n",
      "Epoch 1019, Loss: 0.01462957076728344\n",
      "Epoch 1020, Loss: 0.009439999237656593\n",
      "Epoch 1021, Loss: 0.11259569972753525\n",
      "Epoch 1022, Loss: 0.015046877786517143\n",
      "Epoch 1023, Loss: 0.010254675522446632\n",
      "Epoch 1024, Loss: 0.11732743680477142\n",
      "Epoch 1025, Loss: 0.00743040582165122\n",
      "Epoch 1026, Loss: 0.016435787081718445\n",
      "Epoch 1027, Loss: 0.10093805938959122\n",
      "Epoch 1028, Loss: 0.002538556233048439\n",
      "Epoch 1029, Loss: 0.012843133881688118\n",
      "Epoch 1030, Loss: 0.017099563032388687\n",
      "Epoch 1031, Loss: 0.01746131107211113\n",
      "Epoch 1032, Loss: 0.0286780446767807\n",
      "Epoch 1033, Loss: 0.04384610056877136\n",
      "Epoch 1034, Loss: 0.007844654843211174\n",
      "Epoch 1035, Loss: 0.017162488773465157\n",
      "Epoch 1036, Loss: 0.2234809398651123\n",
      "Epoch 1037, Loss: 0.1360170543193817\n",
      "Epoch 1038, Loss: 0.036075010895729065\n",
      "Epoch 1039, Loss: 0.004964207299053669\n",
      "Epoch 1040, Loss: 0.08964898437261581\n",
      "Epoch 1041, Loss: 0.0031639919616281986\n",
      "Epoch 1042, Loss: 0.025860359892249107\n",
      "Epoch 1043, Loss: 0.0031261048279702663\n",
      "Epoch 1044, Loss: 0.07774247229099274\n",
      "Epoch 1045, Loss: 0.08988750725984573\n",
      "Epoch 1046, Loss: 0.08599048852920532\n",
      "Epoch 1047, Loss: 0.011854794807732105\n",
      "Epoch 1048, Loss: 0.01839866116642952\n",
      "Epoch 1049, Loss: 0.11986975371837616\n",
      "Epoch 1050, Loss: 0.008534610271453857\n",
      "Epoch 1051, Loss: 0.09323454648256302\n",
      "Epoch 1052, Loss: 0.2027982920408249\n",
      "Epoch 1053, Loss: 0.20148031413555145\n",
      "Epoch 1054, Loss: 0.03181847184896469\n",
      "Epoch 1055, Loss: 0.012324881739914417\n",
      "Epoch 1056, Loss: 0.03496686741709709\n",
      "Epoch 1057, Loss: 0.016728367656469345\n",
      "Epoch 1058, Loss: 0.0029975860379636288\n",
      "Epoch 1059, Loss: 0.0016255241353064775\n",
      "Epoch 1060, Loss: 0.015150792896747589\n",
      "Epoch 1061, Loss: 0.017431775107979774\n",
      "Epoch 1062, Loss: 0.11454318463802338\n",
      "Epoch 1063, Loss: 0.08249954134225845\n",
      "Epoch 1064, Loss: 0.017313942313194275\n",
      "Epoch 1065, Loss: 0.03382681682705879\n",
      "Epoch 1066, Loss: 0.11769841611385345\n",
      "Epoch 1067, Loss: 0.19201870262622833\n",
      "Epoch 1068, Loss: 0.0010950386058539152\n",
      "Epoch 1069, Loss: 0.0030267161782830954\n",
      "Epoch 1070, Loss: 0.006919051054865122\n",
      "Epoch 1071, Loss: 0.03126463666558266\n",
      "Epoch 1072, Loss: 0.034636978060007095\n",
      "Epoch 1073, Loss: 0.038351405411958694\n",
      "Epoch 1074, Loss: 0.009827408008277416\n",
      "Epoch 1075, Loss: 0.012573678977787495\n",
      "Epoch 1076, Loss: 0.03658091649413109\n",
      "Epoch 1077, Loss: 0.25890183448791504\n",
      "Epoch 1078, Loss: 0.01732831820845604\n",
      "Epoch 1079, Loss: 0.0036251493729650974\n",
      "Epoch 1080, Loss: 0.0021410102490335703\n",
      "Epoch 1081, Loss: 0.011962613090872765\n",
      "Epoch 1082, Loss: 0.009660398587584496\n",
      "Epoch 1083, Loss: 0.04607871174812317\n",
      "Epoch 1084, Loss: 0.0006377110839821398\n",
      "Epoch 1085, Loss: 0.003927937708795071\n",
      "Epoch 1086, Loss: 0.006560221314430237\n",
      "Epoch 1087, Loss: 0.04510995373129845\n",
      "Epoch 1088, Loss: 0.0018878206610679626\n",
      "Epoch 1089, Loss: 0.011874967254698277\n",
      "Epoch 1090, Loss: 0.0020316101144999266\n",
      "Epoch 1091, Loss: 0.009619934484362602\n",
      "Epoch 1092, Loss: 0.1353999227285385\n",
      "Epoch 1093, Loss: 0.021624969318509102\n",
      "Epoch 1094, Loss: 0.08029404282569885\n",
      "Epoch 1095, Loss: 0.028571397066116333\n",
      "Epoch 1096, Loss: 0.033645130693912506\n",
      "Epoch 1097, Loss: 0.020021894946694374\n",
      "Epoch 1098, Loss: 0.0016703319270163774\n",
      "Epoch 1099, Loss: 0.10436121374368668\n",
      "Epoch 1100, Loss: 0.02270292118191719\n",
      "Epoch 1101, Loss: 0.0607367567718029\n",
      "Epoch 1102, Loss: 0.028724700212478638\n",
      "Epoch 1103, Loss: 0.09850571304559708\n",
      "Epoch 1104, Loss: 0.015868980437517166\n",
      "Epoch 1105, Loss: 0.009270315058529377\n",
      "Epoch 1106, Loss: 0.012121356092393398\n",
      "Epoch 1107, Loss: 0.11223410069942474\n",
      "Epoch 1108, Loss: 0.11066693067550659\n",
      "Epoch 1109, Loss: 0.04850838705897331\n",
      "Epoch 1110, Loss: 0.015805574133992195\n",
      "Epoch 1111, Loss: 0.01728604920208454\n",
      "Epoch 1112, Loss: 0.0683993548154831\n",
      "Epoch 1113, Loss: 0.01227730792015791\n",
      "Epoch 1114, Loss: 0.11770029366016388\n",
      "Epoch 1115, Loss: 0.017418023198843002\n",
      "Epoch 1116, Loss: 0.0501258485019207\n",
      "Epoch 1117, Loss: 0.009540824219584465\n",
      "Epoch 1118, Loss: 0.07923164963722229\n",
      "Epoch 1119, Loss: 0.018642228096723557\n",
      "Epoch 1120, Loss: 0.14654839038848877\n",
      "Epoch 1121, Loss: 0.023466669023036957\n",
      "Epoch 1122, Loss: 0.0030886982567608356\n",
      "Epoch 1123, Loss: 0.14768998324871063\n",
      "Epoch 1124, Loss: 0.0008638493018224835\n",
      "Epoch 1125, Loss: 0.028234723955392838\n",
      "Epoch 1126, Loss: 0.05767715722322464\n",
      "Epoch 1127, Loss: 0.07248062640428543\n",
      "Epoch 1128, Loss: 0.11047367006540298\n",
      "Epoch 1129, Loss: 0.006968738976866007\n",
      "Epoch 1130, Loss: 0.008302674628794193\n",
      "Epoch 1131, Loss: 0.18866027891635895\n",
      "Epoch 1132, Loss: 0.15840207040309906\n",
      "Epoch 1133, Loss: 0.0036464035511016846\n",
      "Epoch 1134, Loss: 0.10252237319946289\n",
      "Epoch 1135, Loss: 0.08656855672597885\n",
      "Epoch 1136, Loss: 0.0903661698102951\n",
      "Epoch 1137, Loss: 0.019110947847366333\n",
      "Epoch 1138, Loss: 0.031543005257844925\n",
      "Epoch 1139, Loss: 0.0217277891933918\n",
      "Epoch 1140, Loss: 0.023310068994760513\n",
      "Epoch 1141, Loss: 0.012390726245939732\n",
      "Epoch 1142, Loss: 0.01463975477963686\n",
      "Epoch 1143, Loss: 0.013219475746154785\n",
      "Epoch 1144, Loss: 0.0223859753459692\n",
      "Epoch 1145, Loss: 0.03673287481069565\n",
      "Epoch 1146, Loss: 0.08728455007076263\n",
      "Epoch 1147, Loss: 0.009732144884765148\n",
      "Epoch 1148, Loss: 0.07579571008682251\n",
      "Epoch 1149, Loss: 0.008495942689478397\n",
      "Epoch 1150, Loss: 0.10271291434764862\n",
      "Epoch 1151, Loss: 0.04678533971309662\n",
      "Epoch 1152, Loss: 0.04579043760895729\n",
      "Epoch 1153, Loss: 0.06321725994348526\n",
      "Epoch 1154, Loss: 0.08917541801929474\n",
      "Epoch 1155, Loss: 0.006922631524503231\n",
      "Epoch 1156, Loss: 0.0025812506210058928\n",
      "Epoch 1157, Loss: 0.004050783812999725\n",
      "Epoch 1158, Loss: 0.0112233217805624\n",
      "Epoch 1159, Loss: 0.022742625325918198\n",
      "Epoch 1160, Loss: 0.09945841133594513\n",
      "Epoch 1161, Loss: 0.000950026442296803\n",
      "Epoch 1162, Loss: 0.12461141496896744\n",
      "Epoch 1163, Loss: 0.0565335750579834\n",
      "Epoch 1164, Loss: 0.015290385112166405\n",
      "Epoch 1165, Loss: 0.0036987836938351393\n",
      "Epoch 1166, Loss: 0.02064826898276806\n",
      "Epoch 1167, Loss: 0.0791962742805481\n",
      "Epoch 1168, Loss: 0.025520121678709984\n",
      "Epoch 1169, Loss: 0.028147000819444656\n",
      "Epoch 1170, Loss: 0.02761591039597988\n",
      "Epoch 1171, Loss: 0.01589328423142433\n",
      "Epoch 1172, Loss: 0.01371978223323822\n",
      "Epoch 1173, Loss: 0.002838471904397011\n",
      "Epoch 1174, Loss: 0.02559186890721321\n",
      "Epoch 1175, Loss: 0.1870267540216446\n",
      "Epoch 1176, Loss: 0.01805296540260315\n",
      "Epoch 1177, Loss: 0.0034298175014555454\n",
      "Epoch 1178, Loss: 0.0026370675768703222\n",
      "Epoch 1179, Loss: 0.012724561616778374\n",
      "Epoch 1180, Loss: 0.0809592753648758\n",
      "Epoch 1181, Loss: 0.005167110823094845\n",
      "Epoch 1182, Loss: 0.004621279425919056\n",
      "Epoch 1183, Loss: 0.002411671681329608\n",
      "Epoch 1184, Loss: 0.0016810534289106727\n",
      "Epoch 1185, Loss: 0.02889252081513405\n",
      "Epoch 1186, Loss: 0.01663847267627716\n",
      "Epoch 1187, Loss: 0.023500744253396988\n",
      "Epoch 1188, Loss: 0.0013521239161491394\n",
      "Epoch 1189, Loss: 0.011283202096819878\n",
      "Epoch 1190, Loss: 0.005901949480175972\n",
      "Epoch 1191, Loss: 0.3734525740146637\n",
      "Epoch 1192, Loss: 0.035146165639162064\n",
      "Epoch 1193, Loss: 0.10838980972766876\n",
      "Epoch 1194, Loss: 0.0030861790291965008\n",
      "Epoch 1195, Loss: 0.0006296423962339759\n",
      "Epoch 1196, Loss: 0.01068432442843914\n",
      "Epoch 1197, Loss: 0.020748494192957878\n",
      "Epoch 1198, Loss: 0.07555760443210602\n",
      "Epoch 1199, Loss: 0.012899701483547688\n",
      "Epoch 1200, Loss: 0.0012166984379291534\n",
      "Epoch 1201, Loss: 0.023518595844507217\n",
      "Epoch 1202, Loss: 0.5316987037658691\n",
      "Epoch 1203, Loss: 0.008340013213455677\n",
      "Epoch 1204, Loss: 0.027916032820940018\n",
      "Epoch 1205, Loss: 0.19371820986270905\n",
      "Epoch 1206, Loss: 0.007778511848300695\n",
      "Epoch 1207, Loss: 0.005802371073514223\n",
      "Epoch 1208, Loss: 0.11486086994409561\n",
      "Epoch 1209, Loss: 0.028436794877052307\n",
      "Epoch 1210, Loss: 0.01889108307659626\n",
      "Epoch 1211, Loss: 0.018077965825796127\n",
      "Epoch 1212, Loss: 0.010734202340245247\n",
      "Epoch 1213, Loss: 0.038640715181827545\n",
      "Epoch 1214, Loss: 0.10291580110788345\n",
      "Epoch 1215, Loss: 0.005824538413435221\n",
      "Epoch 1216, Loss: 0.000337762467097491\n",
      "Epoch 1217, Loss: 0.002553483471274376\n",
      "Epoch 1218, Loss: 0.003558967960998416\n",
      "Epoch 1219, Loss: 0.24911156296730042\n",
      "Epoch 1220, Loss: 0.001265607075765729\n",
      "Epoch 1221, Loss: 0.0018768642330542207\n",
      "Epoch 1222, Loss: 0.00939134694635868\n",
      "Epoch 1223, Loss: 0.006823775824159384\n",
      "Epoch 1224, Loss: 0.06083151698112488\n",
      "Epoch 1225, Loss: 0.02159295044839382\n",
      "Epoch 1226, Loss: 0.09299546480178833\n",
      "Epoch 1227, Loss: 0.0023277155123651028\n",
      "Epoch 1228, Loss: 0.0038004890084266663\n",
      "Epoch 1229, Loss: 0.05432892590761185\n",
      "Epoch 1230, Loss: 0.008126107975840569\n",
      "Epoch 1231, Loss: 0.023282770067453384\n",
      "Epoch 1232, Loss: 0.15282084047794342\n",
      "Epoch 1233, Loss: 0.2357812225818634\n",
      "Epoch 1234, Loss: 0.056687600910663605\n",
      "Epoch 1235, Loss: 0.009635433554649353\n",
      "Epoch 1236, Loss: 0.09901121258735657\n",
      "Epoch 1237, Loss: 0.027512451633810997\n",
      "Epoch 1238, Loss: 0.1271325796842575\n",
      "Epoch 1239, Loss: 0.029359813779592514\n",
      "Epoch 1240, Loss: 0.002245938638225198\n",
      "Epoch 1241, Loss: 0.09088680893182755\n",
      "Epoch 1242, Loss: 0.010466349311172962\n",
      "Epoch 1243, Loss: 0.0050812168046832085\n",
      "Epoch 1244, Loss: 0.026617515832185745\n",
      "Epoch 1245, Loss: 0.010993018746376038\n",
      "Epoch 1246, Loss: 0.008404767140746117\n",
      "Epoch 1247, Loss: 0.020641695708036423\n",
      "Epoch 1248, Loss: 0.005921609234064817\n",
      "Epoch 1249, Loss: 0.18758997321128845\n",
      "Epoch 1250, Loss: 0.017014367505908012\n",
      "Epoch 1251, Loss: 0.008566564880311489\n",
      "Epoch 1252, Loss: 0.009895194321870804\n",
      "Epoch 1253, Loss: 0.018890954554080963\n",
      "Epoch 1254, Loss: 0.008996302261948586\n",
      "Epoch 1255, Loss: 0.008938523940742016\n",
      "Epoch 1256, Loss: 0.004561564419418573\n",
      "Epoch 1257, Loss: 0.0176769457757473\n",
      "Epoch 1258, Loss: 0.060436565428972244\n",
      "Epoch 1259, Loss: 0.13906759023666382\n",
      "Epoch 1260, Loss: 0.4406047761440277\n",
      "Epoch 1261, Loss: 0.15207533538341522\n",
      "Epoch 1262, Loss: 0.014856422320008278\n",
      "Epoch 1263, Loss: 0.007218255195766687\n",
      "Epoch 1264, Loss: 0.005360759329050779\n",
      "Epoch 1265, Loss: 0.23364043235778809\n",
      "Epoch 1266, Loss: 0.02686021663248539\n",
      "Epoch 1267, Loss: 0.14925029873847961\n",
      "Epoch 1268, Loss: 0.0258844792842865\n",
      "Epoch 1269, Loss: 0.007827498950064182\n",
      "Epoch 1270, Loss: 0.09625901281833649\n",
      "Epoch 1271, Loss: 0.023174388334155083\n",
      "Epoch 1272, Loss: 0.051298391073942184\n",
      "Epoch 1273, Loss: 0.029679473489522934\n",
      "Epoch 1274, Loss: 0.032994434237480164\n",
      "Epoch 1275, Loss: 0.0022265238221734762\n",
      "Epoch 1276, Loss: 0.07149900496006012\n",
      "Epoch 1277, Loss: 0.014979496598243713\n",
      "Epoch 1278, Loss: 0.020790468901395798\n",
      "Epoch 1279, Loss: 0.026185622438788414\n",
      "Epoch 1280, Loss: 0.023906897753477097\n",
      "Epoch 1281, Loss: 0.23093652725219727\n",
      "Epoch 1282, Loss: 0.01785019040107727\n",
      "Epoch 1283, Loss: 0.16939479112625122\n",
      "Epoch 1284, Loss: 0.013996200636029243\n",
      "Epoch 1285, Loss: 0.00615542009472847\n",
      "Epoch 1286, Loss: 0.08477477729320526\n",
      "Epoch 1287, Loss: 0.031187575310468674\n",
      "Epoch 1288, Loss: 0.08064334094524384\n",
      "Epoch 1289, Loss: 0.07600495219230652\n",
      "Epoch 1290, Loss: 0.234135702252388\n",
      "Epoch 1291, Loss: 0.18831783533096313\n",
      "Epoch 1292, Loss: 0.08675485104322433\n",
      "Epoch 1293, Loss: 0.004336184822022915\n",
      "Epoch 1294, Loss: 0.2707924246788025\n",
      "Epoch 1295, Loss: 0.0019549827557057142\n",
      "Epoch 1296, Loss: 0.011669705621898174\n",
      "Epoch 1297, Loss: 0.011765234172344208\n",
      "Epoch 1298, Loss: 0.037264417856931686\n",
      "Epoch 1299, Loss: 0.13635468482971191\n",
      "Epoch 1300, Loss: 0.028956925496459007\n",
      "Epoch 1301, Loss: 0.08075098693370819\n",
      "Epoch 1302, Loss: 0.03680763393640518\n",
      "Epoch 1303, Loss: 0.009224540553987026\n",
      "Epoch 1304, Loss: 0.017245003953576088\n",
      "Epoch 1305, Loss: 0.014373444020748138\n",
      "Epoch 1306, Loss: 0.21765652298927307\n",
      "Epoch 1307, Loss: 0.022190123796463013\n",
      "Epoch 1308, Loss: 0.002779121045023203\n",
      "Epoch 1309, Loss: 0.012861790135502815\n",
      "Epoch 1310, Loss: 0.07654774188995361\n",
      "Epoch 1311, Loss: 0.025099236518144608\n",
      "Epoch 1312, Loss: 0.0013258191756904125\n",
      "Epoch 1313, Loss: 0.04641496017575264\n",
      "Epoch 1314, Loss: 0.042562972754240036\n",
      "Epoch 1315, Loss: 0.002163057681173086\n",
      "Epoch 1316, Loss: 0.03272710368037224\n",
      "Epoch 1317, Loss: 0.07324054092168808\n",
      "Epoch 1318, Loss: 0.07441643625497818\n",
      "Epoch 1319, Loss: 0.01784963347017765\n",
      "Epoch 1320, Loss: 0.10288786888122559\n",
      "Epoch 1321, Loss: 0.047812458127737045\n",
      "Epoch 1322, Loss: 0.014841966331005096\n",
      "Epoch 1323, Loss: 0.005552900023758411\n",
      "Epoch 1324, Loss: 0.006038576830178499\n",
      "Epoch 1325, Loss: 0.00519501743838191\n",
      "Epoch 1326, Loss: 0.0030989486258476973\n",
      "Epoch 1327, Loss: 0.2268681526184082\n",
      "Epoch 1328, Loss: 0.025864383205771446\n",
      "Epoch 1329, Loss: 0.06946536153554916\n",
      "Epoch 1330, Loss: 0.29396504163742065\n",
      "Epoch 1331, Loss: 0.003972700797021389\n",
      "Epoch 1332, Loss: 0.050776757299900055\n",
      "Epoch 1333, Loss: 0.0754217803478241\n",
      "Epoch 1334, Loss: 0.016355477273464203\n",
      "Epoch 1335, Loss: 0.014968251809477806\n",
      "Epoch 1336, Loss: 0.012755279429256916\n",
      "Epoch 1337, Loss: 0.008648645132780075\n",
      "Epoch 1338, Loss: 0.03779448941349983\n",
      "Epoch 1339, Loss: 0.0021202899515628815\n",
      "Epoch 1340, Loss: 0.003534602001309395\n",
      "Epoch 1341, Loss: 0.00845823623239994\n",
      "Epoch 1342, Loss: 0.005896667018532753\n",
      "Epoch 1343, Loss: 0.009383231401443481\n",
      "Epoch 1344, Loss: 0.1196027547121048\n",
      "Epoch 1345, Loss: 0.043942537158727646\n",
      "Epoch 1346, Loss: 0.010048644617199898\n",
      "Epoch 1347, Loss: 0.021620992571115494\n",
      "Epoch 1348, Loss: 0.008385754190385342\n",
      "Epoch 1349, Loss: 0.0027188509702682495\n",
      "Epoch 1350, Loss: 0.0019843601621687412\n",
      "Epoch 1351, Loss: 0.05203387886285782\n",
      "Epoch 1352, Loss: 0.01842661201953888\n",
      "Epoch 1353, Loss: 0.0032869838178157806\n",
      "Epoch 1354, Loss: 0.011032097041606903\n",
      "Epoch 1355, Loss: 0.024675996974110603\n",
      "Epoch 1356, Loss: 0.0027978899888694286\n",
      "Epoch 1357, Loss: 0.014875595457851887\n",
      "Epoch 1358, Loss: 0.023536689579486847\n",
      "Epoch 1359, Loss: 0.2813112735748291\n",
      "Epoch 1360, Loss: 0.06030721217393875\n",
      "Epoch 1361, Loss: 0.007408740930259228\n",
      "Epoch 1362, Loss: 0.005301326513290405\n",
      "Epoch 1363, Loss: 0.01617726869881153\n",
      "Epoch 1364, Loss: 0.016008082777261734\n",
      "Epoch 1365, Loss: 0.01860200986266136\n",
      "Epoch 1366, Loss: 0.0009770102333277464\n",
      "Epoch 1367, Loss: 0.08716848492622375\n",
      "Epoch 1368, Loss: 0.14572057127952576\n",
      "Epoch 1369, Loss: 0.006777135189622641\n",
      "Epoch 1370, Loss: 0.02838912606239319\n",
      "Epoch 1371, Loss: 0.025018062442541122\n",
      "Epoch 1372, Loss: 0.00473615201190114\n",
      "Epoch 1373, Loss: 0.009017476812005043\n",
      "Epoch 1374, Loss: 0.11330819129943848\n",
      "Epoch 1375, Loss: 0.02472762204706669\n",
      "Epoch 1376, Loss: 0.10021265596151352\n",
      "Epoch 1377, Loss: 0.21467828750610352\n",
      "Epoch 1378, Loss: 0.0877639576792717\n",
      "Epoch 1379, Loss: 0.009688948281109333\n",
      "Epoch 1380, Loss: 0.2030792534351349\n",
      "Epoch 1381, Loss: 0.010866242460906506\n",
      "Epoch 1382, Loss: 0.09587575495243073\n",
      "Epoch 1383, Loss: 0.01927536353468895\n",
      "Epoch 1384, Loss: 0.09630163013935089\n",
      "Epoch 1385, Loss: 0.011181498877704144\n",
      "Epoch 1386, Loss: 0.009174334816634655\n",
      "Epoch 1387, Loss: 0.011372959241271019\n",
      "Epoch 1388, Loss: 0.01768483594059944\n",
      "Epoch 1389, Loss: 0.07033489644527435\n",
      "Epoch 1390, Loss: 0.023737793788313866\n",
      "Epoch 1391, Loss: 0.08165449649095535\n",
      "Epoch 1392, Loss: 0.025980323553085327\n",
      "Epoch 1393, Loss: 0.004253664053976536\n",
      "Epoch 1394, Loss: 0.0016037968453019857\n",
      "Epoch 1395, Loss: 0.024800729006528854\n",
      "Epoch 1396, Loss: 0.10500133037567139\n",
      "Epoch 1397, Loss: 0.009050140157341957\n",
      "Epoch 1398, Loss: 0.012069016695022583\n",
      "Epoch 1399, Loss: 0.025999154895544052\n",
      "Epoch 1400, Loss: 0.14472275972366333\n",
      "Epoch 1401, Loss: 0.01009706687182188\n",
      "Epoch 1402, Loss: 0.0906994491815567\n",
      "Epoch 1403, Loss: 0.0011399073991924524\n",
      "Epoch 1404, Loss: 0.037227220833301544\n",
      "Epoch 1405, Loss: 0.09918303787708282\n",
      "Epoch 1406, Loss: 0.02162419632077217\n",
      "Epoch 1407, Loss: 0.0015360626857727766\n",
      "Epoch 1408, Loss: 0.0240204818546772\n",
      "Epoch 1409, Loss: 0.03136295825242996\n",
      "Epoch 1410, Loss: 0.002257302636280656\n",
      "Epoch 1411, Loss: 0.005921461619436741\n",
      "Epoch 1412, Loss: 0.019723661243915558\n",
      "Epoch 1413, Loss: 0.08187679946422577\n",
      "Epoch 1414, Loss: 0.09341854602098465\n",
      "Epoch 1415, Loss: 0.003309253603219986\n",
      "Epoch 1416, Loss: 0.0024496091064065695\n",
      "Epoch 1417, Loss: 0.00838434137403965\n",
      "Epoch 1418, Loss: 0.5644249320030212\n",
      "Epoch 1419, Loss: 0.03670879825949669\n",
      "Epoch 1420, Loss: 0.021398136392235756\n",
      "Epoch 1421, Loss: 0.2415212094783783\n",
      "Epoch 1422, Loss: 0.15759024024009705\n",
      "Epoch 1423, Loss: 0.002359752543270588\n",
      "Epoch 1424, Loss: 0.025813717395067215\n",
      "Epoch 1425, Loss: 0.09658242762088776\n",
      "Epoch 1426, Loss: 0.025259098038077354\n",
      "Epoch 1427, Loss: 0.01678561605513096\n",
      "Epoch 1428, Loss: 0.009625120088458061\n",
      "Epoch 1429, Loss: 0.02747022546827793\n",
      "Epoch 1430, Loss: 0.03446924686431885\n",
      "Epoch 1431, Loss: 0.10404558479785919\n",
      "Epoch 1432, Loss: 0.07992614060640335\n",
      "Epoch 1433, Loss: 0.012274445965886116\n",
      "Epoch 1434, Loss: 0.11176705360412598\n",
      "Epoch 1435, Loss: 0.0029201090801507235\n",
      "Epoch 1436, Loss: 0.002657296834513545\n",
      "Epoch 1437, Loss: 0.003314739791676402\n",
      "Epoch 1438, Loss: 0.024374036118388176\n",
      "Epoch 1439, Loss: 0.021605469286441803\n",
      "Epoch 1440, Loss: 0.004013432189822197\n",
      "Epoch 1441, Loss: 0.13923613727092743\n",
      "Epoch 1442, Loss: 0.04634195566177368\n",
      "Epoch 1443, Loss: 0.08215828239917755\n",
      "Epoch 1444, Loss: 0.005285236053168774\n",
      "Epoch 1445, Loss: 0.015319625847041607\n",
      "Epoch 1446, Loss: 0.005451174918562174\n",
      "Epoch 1447, Loss: 0.02258843183517456\n",
      "Epoch 1448, Loss: 0.010478898882865906\n",
      "Epoch 1449, Loss: 0.01800926774740219\n",
      "Epoch 1450, Loss: 0.010362823493778706\n",
      "Epoch 1451, Loss: 0.04271445423364639\n",
      "Epoch 1452, Loss: 0.015310144051909447\n",
      "Epoch 1453, Loss: 0.010722565464675426\n",
      "Epoch 1454, Loss: 0.004428221844136715\n",
      "Epoch 1455, Loss: 0.012636709026992321\n",
      "Epoch 1456, Loss: 0.019123297184705734\n",
      "Epoch 1457, Loss: 0.00919573474675417\n",
      "Epoch 1458, Loss: 0.007648786064237356\n",
      "Epoch 1459, Loss: 0.0036977953277528286\n",
      "Epoch 1460, Loss: 0.0013178049121052027\n",
      "Epoch 1461, Loss: 0.01056918315589428\n",
      "Epoch 1462, Loss: 0.08998338878154755\n",
      "Epoch 1463, Loss: 0.08865529298782349\n",
      "Epoch 1464, Loss: 0.0037539980839937925\n",
      "Epoch 1465, Loss: 0.013020135462284088\n",
      "Epoch 1466, Loss: 0.00048598297871649265\n",
      "Epoch 1467, Loss: 0.027568379417061806\n",
      "Epoch 1468, Loss: 0.008743437938392162\n",
      "Epoch 1469, Loss: 0.08310532569885254\n",
      "Epoch 1470, Loss: 0.09797391295433044\n",
      "Epoch 1471, Loss: 0.06073616072535515\n",
      "Epoch 1472, Loss: 0.002376855118200183\n",
      "Epoch 1473, Loss: 0.0074292817153036594\n",
      "Epoch 1474, Loss: 0.08593963086605072\n",
      "Epoch 1475, Loss: 0.006386446766555309\n",
      "Epoch 1476, Loss: 0.04644859582185745\n",
      "Epoch 1477, Loss: 0.08329085260629654\n",
      "Epoch 1478, Loss: 0.004171203821897507\n",
      "Epoch 1479, Loss: 0.022275900468230247\n",
      "Epoch 1480, Loss: 0.00971473753452301\n",
      "Epoch 1481, Loss: 0.026783183217048645\n",
      "Epoch 1482, Loss: 0.0023423396050930023\n",
      "Epoch 1483, Loss: 0.03245171532034874\n",
      "Epoch 1484, Loss: 0.006947261746972799\n",
      "Epoch 1485, Loss: 0.001298675430007279\n",
      "Epoch 1486, Loss: 0.08471179753541946\n",
      "Epoch 1487, Loss: 0.006055653560906649\n",
      "Epoch 1488, Loss: 0.008434533141553402\n",
      "Epoch 1489, Loss: 0.023755526170134544\n",
      "Epoch 1490, Loss: 0.017844395712018013\n",
      "Epoch 1491, Loss: 0.10187836736440659\n",
      "Epoch 1492, Loss: 0.02814672887325287\n",
      "Epoch 1493, Loss: 0.007982469163835049\n",
      "Epoch 1494, Loss: 0.11418499052524567\n",
      "Epoch 1495, Loss: 0.019593294709920883\n",
      "Epoch 1496, Loss: 0.007044835947453976\n",
      "Epoch 1497, Loss: 0.008975109085440636\n",
      "Epoch 1498, Loss: 0.06125495582818985\n",
      "Epoch 1499, Loss: 0.1423311084508896\n",
      "Epoch 1500, Loss: 0.15206746757030487\n",
      "Epoch 1501, Loss: 0.027229219675064087\n",
      "Epoch 1502, Loss: 0.05600552633404732\n",
      "Epoch 1503, Loss: 0.0029041185043752193\n",
      "Epoch 1504, Loss: 0.18899090588092804\n",
      "Epoch 1505, Loss: 0.024861270561814308\n",
      "Epoch 1506, Loss: 0.00873284600675106\n",
      "Epoch 1507, Loss: 0.08251844346523285\n",
      "Epoch 1508, Loss: 0.1472204625606537\n",
      "Epoch 1509, Loss: 0.003886974649503827\n",
      "Epoch 1510, Loss: 0.1083158403635025\n",
      "Epoch 1511, Loss: 0.006170681677758694\n",
      "Epoch 1512, Loss: 0.0018516465788707137\n",
      "Epoch 1513, Loss: 0.37573671340942383\n",
      "Epoch 1514, Loss: 0.026537109166383743\n",
      "Epoch 1515, Loss: 0.008209706284105778\n",
      "Epoch 1516, Loss: 0.07881461083889008\n",
      "Epoch 1517, Loss: 0.19586069881916046\n",
      "Epoch 1518, Loss: 0.013515478000044823\n",
      "Epoch 1519, Loss: 0.00875297375023365\n",
      "Epoch 1520, Loss: 0.01820989139378071\n",
      "Epoch 1521, Loss: 0.017123311758041382\n",
      "Epoch 1522, Loss: 0.0009441973525099456\n",
      "Epoch 1523, Loss: 0.011321688070893288\n",
      "Epoch 1524, Loss: 0.005114982835948467\n",
      "Epoch 1525, Loss: 0.011005712673068047\n",
      "Epoch 1526, Loss: 0.03137290105223656\n",
      "Epoch 1527, Loss: 0.21118298172950745\n",
      "Epoch 1528, Loss: 0.08525149524211884\n",
      "Epoch 1529, Loss: 0.007945085875689983\n",
      "Epoch 1530, Loss: 0.08229761570692062\n",
      "Epoch 1531, Loss: 0.20405757427215576\n",
      "Epoch 1532, Loss: 0.010601107031106949\n",
      "Epoch 1533, Loss: 0.02516617812216282\n",
      "Epoch 1534, Loss: 0.014142712578177452\n",
      "Epoch 1535, Loss: 0.006002635695040226\n",
      "Epoch 1536, Loss: 0.22883102297782898\n",
      "Epoch 1537, Loss: 0.10643880069255829\n",
      "Epoch 1538, Loss: 0.012586826458573341\n",
      "Epoch 1539, Loss: 0.02989225648343563\n",
      "Epoch 1540, Loss: 0.004870776552706957\n",
      "Epoch 1541, Loss: 0.034487295895814896\n",
      "Epoch 1542, Loss: 0.008623969741165638\n",
      "Epoch 1543, Loss: 0.01217486523091793\n",
      "Epoch 1544, Loss: 0.12368686497211456\n",
      "Epoch 1545, Loss: 0.12227308750152588\n",
      "Epoch 1546, Loss: 0.07072640210390091\n",
      "Epoch 1547, Loss: 0.06714779138565063\n",
      "Epoch 1548, Loss: 0.1142863780260086\n",
      "Epoch 1549, Loss: 0.0004503208620008081\n",
      "Epoch 1550, Loss: 0.05441861227154732\n",
      "Epoch 1551, Loss: 0.011953824199736118\n",
      "Epoch 1552, Loss: 0.04883112758398056\n",
      "Epoch 1553, Loss: 0.00448512751609087\n",
      "Epoch 1554, Loss: 0.023976365104317665\n",
      "Epoch 1555, Loss: 0.021692361682653427\n",
      "Epoch 1556, Loss: 0.027051517739892006\n",
      "Epoch 1557, Loss: 0.004566828720271587\n",
      "Epoch 1558, Loss: 0.005487048998475075\n",
      "Epoch 1559, Loss: 0.015972185879945755\n",
      "Epoch 1560, Loss: 0.010420790873467922\n",
      "Epoch 1561, Loss: 0.07589489966630936\n",
      "Epoch 1562, Loss: 0.010290761478245258\n",
      "Epoch 1563, Loss: 0.23571202158927917\n",
      "Epoch 1564, Loss: 0.00972244143486023\n",
      "Epoch 1565, Loss: 0.061491381376981735\n",
      "Epoch 1566, Loss: 0.2987884283065796\n",
      "Epoch 1567, Loss: 0.005566779524087906\n",
      "Epoch 1568, Loss: 0.03342312574386597\n",
      "Epoch 1569, Loss: 0.01443083118647337\n",
      "Epoch 1570, Loss: 0.01111329160630703\n",
      "Epoch 1571, Loss: 0.019584324210882187\n",
      "Epoch 1572, Loss: 0.0008634418481960893\n",
      "Epoch 1573, Loss: 0.09514302015304565\n",
      "Epoch 1574, Loss: 0.019281137734651566\n",
      "Epoch 1575, Loss: 0.13497373461723328\n",
      "Epoch 1576, Loss: 0.006825996097177267\n",
      "Epoch 1577, Loss: 0.10656224191188812\n",
      "Epoch 1578, Loss: 0.0022224646527320147\n",
      "Epoch 1579, Loss: 0.009918096475303173\n",
      "Epoch 1580, Loss: 0.012346995063126087\n",
      "Epoch 1581, Loss: 0.002388159278780222\n",
      "Epoch 1582, Loss: 0.04712802544236183\n",
      "Epoch 1583, Loss: 0.11403705924749374\n",
      "Epoch 1584, Loss: 0.016445988789200783\n",
      "Epoch 1585, Loss: 0.0172116719186306\n",
      "Epoch 1586, Loss: 0.0063878572545945644\n",
      "Epoch 1587, Loss: 0.028155770152807236\n",
      "Epoch 1588, Loss: 0.016010895371437073\n",
      "Epoch 1589, Loss: 0.05267784744501114\n",
      "Epoch 1590, Loss: 0.003943746443837881\n",
      "Epoch 1591, Loss: 0.034358661621809006\n",
      "Epoch 1592, Loss: 0.10023019462823868\n",
      "Epoch 1593, Loss: 0.008671185001730919\n",
      "Epoch 1594, Loss: 0.03175976127386093\n",
      "Epoch 1595, Loss: 0.04058016464114189\n",
      "Epoch 1596, Loss: 0.21431449055671692\n",
      "Epoch 1597, Loss: 0.13556911051273346\n",
      "Epoch 1598, Loss: 0.029157286509871483\n",
      "Epoch 1599, Loss: 0.14700038731098175\n",
      "Epoch 1600, Loss: 0.01610717549920082\n",
      "Epoch 1601, Loss: 0.01723046600818634\n",
      "Epoch 1602, Loss: 0.015382081270217896\n",
      "Epoch 1603, Loss: 0.020973870530724525\n",
      "Epoch 1604, Loss: 0.057549990713596344\n",
      "Epoch 1605, Loss: 0.023003216832876205\n",
      "Epoch 1606, Loss: 0.024159874767065048\n",
      "Epoch 1607, Loss: 0.03992633521556854\n",
      "Epoch 1608, Loss: 0.01050497405230999\n",
      "Epoch 1609, Loss: 0.008915739133954048\n",
      "Epoch 1610, Loss: 0.006548169068992138\n",
      "Epoch 1611, Loss: 0.010369576513767242\n",
      "Epoch 1612, Loss: 0.02936873957514763\n",
      "Epoch 1613, Loss: 0.01693877764046192\n",
      "Epoch 1614, Loss: 0.005843945313245058\n",
      "Epoch 1615, Loss: 0.0770074874162674\n",
      "Epoch 1616, Loss: 0.2160261571407318\n",
      "Epoch 1617, Loss: 0.0010881838388741016\n",
      "Epoch 1618, Loss: 0.007602388970553875\n",
      "Epoch 1619, Loss: 0.003655325621366501\n",
      "Epoch 1620, Loss: 0.0026836064644157887\n",
      "Epoch 1621, Loss: 0.09406082332134247\n",
      "Epoch 1622, Loss: 0.0904320627450943\n",
      "Epoch 1623, Loss: 0.1213788241147995\n",
      "Epoch 1624, Loss: 0.003644211683422327\n",
      "Epoch 1625, Loss: 0.00565657764673233\n",
      "Epoch 1626, Loss: 0.015879645943641663\n",
      "Epoch 1627, Loss: 0.006873808801174164\n",
      "Epoch 1628, Loss: 0.029736265540122986\n",
      "Epoch 1629, Loss: 0.023931559175252914\n",
      "Epoch 1630, Loss: 0.06311061233282089\n",
      "Epoch 1631, Loss: 0.08342946320772171\n",
      "Epoch 1632, Loss: 0.026105541735887527\n",
      "Epoch 1633, Loss: 0.0015767620643600821\n",
      "Epoch 1634, Loss: 0.04536803439259529\n",
      "Epoch 1635, Loss: 0.004159453324973583\n",
      "Epoch 1636, Loss: 0.1360131800174713\n",
      "Epoch 1637, Loss: 0.055538348853588104\n",
      "Epoch 1638, Loss: 0.0008284740033559501\n",
      "Epoch 1639, Loss: 0.020871944725513458\n",
      "Epoch 1640, Loss: 0.17488110065460205\n",
      "Epoch 1641, Loss: 0.03696860745549202\n",
      "Epoch 1642, Loss: 0.0005392821622081101\n",
      "Epoch 1643, Loss: 0.002517151180654764\n",
      "Epoch 1644, Loss: 0.002472864231094718\n",
      "Epoch 1645, Loss: 0.004542449023574591\n",
      "Epoch 1646, Loss: 0.01465512253344059\n",
      "Epoch 1647, Loss: 0.03178878873586655\n",
      "Epoch 1648, Loss: 0.004161381162703037\n",
      "Epoch 1649, Loss: 0.10905595123767853\n",
      "Epoch 1650, Loss: 0.0005930569604970515\n",
      "Epoch 1651, Loss: 0.030263911932706833\n",
      "Epoch 1652, Loss: 0.020946143195033073\n",
      "Epoch 1653, Loss: 0.014057837426662445\n",
      "Epoch 1654, Loss: 0.01209526788443327\n",
      "Epoch 1655, Loss: 0.1663648784160614\n",
      "Epoch 1656, Loss: 0.012332827784121037\n",
      "Epoch 1657, Loss: 0.2662419080734253\n",
      "Epoch 1658, Loss: 0.010417528450489044\n",
      "Epoch 1659, Loss: 0.15319117903709412\n",
      "Epoch 1660, Loss: 0.0021230217535048723\n",
      "Epoch 1661, Loss: 0.05145580321550369\n",
      "Epoch 1662, Loss: 0.02603203058242798\n",
      "Epoch 1663, Loss: 0.004876559134572744\n",
      "Epoch 1664, Loss: 0.008861491456627846\n",
      "Epoch 1665, Loss: 0.004430487751960754\n",
      "Epoch 1666, Loss: 0.013628346845507622\n",
      "Epoch 1667, Loss: 0.01090799830853939\n",
      "Epoch 1668, Loss: 0.0035363442730158567\n",
      "Epoch 1669, Loss: 0.01184169389307499\n",
      "Epoch 1670, Loss: 0.01462317444384098\n",
      "Epoch 1671, Loss: 0.012825342826545238\n",
      "Epoch 1672, Loss: 0.010021413676440716\n",
      "Epoch 1673, Loss: 0.1037232056260109\n",
      "Epoch 1674, Loss: 0.015371492132544518\n",
      "Epoch 1675, Loss: 0.002138970186933875\n",
      "Epoch 1676, Loss: 0.016004282981157303\n",
      "Epoch 1677, Loss: 0.0008549870690330863\n",
      "Epoch 1678, Loss: 0.04156041517853737\n",
      "Epoch 1679, Loss: 0.006938569247722626\n",
      "Epoch 1680, Loss: 0.006973684765398502\n",
      "Epoch 1681, Loss: 0.09372000396251678\n",
      "Epoch 1682, Loss: 0.0012802460696548223\n",
      "Epoch 1683, Loss: 0.010269406251609325\n",
      "Epoch 1684, Loss: 0.041809991002082825\n",
      "Epoch 1685, Loss: 0.003997128456830978\n",
      "Epoch 1686, Loss: 0.001766039291396737\n",
      "Epoch 1687, Loss: 0.00630516791716218\n",
      "Epoch 1688, Loss: 0.026408731937408447\n",
      "Epoch 1689, Loss: 0.004725026432424784\n",
      "Epoch 1690, Loss: 0.05384799838066101\n",
      "Epoch 1691, Loss: 0.4084760248661041\n",
      "Epoch 1692, Loss: 0.019329166039824486\n",
      "Epoch 1693, Loss: 0.0037551354616880417\n",
      "Epoch 1694, Loss: 0.00867646373808384\n",
      "Epoch 1695, Loss: 0.00833187811076641\n",
      "Epoch 1696, Loss: 0.005441664718091488\n",
      "Epoch 1697, Loss: 0.03820313513278961\n",
      "Epoch 1698, Loss: 0.017740439623594284\n",
      "Epoch 1699, Loss: 0.007047710008919239\n",
      "Epoch 1700, Loss: 0.016067486256361008\n",
      "Epoch 1701, Loss: 0.024175379425287247\n",
      "Epoch 1702, Loss: 0.013167791068553925\n",
      "Epoch 1703, Loss: 0.014378544874489307\n",
      "Epoch 1704, Loss: 0.01985657401382923\n",
      "Epoch 1705, Loss: 0.18439511954784393\n",
      "Epoch 1706, Loss: 0.02991456724703312\n",
      "Epoch 1707, Loss: 0.00628676638007164\n",
      "Epoch 1708, Loss: 0.019892549142241478\n",
      "Epoch 1709, Loss: 0.015978321433067322\n",
      "Epoch 1710, Loss: 0.2647099494934082\n",
      "Epoch 1711, Loss: 0.0018050465732812881\n",
      "Epoch 1712, Loss: 0.09024650603532791\n",
      "Epoch 1713, Loss: 0.17656666040420532\n",
      "Epoch 1714, Loss: 0.11609940230846405\n",
      "Epoch 1715, Loss: 0.14250245690345764\n",
      "Epoch 1716, Loss: 0.12892863154411316\n",
      "Epoch 1717, Loss: 0.022265952080488205\n",
      "Epoch 1718, Loss: 0.02066635526716709\n",
      "Epoch 1719, Loss: 0.009733782149851322\n",
      "Epoch 1720, Loss: 0.014962578192353249\n",
      "Epoch 1721, Loss: 0.16759207844734192\n",
      "Epoch 1722, Loss: 0.027384957298636436\n",
      "Epoch 1723, Loss: 0.003948034718632698\n",
      "Epoch 1724, Loss: 0.0026653301902115345\n",
      "Epoch 1725, Loss: 0.08257656544446945\n",
      "Epoch 1726, Loss: 0.001355937565676868\n",
      "Epoch 1727, Loss: 0.05564846843481064\n",
      "Epoch 1728, Loss: 0.00556734437122941\n",
      "Epoch 1729, Loss: 0.005954802501946688\n",
      "Epoch 1730, Loss: 0.03400670737028122\n",
      "Epoch 1731, Loss: 0.12049254029989243\n",
      "Epoch 1732, Loss: 0.10287918895483017\n",
      "Epoch 1733, Loss: 0.008155161514878273\n",
      "Epoch 1734, Loss: 0.0034881127066910267\n",
      "Epoch 1735, Loss: 0.0030908375047147274\n",
      "Epoch 1736, Loss: 0.017764415591955185\n",
      "Epoch 1737, Loss: 0.025825832039117813\n",
      "Epoch 1738, Loss: 0.0036746268160641193\n",
      "Epoch 1739, Loss: 0.004626271314918995\n",
      "Epoch 1740, Loss: 0.08891589194536209\n",
      "Epoch 1741, Loss: 0.0020879723597317934\n",
      "Epoch 1742, Loss: 0.012387449853122234\n",
      "Epoch 1743, Loss: 0.0646079033613205\n",
      "Epoch 1744, Loss: 0.017879623919725418\n",
      "Epoch 1745, Loss: 0.1060524731874466\n",
      "Epoch 1746, Loss: 0.08611692488193512\n",
      "Epoch 1747, Loss: 0.046992383897304535\n",
      "Epoch 1748, Loss: 0.0051146321929991245\n",
      "Epoch 1749, Loss: 0.06142113357782364\n",
      "Epoch 1750, Loss: 0.06703011691570282\n",
      "Epoch 1751, Loss: 0.02271389774978161\n",
      "Epoch 1752, Loss: 0.014943204820156097\n",
      "Epoch 1753, Loss: 0.012547513470053673\n",
      "Epoch 1754, Loss: 0.12064068019390106\n",
      "Epoch 1755, Loss: 0.019013062119483948\n",
      "Epoch 1756, Loss: 0.024517497047781944\n",
      "Epoch 1757, Loss: 0.012637190520763397\n",
      "Epoch 1758, Loss: 0.03496907651424408\n",
      "Epoch 1759, Loss: 0.028533894568681717\n",
      "Epoch 1760, Loss: 0.1682976931333542\n",
      "Epoch 1761, Loss: 0.047617729753255844\n",
      "Epoch 1762, Loss: 0.07511129230260849\n",
      "Epoch 1763, Loss: 0.005257931537926197\n",
      "Epoch 1764, Loss: 0.09466936439275742\n",
      "Epoch 1765, Loss: 0.011362288147211075\n",
      "Epoch 1766, Loss: 0.020971592515707016\n",
      "Epoch 1767, Loss: 0.009442818351089954\n",
      "Epoch 1768, Loss: 0.0037311601918190718\n",
      "Epoch 1769, Loss: 0.0038352455012500286\n",
      "Epoch 1770, Loss: 0.019936660304665565\n",
      "Epoch 1771, Loss: 0.001048776670359075\n",
      "Epoch 1772, Loss: 0.04196222871541977\n",
      "Epoch 1773, Loss: 0.0018047118792310357\n",
      "Epoch 1774, Loss: 0.033851154148578644\n",
      "Epoch 1775, Loss: 0.008489456959068775\n",
      "Epoch 1776, Loss: 0.22326648235321045\n",
      "Epoch 1777, Loss: 0.029303651303052902\n",
      "Epoch 1778, Loss: 0.3461739122867584\n",
      "Epoch 1779, Loss: 0.005565250758081675\n",
      "Epoch 1780, Loss: 0.01317320205271244\n",
      "Epoch 1781, Loss: 0.01025434024631977\n",
      "Epoch 1782, Loss: 0.04765620082616806\n",
      "Epoch 1783, Loss: 0.127825528383255\n",
      "Epoch 1784, Loss: 0.21144405007362366\n",
      "Epoch 1785, Loss: 0.00926741398870945\n",
      "Epoch 1786, Loss: 0.0026824306696653366\n",
      "Epoch 1787, Loss: 0.10400532186031342\n",
      "Epoch 1788, Loss: 0.0013539601350203156\n",
      "Epoch 1789, Loss: 0.1579069197177887\n",
      "Epoch 1790, Loss: 0.05406569689512253\n",
      "Epoch 1791, Loss: 0.09159497916698456\n",
      "Epoch 1792, Loss: 0.15241925418376923\n",
      "Epoch 1793, Loss: 0.001705431379377842\n",
      "Epoch 1794, Loss: 0.023691650480031967\n",
      "Epoch 1795, Loss: 0.013173140585422516\n",
      "Epoch 1796, Loss: 0.18310655653476715\n",
      "Epoch 1797, Loss: 0.09122072160243988\n",
      "Epoch 1798, Loss: 0.05625941604375839\n",
      "Epoch 1799, Loss: 0.12270838022232056\n",
      "Epoch 1800, Loss: 0.009202351793646812\n",
      "Epoch 1801, Loss: 0.007126416079699993\n",
      "Epoch 1802, Loss: 0.11518885940313339\n",
      "Epoch 1803, Loss: 0.005201324820518494\n",
      "Epoch 1804, Loss: 0.060439467430114746\n",
      "Epoch 1805, Loss: 0.05769002437591553\n",
      "Epoch 1806, Loss: 0.031953856348991394\n",
      "Epoch 1807, Loss: 0.01045508123934269\n",
      "Epoch 1808, Loss: 0.02980303391814232\n",
      "Epoch 1809, Loss: 0.12382857501506805\n",
      "Epoch 1810, Loss: 0.015407023020088673\n",
      "Epoch 1811, Loss: 0.014278141781687737\n",
      "Epoch 1812, Loss: 0.002566652838140726\n",
      "Epoch 1813, Loss: 0.0009763273410499096\n",
      "Epoch 1814, Loss: 0.04007077217102051\n",
      "Epoch 1815, Loss: 0.17886659502983093\n",
      "Epoch 1816, Loss: 0.0052753714844584465\n",
      "Epoch 1817, Loss: 0.0068582757376134396\n",
      "Epoch 1818, Loss: 0.0055363052524626255\n",
      "Epoch 1819, Loss: 0.029595408588647842\n",
      "Epoch 1820, Loss: 0.007768754847347736\n",
      "Epoch 1821, Loss: 0.33341580629348755\n",
      "Epoch 1822, Loss: 0.02261456847190857\n",
      "Epoch 1823, Loss: 0.06688851118087769\n",
      "Epoch 1824, Loss: 0.10182131826877594\n",
      "Epoch 1825, Loss: 0.017267007380723953\n",
      "Epoch 1826, Loss: 0.005785358138382435\n",
      "Epoch 1827, Loss: 0.018228206783533096\n",
      "Epoch 1828, Loss: 0.004981557838618755\n",
      "Epoch 1829, Loss: 0.0720357745885849\n",
      "Epoch 1830, Loss: 0.012509752996265888\n",
      "Epoch 1831, Loss: 0.07970656454563141\n",
      "Epoch 1832, Loss: 0.1250561624765396\n",
      "Epoch 1833, Loss: 0.020946484059095383\n",
      "Epoch 1834, Loss: 0.08430632948875427\n",
      "Epoch 1835, Loss: 0.015644807368516922\n",
      "Epoch 1836, Loss: 0.004040286876261234\n",
      "Epoch 1837, Loss: 0.009375291876494884\n",
      "Epoch 1838, Loss: 0.10843002796173096\n",
      "Epoch 1839, Loss: 0.016375696286559105\n",
      "Epoch 1840, Loss: 0.06292290985584259\n",
      "Epoch 1841, Loss: 0.0018041711300611496\n",
      "Epoch 1842, Loss: 0.008947348222136497\n",
      "Epoch 1843, Loss: 0.15241822600364685\n",
      "Epoch 1844, Loss: 0.025059204548597336\n",
      "Epoch 1845, Loss: 0.2908400595188141\n",
      "Epoch 1846, Loss: 0.11531949043273926\n",
      "Epoch 1847, Loss: 0.013026595115661621\n",
      "Epoch 1848, Loss: 0.09473715722560883\n",
      "Epoch 1849, Loss: 0.004042383283376694\n",
      "Epoch 1850, Loss: 0.008219845592975616\n",
      "Epoch 1851, Loss: 0.022956829518079758\n",
      "Epoch 1852, Loss: 0.01560676097869873\n",
      "Epoch 1853, Loss: 0.021681642159819603\n",
      "Epoch 1854, Loss: 0.03225330635905266\n",
      "Epoch 1855, Loss: 4.447703031473793e-05\n",
      "Epoch 1856, Loss: 0.06408296525478363\n",
      "Epoch 1857, Loss: 0.10605257749557495\n",
      "Epoch 1858, Loss: 0.018356595188379288\n",
      "Epoch 1859, Loss: 0.21831277012825012\n",
      "Epoch 1860, Loss: 0.08131431043148041\n",
      "Epoch 1861, Loss: 0.3404638171195984\n",
      "Epoch 1862, Loss: 0.018176008015871048\n",
      "Epoch 1863, Loss: 0.0039200978353619576\n",
      "Epoch 1864, Loss: 0.006635844707489014\n",
      "Epoch 1865, Loss: 0.03495392948389053\n",
      "Epoch 1866, Loss: 0.06521809101104736\n",
      "Epoch 1867, Loss: 0.018568776547908783\n",
      "Epoch 1868, Loss: 0.012375506572425365\n",
      "Epoch 1869, Loss: 0.034454453736543655\n",
      "Epoch 1870, Loss: 0.004859319422394037\n",
      "Epoch 1871, Loss: 0.019806046038866043\n",
      "Epoch 1872, Loss: 0.006132571026682854\n",
      "Epoch 1873, Loss: 0.026291361078619957\n",
      "Epoch 1874, Loss: 0.021063338965177536\n",
      "Epoch 1875, Loss: 0.10090234130620956\n",
      "Epoch 1876, Loss: 0.01769101247191429\n",
      "Epoch 1877, Loss: 0.009621392004191875\n",
      "Epoch 1878, Loss: 0.009381887502968311\n",
      "Epoch 1879, Loss: 0.01605275645852089\n",
      "Epoch 1880, Loss: 0.10078857839107513\n",
      "Epoch 1881, Loss: 0.03927937150001526\n",
      "Epoch 1882, Loss: 0.05157681554555893\n",
      "Epoch 1883, Loss: 0.1261691451072693\n",
      "Epoch 1884, Loss: 0.00876647885888815\n",
      "Epoch 1885, Loss: 0.015687858685851097\n",
      "Epoch 1886, Loss: 0.014164688996970654\n",
      "Epoch 1887, Loss: 0.05688276141881943\n",
      "Epoch 1888, Loss: 0.016625480726361275\n",
      "Epoch 1889, Loss: 0.07116611301898956\n",
      "Epoch 1890, Loss: 0.0850321501493454\n",
      "Epoch 1891, Loss: 0.15825824439525604\n",
      "Epoch 1892, Loss: 0.03961686044931412\n",
      "Epoch 1893, Loss: 0.09807825833559036\n",
      "Epoch 1894, Loss: 0.08831284195184708\n",
      "Epoch 1895, Loss: 0.261031836271286\n",
      "Epoch 1896, Loss: 0.0023997598327696323\n",
      "Epoch 1897, Loss: 0.0016826275968924165\n",
      "Epoch 1898, Loss: 0.007814706303179264\n",
      "Epoch 1899, Loss: 0.07296804338693619\n",
      "Epoch 1900, Loss: 0.0004124300612602383\n",
      "Epoch 1901, Loss: 0.005551712121814489\n",
      "Epoch 1902, Loss: 0.026149366050958633\n",
      "Epoch 1903, Loss: 0.05837015062570572\n",
      "Epoch 1904, Loss: 0.0009427131153643131\n",
      "Epoch 1905, Loss: 0.007886059582233429\n",
      "Epoch 1906, Loss: 0.02147850953042507\n",
      "Epoch 1907, Loss: 0.0021749543957412243\n",
      "Epoch 1908, Loss: 0.004843011032789946\n",
      "Epoch 1909, Loss: 0.09952544420957565\n",
      "Epoch 1910, Loss: 0.013401043601334095\n",
      "Epoch 1911, Loss: 0.007996056228876114\n",
      "Epoch 1912, Loss: 0.01006553415209055\n",
      "Epoch 1913, Loss: 0.02560078725218773\n",
      "Epoch 1914, Loss: 0.004484109580516815\n",
      "Epoch 1915, Loss: 0.003658779663965106\n",
      "Epoch 1916, Loss: 0.014663457870483398\n",
      "Epoch 1917, Loss: 0.04001285135746002\n",
      "Epoch 1918, Loss: 0.3706827163696289\n",
      "Epoch 1919, Loss: 0.3632104992866516\n",
      "Epoch 1920, Loss: 0.026825204491615295\n",
      "Epoch 1921, Loss: 0.006341924425214529\n",
      "Epoch 1922, Loss: 0.011785460636019707\n",
      "Epoch 1923, Loss: 0.057392917573451996\n",
      "Epoch 1924, Loss: 0.011028770357370377\n",
      "Epoch 1925, Loss: 0.004100116901099682\n",
      "Epoch 1926, Loss: 0.0601036436855793\n",
      "Epoch 1927, Loss: 0.01391156017780304\n",
      "Epoch 1928, Loss: 0.3233932852745056\n",
      "Epoch 1929, Loss: 0.0013108993880450726\n",
      "Epoch 1930, Loss: 0.012176590040326118\n",
      "Epoch 1931, Loss: 0.002434034366160631\n",
      "Epoch 1932, Loss: 0.0278845876455307\n",
      "Epoch 1933, Loss: 0.004227283410727978\n",
      "Epoch 1934, Loss: 0.009885972365736961\n",
      "Epoch 1935, Loss: 0.014959459193050861\n",
      "Epoch 1936, Loss: 0.028322696685791016\n",
      "Epoch 1937, Loss: 0.008445192128419876\n",
      "Epoch 1938, Loss: 0.017825255170464516\n",
      "Epoch 1939, Loss: 0.02046199142932892\n",
      "Epoch 1940, Loss: 0.003193262964487076\n",
      "Epoch 1941, Loss: 0.011696270667016506\n",
      "Epoch 1942, Loss: 0.002480675932019949\n",
      "Epoch 1943, Loss: 0.016032541170716286\n",
      "Epoch 1944, Loss: 0.0019398160511627793\n",
      "Epoch 1945, Loss: 0.017848316580057144\n",
      "Epoch 1946, Loss: 0.006194290705025196\n",
      "Epoch 1947, Loss: 0.009339623153209686\n",
      "Epoch 1948, Loss: 0.00456895912066102\n",
      "Epoch 1949, Loss: 0.01874460093677044\n",
      "Epoch 1950, Loss: 0.012312104925513268\n",
      "Epoch 1951, Loss: 0.007233918644487858\n",
      "Epoch 1952, Loss: 0.0009220067295245826\n",
      "Epoch 1953, Loss: 0.007166162133216858\n",
      "Epoch 1954, Loss: 0.019567709416151047\n",
      "Epoch 1955, Loss: 0.04008673131465912\n",
      "Epoch 1956, Loss: 0.05889609456062317\n",
      "Epoch 1957, Loss: 0.033409833908081055\n",
      "Epoch 1958, Loss: 0.011010118760168552\n",
      "Epoch 1959, Loss: 0.005495036952197552\n",
      "Epoch 1960, Loss: 0.009531913325190544\n",
      "Epoch 1961, Loss: 0.0037054470740258694\n",
      "Epoch 1962, Loss: 0.041911981999874115\n",
      "Epoch 1963, Loss: 0.12763722240924835\n",
      "Epoch 1964, Loss: 0.012004903517663479\n",
      "Epoch 1965, Loss: 0.004225099924951792\n",
      "Epoch 1966, Loss: 0.0888945534825325\n",
      "Epoch 1967, Loss: 0.0027006142772734165\n",
      "Epoch 1968, Loss: 0.08471658080816269\n",
      "Epoch 1969, Loss: 0.0066804648377001286\n",
      "Epoch 1970, Loss: 0.03270481526851654\n",
      "Epoch 1971, Loss: 0.007951488718390465\n",
      "Epoch 1972, Loss: 0.04875926300883293\n",
      "Epoch 1973, Loss: 0.08502878248691559\n",
      "Epoch 1974, Loss: 0.0024077175185084343\n",
      "Epoch 1975, Loss: 0.016811812296509743\n",
      "Epoch 1976, Loss: 0.1311568021774292\n",
      "Epoch 1977, Loss: 0.01796066015958786\n",
      "Epoch 1978, Loss: 0.02992207743227482\n",
      "Epoch 1979, Loss: 0.00808456540107727\n",
      "Epoch 1980, Loss: 0.014066780917346478\n",
      "Epoch 1981, Loss: 0.0019867669325321913\n",
      "Epoch 1982, Loss: 0.0169012900441885\n",
      "Epoch 1983, Loss: 0.01986062154173851\n",
      "Epoch 1984, Loss: 0.0636296197772026\n",
      "Epoch 1985, Loss: 0.017994096502661705\n",
      "Epoch 1986, Loss: 0.039730388671159744\n",
      "Epoch 1987, Loss: 0.10681407153606415\n",
      "Epoch 1988, Loss: 0.3302348256111145\n",
      "Epoch 1989, Loss: 0.024244079366326332\n",
      "Epoch 1990, Loss: 0.0028348162304610014\n",
      "Epoch 1991, Loss: 0.015486168675124645\n",
      "Epoch 1992, Loss: 0.021421309560537338\n",
      "Epoch 1993, Loss: 0.009182317182421684\n",
      "Epoch 1994, Loss: 0.0016428027302026749\n",
      "Epoch 1995, Loss: 0.0006780568510293961\n",
      "Epoch 1996, Loss: 0.0030054233502596617\n",
      "Epoch 1997, Loss: 0.37367284297943115\n",
      "Epoch 1998, Loss: 0.01632525958120823\n",
      "Epoch 1999, Loss: 0.0015964312478899956\n",
      "Epoch 2000, Loss: 0.010602586902678013\n",
      "Epoch 2001, Loss: 0.007249412592500448\n",
      "Epoch 2002, Loss: 0.060740482062101364\n",
      "Epoch 2003, Loss: 0.013230954296886921\n",
      "Epoch 2004, Loss: 0.015081122517585754\n",
      "Epoch 2005, Loss: 0.005236858502030373\n",
      "Epoch 2006, Loss: 0.02443547733128071\n",
      "Epoch 2007, Loss: 0.08319374918937683\n",
      "Epoch 2008, Loss: 0.014012505300343037\n",
      "Epoch 2009, Loss: 0.019568651914596558\n",
      "Epoch 2010, Loss: 0.006480696145445108\n",
      "Epoch 2011, Loss: 0.21159836649894714\n",
      "Epoch 2012, Loss: 0.07356544584035873\n",
      "Epoch 2013, Loss: 0.002663565566763282\n",
      "Epoch 2014, Loss: 0.017043864354491234\n",
      "Epoch 2015, Loss: 0.006765076424926519\n",
      "Epoch 2016, Loss: 0.01070334855467081\n",
      "Epoch 2017, Loss: 0.04377980902791023\n",
      "Epoch 2018, Loss: 0.009939673356711864\n",
      "Epoch 2019, Loss: 0.010348859243094921\n",
      "Epoch 2020, Loss: 0.008784410543739796\n",
      "Epoch 2021, Loss: 0.007164663169533014\n",
      "Epoch 2022, Loss: 0.040392592549324036\n",
      "Epoch 2023, Loss: 0.08739504963159561\n",
      "Epoch 2024, Loss: 0.0863916203379631\n",
      "Epoch 2025, Loss: 0.005423349794000387\n",
      "Epoch 2026, Loss: 0.014928492717444897\n",
      "Epoch 2027, Loss: 0.01705940067768097\n",
      "Epoch 2028, Loss: 0.25066661834716797\n",
      "Epoch 2029, Loss: 0.01225290633738041\n",
      "Epoch 2030, Loss: 0.02990100346505642\n",
      "Epoch 2031, Loss: 0.029049212113022804\n",
      "Epoch 2032, Loss: 0.004898198880255222\n",
      "Epoch 2033, Loss: 0.001254270551726222\n",
      "Epoch 2034, Loss: 0.0032542026601731777\n",
      "Epoch 2035, Loss: 0.07655937224626541\n",
      "Epoch 2036, Loss: 0.016245698556303978\n",
      "Epoch 2037, Loss: 0.034154582768678665\n",
      "Epoch 2038, Loss: 0.021414006128907204\n",
      "Epoch 2039, Loss: 0.013595757074654102\n",
      "Epoch 2040, Loss: 0.00975064653903246\n",
      "Epoch 2041, Loss: 0.01916145347058773\n",
      "Epoch 2042, Loss: 0.04524612054228783\n",
      "Epoch 2043, Loss: 0.019327562302350998\n",
      "Epoch 2044, Loss: 0.028788913041353226\n",
      "Epoch 2045, Loss: 0.0010954586323350668\n",
      "Epoch 2046, Loss: 0.014695828780531883\n",
      "Epoch 2047, Loss: 0.015590590424835682\n",
      "Epoch 2048, Loss: 0.005217086058109999\n",
      "Epoch 2049, Loss: 0.0913691446185112\n",
      "Epoch 2050, Loss: 0.07819125801324844\n",
      "Epoch 2051, Loss: 0.1331091672182083\n",
      "Epoch 2052, Loss: 0.009513930417597294\n",
      "Epoch 2053, Loss: 0.14399954676628113\n",
      "Epoch 2054, Loss: 0.1619369238615036\n",
      "Epoch 2055, Loss: 0.05569980666041374\n",
      "Epoch 2056, Loss: 0.024212418124079704\n",
      "Epoch 2057, Loss: 0.023071665316820145\n",
      "Epoch 2058, Loss: 0.34520432353019714\n",
      "Epoch 2059, Loss: 0.004522240255028009\n",
      "Epoch 2060, Loss: 0.032816991209983826\n",
      "Epoch 2061, Loss: 0.026142096146941185\n",
      "Epoch 2062, Loss: 0.0032802093774080276\n",
      "Epoch 2063, Loss: 0.04421105608344078\n",
      "Epoch 2064, Loss: 0.0020931106992065907\n",
      "Epoch 2065, Loss: 0.09590014070272446\n",
      "Epoch 2066, Loss: 0.027290189638733864\n",
      "Epoch 2067, Loss: 0.005869057960808277\n",
      "Epoch 2068, Loss: 0.0036591265816241503\n",
      "Epoch 2069, Loss: 0.05993477255105972\n",
      "Epoch 2070, Loss: 0.11168871074914932\n",
      "Epoch 2071, Loss: 0.010324982926249504\n",
      "Epoch 2072, Loss: 0.016504734754562378\n",
      "Epoch 2073, Loss: 0.10639443248510361\n",
      "Epoch 2074, Loss: 0.0018951345700770617\n",
      "Epoch 2075, Loss: 0.0033557177521288395\n",
      "Epoch 2076, Loss: 0.020117243751883507\n",
      "Epoch 2077, Loss: 0.03169110789895058\n",
      "Epoch 2078, Loss: 0.08224542438983917\n",
      "Epoch 2079, Loss: 0.09983991831541061\n",
      "Epoch 2080, Loss: 0.0031097878236323595\n",
      "Epoch 2081, Loss: 0.19406963884830475\n",
      "Epoch 2082, Loss: 0.02621028944849968\n",
      "Epoch 2083, Loss: 0.022684110328555107\n",
      "Epoch 2084, Loss: 0.017403170466423035\n",
      "Epoch 2085, Loss: 0.012185325846076012\n",
      "Epoch 2086, Loss: 0.003858479904010892\n",
      "Epoch 2087, Loss: 0.14306840300559998\n",
      "Epoch 2088, Loss: 0.0016434898134320974\n",
      "Epoch 2089, Loss: 0.21018266677856445\n",
      "Epoch 2090, Loss: 0.10140778869390488\n",
      "Epoch 2091, Loss: 0.014484541490674019\n",
      "Epoch 2092, Loss: 0.02205398678779602\n",
      "Epoch 2093, Loss: 0.007431956473737955\n",
      "Epoch 2094, Loss: 0.015794258564710617\n",
      "Epoch 2095, Loss: 0.011384046636521816\n",
      "Epoch 2096, Loss: 0.012560518458485603\n",
      "Epoch 2097, Loss: 0.01358420867472887\n",
      "Epoch 2098, Loss: 0.009761633351445198\n",
      "Epoch 2099, Loss: 0.019417397677898407\n",
      "Epoch 2100, Loss: 0.014191405847668648\n",
      "Epoch 2101, Loss: 0.01502595841884613\n",
      "Epoch 2102, Loss: 0.005802457686513662\n",
      "Epoch 2103, Loss: 0.00960414670407772\n",
      "Epoch 2104, Loss: 0.03813104331493378\n",
      "Epoch 2105, Loss: 0.015025632455945015\n",
      "Epoch 2106, Loss: 0.024119779467582703\n",
      "Epoch 2107, Loss: 0.0002963642473332584\n",
      "Epoch 2108, Loss: 0.0011978521943092346\n",
      "Epoch 2109, Loss: 0.015615740790963173\n",
      "Epoch 2110, Loss: 0.0028449781239032745\n",
      "Epoch 2111, Loss: 0.025043437257409096\n",
      "Epoch 2112, Loss: 0.0157074723392725\n",
      "Epoch 2113, Loss: 0.020144611597061157\n",
      "Epoch 2114, Loss: 0.1370486468076706\n",
      "Epoch 2115, Loss: 0.0010112316813319921\n",
      "Epoch 2116, Loss: 0.01131079625338316\n",
      "Epoch 2117, Loss: 0.14947377145290375\n",
      "Epoch 2118, Loss: 0.002306701149791479\n",
      "Epoch 2119, Loss: 0.09478164464235306\n",
      "Epoch 2120, Loss: 0.017072303220629692\n",
      "Epoch 2121, Loss: 0.0742352157831192\n",
      "Epoch 2122, Loss: 0.018330959603190422\n",
      "Epoch 2123, Loss: 0.10142733156681061\n",
      "Epoch 2124, Loss: 0.016425106674432755\n",
      "Epoch 2125, Loss: 0.0020443350076675415\n",
      "Epoch 2126, Loss: 0.02901720069348812\n",
      "Epoch 2127, Loss: 0.1063593253493309\n",
      "Epoch 2128, Loss: 0.04350259527564049\n",
      "Epoch 2129, Loss: 0.0636412650346756\n",
      "Epoch 2130, Loss: 0.10614925622940063\n",
      "Epoch 2131, Loss: 0.0027569292578846216\n",
      "Epoch 2132, Loss: 0.1339729130268097\n",
      "Epoch 2133, Loss: 0.0193591620773077\n",
      "Epoch 2134, Loss: 0.0012507943902164698\n",
      "Epoch 2135, Loss: 0.04066542536020279\n",
      "Epoch 2136, Loss: 0.0008435336640104651\n",
      "Epoch 2137, Loss: 0.013792512007057667\n",
      "Epoch 2138, Loss: 0.2223188430070877\n",
      "Epoch 2139, Loss: 0.012861895374953747\n",
      "Epoch 2140, Loss: 0.009234878234565258\n",
      "Epoch 2141, Loss: 0.01971384324133396\n",
      "Epoch 2142, Loss: 0.009639313444495201\n",
      "Epoch 2143, Loss: 0.037601880729198456\n",
      "Epoch 2144, Loss: 0.004150792490690947\n",
      "Epoch 2145, Loss: 0.025307659059762955\n",
      "Epoch 2146, Loss: 0.015468272380530834\n",
      "Epoch 2147, Loss: 0.20143325626850128\n",
      "Epoch 2148, Loss: 0.0022383020259439945\n",
      "Epoch 2149, Loss: 0.23217394948005676\n",
      "Epoch 2150, Loss: 0.0033908996265381575\n",
      "Epoch 2151, Loss: 0.010516098700463772\n",
      "Epoch 2152, Loss: 0.06072169542312622\n",
      "Epoch 2153, Loss: 0.1561652421951294\n",
      "Epoch 2154, Loss: 0.003329367144033313\n",
      "Epoch 2155, Loss: 0.05890260264277458\n",
      "Epoch 2156, Loss: 0.1683245301246643\n",
      "Epoch 2157, Loss: 0.0034332838840782642\n",
      "Epoch 2158, Loss: 0.015403320081532001\n",
      "Epoch 2159, Loss: 0.13132087886333466\n",
      "Epoch 2160, Loss: 0.023399386554956436\n",
      "Epoch 2161, Loss: 0.18592867255210876\n",
      "Epoch 2162, Loss: 0.007330069784075022\n",
      "Epoch 2163, Loss: 0.010210508480668068\n",
      "Epoch 2164, Loss: 0.02484409511089325\n",
      "Epoch 2165, Loss: 0.0065279132686555386\n",
      "Epoch 2166, Loss: 0.01971760205924511\n",
      "Epoch 2167, Loss: 0.014683288522064686\n",
      "Epoch 2168, Loss: 0.002733255038037896\n",
      "Epoch 2169, Loss: 0.011055794544517994\n",
      "Epoch 2170, Loss: 0.014035247266292572\n",
      "Epoch 2171, Loss: 0.0033840960822999477\n",
      "Epoch 2172, Loss: 0.059954605996608734\n",
      "Epoch 2173, Loss: 0.10217531025409698\n",
      "Epoch 2174, Loss: 0.21252968907356262\n",
      "Epoch 2175, Loss: 0.16190215945243835\n",
      "Epoch 2176, Loss: 0.02418157458305359\n",
      "Epoch 2177, Loss: 0.0016355339903384447\n",
      "Epoch 2178, Loss: 0.001501463702879846\n",
      "Epoch 2179, Loss: 0.017665382474660873\n",
      "Epoch 2180, Loss: 0.05070113390684128\n",
      "Epoch 2181, Loss: 0.02488662488758564\n",
      "Epoch 2182, Loss: 0.010576523840427399\n",
      "Epoch 2183, Loss: 0.33143699169158936\n",
      "Epoch 2184, Loss: 0.047882262617349625\n",
      "Epoch 2185, Loss: 0.00803721509873867\n",
      "Epoch 2186, Loss: 0.006923125125467777\n",
      "Epoch 2187, Loss: 0.003179817693307996\n",
      "Epoch 2188, Loss: 0.009607043117284775\n",
      "Epoch 2189, Loss: 0.01082079578191042\n",
      "Epoch 2190, Loss: 0.010081917978823185\n",
      "Epoch 2191, Loss: 0.02073424495756626\n",
      "Epoch 2192, Loss: 0.1662905514240265\n",
      "Epoch 2193, Loss: 0.018356770277023315\n",
      "Epoch 2194, Loss: 0.006057266611605883\n",
      "Epoch 2195, Loss: 0.017427215352654457\n",
      "Epoch 2196, Loss: 0.011738666333258152\n",
      "Epoch 2197, Loss: 0.01964591257274151\n",
      "Epoch 2198, Loss: 0.014014510437846184\n",
      "Epoch 2199, Loss: 0.5179418325424194\n",
      "Epoch 2200, Loss: 0.006684771738946438\n",
      "Epoch 2201, Loss: 0.0034980173222720623\n",
      "Epoch 2202, Loss: 0.01272668968886137\n",
      "Epoch 2203, Loss: 0.0007061593933030963\n",
      "Epoch 2204, Loss: 0.0019603497348725796\n",
      "Epoch 2205, Loss: 0.004343707580119371\n",
      "Epoch 2206, Loss: 0.033527664840221405\n",
      "Epoch 2207, Loss: 0.016242319718003273\n",
      "Epoch 2208, Loss: 0.04522877186536789\n",
      "Epoch 2209, Loss: 0.004013988189399242\n",
      "Epoch 2210, Loss: 0.09556977450847626\n",
      "Epoch 2211, Loss: 0.31376177072525024\n",
      "Epoch 2212, Loss: 0.011239895597100258\n",
      "Epoch 2213, Loss: 0.006285971961915493\n",
      "Epoch 2214, Loss: 0.004102566745132208\n",
      "Epoch 2215, Loss: 0.003360990434885025\n",
      "Epoch 2216, Loss: 0.017555680125951767\n",
      "Epoch 2217, Loss: 0.023148857057094574\n",
      "Epoch 2218, Loss: 0.06865926086902618\n",
      "Epoch 2219, Loss: 0.03255556523799896\n",
      "Epoch 2220, Loss: 0.004246643744409084\n",
      "Epoch 2221, Loss: 0.17982396483421326\n",
      "Epoch 2222, Loss: 0.025020781904459\n",
      "Epoch 2223, Loss: 0.0008877141517587006\n",
      "Epoch 2224, Loss: 0.0009061897289939225\n",
      "Epoch 2225, Loss: 0.008697830140590668\n",
      "Epoch 2226, Loss: 0.014203486032783985\n",
      "Epoch 2227, Loss: 0.3162151575088501\n",
      "Epoch 2228, Loss: 0.013743956573307514\n",
      "Epoch 2229, Loss: 0.02504778280854225\n",
      "Epoch 2230, Loss: 0.026120368391275406\n",
      "Epoch 2231, Loss: 0.05222058296203613\n",
      "Epoch 2232, Loss: 0.02429121360182762\n",
      "Epoch 2233, Loss: 0.012715521268546581\n",
      "Epoch 2234, Loss: 0.0006669580470770597\n",
      "Epoch 2235, Loss: 0.005840328522026539\n",
      "Epoch 2236, Loss: 0.005273235030472279\n",
      "Epoch 2237, Loss: 0.01731407642364502\n",
      "Epoch 2238, Loss: 0.02249087765812874\n",
      "Epoch 2239, Loss: 0.00794234313070774\n",
      "Epoch 2240, Loss: 0.08490615338087082\n",
      "Epoch 2241, Loss: 0.002378788311034441\n",
      "Epoch 2242, Loss: 0.2396770715713501\n",
      "Epoch 2243, Loss: 0.012074267491698265\n",
      "Epoch 2244, Loss: 0.016234425827860832\n",
      "Epoch 2245, Loss: 0.005377976223826408\n",
      "Epoch 2246, Loss: 0.031182125210762024\n",
      "Epoch 2247, Loss: 0.02635006047785282\n",
      "Epoch 2248, Loss: 0.01646316424012184\n",
      "Epoch 2249, Loss: 0.0021407082676887512\n",
      "Epoch 2250, Loss: 0.2326744794845581\n",
      "Epoch 2251, Loss: 0.0508752278983593\n",
      "Epoch 2252, Loss: 0.0038601085543632507\n",
      "Epoch 2253, Loss: 0.0022753169760107994\n",
      "Epoch 2254, Loss: 0.008508777245879173\n",
      "Epoch 2255, Loss: 0.00196398189291358\n",
      "Epoch 2256, Loss: 0.1206488385796547\n",
      "Epoch 2257, Loss: 0.014551590196788311\n",
      "Epoch 2258, Loss: 0.017177511006593704\n",
      "Epoch 2259, Loss: 0.02318159118294716\n",
      "Epoch 2260, Loss: 0.06167960911989212\n",
      "Epoch 2261, Loss: 0.0017215261468663812\n",
      "Epoch 2262, Loss: 0.002386885229498148\n",
      "Epoch 2263, Loss: 0.010440902784466743\n",
      "Epoch 2264, Loss: 0.01115837786346674\n",
      "Epoch 2265, Loss: 0.04565048590302467\n",
      "Epoch 2266, Loss: 0.00907695572823286\n",
      "Epoch 2267, Loss: 0.005459146108478308\n",
      "Epoch 2268, Loss: 0.011465475894510746\n",
      "Epoch 2269, Loss: 0.011317068710923195\n",
      "Epoch 2270, Loss: 0.15949830412864685\n",
      "Epoch 2271, Loss: 0.003345232456922531\n",
      "Epoch 2272, Loss: 0.01627960056066513\n",
      "Epoch 2273, Loss: 0.00453971978276968\n",
      "Epoch 2274, Loss: 0.011507369577884674\n",
      "Epoch 2275, Loss: 0.036315448582172394\n",
      "Epoch 2276, Loss: 0.0002809439320117235\n",
      "Epoch 2277, Loss: 0.018857885152101517\n",
      "Epoch 2278, Loss: 0.010287260636687279\n",
      "Epoch 2279, Loss: 0.012624777853488922\n",
      "Epoch 2280, Loss: 0.021875960752367973\n",
      "Epoch 2281, Loss: 0.00042110038339160383\n",
      "Epoch 2282, Loss: 0.018271077424287796\n",
      "Epoch 2283, Loss: 0.026971593499183655\n",
      "Epoch 2284, Loss: 0.012726692482829094\n",
      "Epoch 2285, Loss: 0.041553299874067307\n",
      "Epoch 2286, Loss: 0.012686667032539845\n",
      "Epoch 2287, Loss: 0.005332442000508308\n",
      "Epoch 2288, Loss: 0.06485340744256973\n",
      "Epoch 2289, Loss: 0.028849761933088303\n",
      "Epoch 2290, Loss: 0.021720899268984795\n",
      "Epoch 2291, Loss: 0.0010328009957447648\n",
      "Epoch 2292, Loss: 0.012505087070167065\n",
      "Epoch 2293, Loss: 0.014025446958839893\n",
      "Epoch 2294, Loss: 0.015952114015817642\n",
      "Epoch 2295, Loss: 0.09518631547689438\n",
      "Epoch 2296, Loss: 0.002608743729069829\n",
      "Epoch 2297, Loss: 0.10283620655536652\n",
      "Epoch 2298, Loss: 0.12084786593914032\n",
      "Epoch 2299, Loss: 0.010264461860060692\n",
      "Epoch 2300, Loss: 0.18680216372013092\n",
      "Epoch 2301, Loss: 0.05203825235366821\n",
      "Epoch 2302, Loss: 0.017989356070756912\n",
      "Epoch 2303, Loss: 0.021113615483045578\n",
      "Epoch 2304, Loss: 0.20780017971992493\n",
      "Epoch 2305, Loss: 0.011784463189542294\n",
      "Epoch 2306, Loss: 0.01622498407959938\n",
      "Epoch 2307, Loss: 0.015305837616324425\n",
      "Epoch 2308, Loss: 0.019005734473466873\n",
      "Epoch 2309, Loss: 0.11052743345499039\n",
      "Epoch 2310, Loss: 0.0022803968749940395\n",
      "Epoch 2311, Loss: 0.005800217390060425\n",
      "Epoch 2312, Loss: 0.027575168758630753\n",
      "Epoch 2313, Loss: 0.032542724162340164\n",
      "Epoch 2314, Loss: 0.10672984272241592\n",
      "Epoch 2315, Loss: 0.0008931284537538886\n",
      "Epoch 2316, Loss: 0.08817407488822937\n",
      "Epoch 2317, Loss: 0.03278718516230583\n",
      "Epoch 2318, Loss: 0.0041250078938901424\n",
      "Epoch 2319, Loss: 0.003475665347650647\n",
      "Epoch 2320, Loss: 0.10115617513656616\n",
      "Epoch 2321, Loss: 0.01906929910182953\n",
      "Epoch 2322, Loss: 0.24830961227416992\n",
      "Epoch 2323, Loss: 0.011879738420248032\n",
      "Epoch 2324, Loss: 0.01169123686850071\n",
      "Epoch 2325, Loss: 0.008685311302542686\n",
      "Epoch 2326, Loss: 0.005950392689555883\n",
      "Epoch 2327, Loss: 0.012301014736294746\n",
      "Epoch 2328, Loss: 0.006499734707176685\n",
      "Epoch 2329, Loss: 0.01766267605125904\n",
      "Epoch 2330, Loss: 0.0009060081792995334\n",
      "Epoch 2331, Loss: 0.03761618211865425\n",
      "Epoch 2332, Loss: 0.014425325207412243\n",
      "Epoch 2333, Loss: 0.015566269867122173\n",
      "Epoch 2334, Loss: 0.009649770334362984\n",
      "Epoch 2335, Loss: 0.032615989446640015\n",
      "Epoch 2336, Loss: 0.0024540810845792294\n",
      "Epoch 2337, Loss: 0.0006386689492501318\n",
      "Epoch 2338, Loss: 0.0029092109762132168\n",
      "Epoch 2339, Loss: 0.00408308207988739\n",
      "Epoch 2340, Loss: 0.024049371480941772\n",
      "Epoch 2341, Loss: 0.01130568329244852\n",
      "Epoch 2342, Loss: 0.02809489145874977\n",
      "Epoch 2343, Loss: 0.0025957729667425156\n",
      "Epoch 2344, Loss: 0.24886098504066467\n",
      "Epoch 2345, Loss: 0.03787075728178024\n",
      "Epoch 2346, Loss: 0.010592883452773094\n",
      "Epoch 2347, Loss: 0.007497172802686691\n",
      "Epoch 2348, Loss: 0.0010850559920072556\n",
      "Epoch 2349, Loss: 0.022743647918105125\n",
      "Epoch 2350, Loss: 0.10347624868154526\n",
      "Epoch 2351, Loss: 0.004553087055683136\n",
      "Epoch 2352, Loss: 0.008441917598247528\n",
      "Epoch 2353, Loss: 0.030410682782530785\n",
      "Epoch 2354, Loss: 0.019981749355793\n",
      "Epoch 2355, Loss: 0.013345787301659584\n",
      "Epoch 2356, Loss: 0.0038970052264630795\n",
      "Epoch 2357, Loss: 0.01792876049876213\n",
      "Epoch 2358, Loss: 0.006199982482939959\n",
      "Epoch 2359, Loss: 0.033680129796266556\n",
      "Epoch 2360, Loss: 0.014444763772189617\n",
      "Epoch 2361, Loss: 0.00744433980435133\n",
      "Epoch 2362, Loss: 0.0005231450195424259\n",
      "Epoch 2363, Loss: 0.13927505910396576\n",
      "Epoch 2364, Loss: 0.0036951438523828983\n",
      "Epoch 2365, Loss: 0.01221397053450346\n",
      "Epoch 2366, Loss: 0.004689074121415615\n",
      "Epoch 2367, Loss: 0.15283077955245972\n",
      "Epoch 2368, Loss: 0.009766674600541592\n",
      "Epoch 2369, Loss: 0.06043676286935806\n",
      "Epoch 2370, Loss: 0.10531316697597504\n",
      "Epoch 2371, Loss: 0.02646159566938877\n",
      "Epoch 2372, Loss: 0.002928087953478098\n",
      "Epoch 2373, Loss: 0.0029814571607857943\n",
      "Epoch 2374, Loss: 0.04595797508955002\n",
      "Epoch 2375, Loss: 0.006799768656492233\n",
      "Epoch 2376, Loss: 0.0025163833051919937\n",
      "Epoch 2377, Loss: 0.024405021220445633\n",
      "Epoch 2378, Loss: 0.0033160776365548372\n",
      "Epoch 2379, Loss: 0.013654453679919243\n",
      "Epoch 2380, Loss: 0.014373441226780415\n",
      "Epoch 2381, Loss: 0.13963603973388672\n",
      "Epoch 2382, Loss: 0.028487805277109146\n",
      "Epoch 2383, Loss: 0.003593846457079053\n",
      "Epoch 2384, Loss: 0.013351487927138805\n",
      "Epoch 2385, Loss: 0.2031024694442749\n",
      "Epoch 2386, Loss: 0.1221253052353859\n",
      "Epoch 2387, Loss: 0.0322113111615181\n",
      "Epoch 2388, Loss: 0.01207413524389267\n",
      "Epoch 2389, Loss: 0.04661119729280472\n",
      "Epoch 2390, Loss: 0.01620851270854473\n",
      "Epoch 2391, Loss: 0.006346681620925665\n",
      "Epoch 2392, Loss: 0.018507713451981544\n",
      "Epoch 2393, Loss: 0.006479772739112377\n",
      "Epoch 2394, Loss: 0.00905416626483202\n",
      "Epoch 2395, Loss: 0.01369986217468977\n",
      "Epoch 2396, Loss: 0.07537700235843658\n",
      "Epoch 2397, Loss: 0.009624775499105453\n",
      "Epoch 2398, Loss: 0.24785348773002625\n",
      "Epoch 2399, Loss: 0.013635212555527687\n",
      "Epoch 2400, Loss: 0.0074448310770094395\n",
      "Epoch 2401, Loss: 0.09527388215065002\n",
      "Epoch 2402, Loss: 0.004568947479128838\n",
      "Epoch 2403, Loss: 0.0011070482432842255\n",
      "Epoch 2404, Loss: 0.11594337224960327\n",
      "Epoch 2405, Loss: 0.02949385903775692\n",
      "Epoch 2406, Loss: 0.0024616888258606195\n",
      "Epoch 2407, Loss: 0.012080812826752663\n",
      "Epoch 2408, Loss: 0.09630729258060455\n",
      "Epoch 2409, Loss: 0.024442415684461594\n",
      "Epoch 2410, Loss: 0.09828115254640579\n",
      "Epoch 2411, Loss: 0.016898367553949356\n",
      "Epoch 2412, Loss: 0.014919066801667213\n",
      "Epoch 2413, Loss: 0.08473001420497894\n",
      "Epoch 2414, Loss: 0.011654196307063103\n",
      "Epoch 2415, Loss: 0.008061016909778118\n",
      "Epoch 2416, Loss: 0.010787165723741055\n",
      "Epoch 2417, Loss: 0.015638981014490128\n",
      "Epoch 2418, Loss: 0.0074692717753350735\n",
      "Epoch 2419, Loss: 0.0471685491502285\n",
      "Epoch 2420, Loss: 0.0251876562833786\n",
      "Epoch 2421, Loss: 0.12664540112018585\n",
      "Epoch 2422, Loss: 0.022854318842291832\n",
      "Epoch 2423, Loss: 0.01057293452322483\n",
      "Epoch 2424, Loss: 0.020931776612997055\n",
      "Epoch 2425, Loss: 0.017700033262372017\n",
      "Epoch 2426, Loss: 0.007437358610332012\n",
      "Epoch 2427, Loss: 0.02411738969385624\n",
      "Epoch 2428, Loss: 0.05775460600852966\n",
      "Epoch 2429, Loss: 0.008366535417735577\n",
      "Epoch 2430, Loss: 0.0029508855659514666\n",
      "Epoch 2431, Loss: 0.005629929713904858\n",
      "Epoch 2432, Loss: 0.002703554229810834\n",
      "Epoch 2433, Loss: 0.007786893751472235\n",
      "Epoch 2434, Loss: 0.0266437791287899\n",
      "Epoch 2435, Loss: 0.008799155242741108\n",
      "Epoch 2436, Loss: 0.022560980170965195\n",
      "Epoch 2437, Loss: 0.009079476818442345\n",
      "Epoch 2438, Loss: 0.007815496064722538\n",
      "Epoch 2439, Loss: 0.0028363480232656\n",
      "Epoch 2440, Loss: 0.000556557031814009\n",
      "Epoch 2441, Loss: 0.008804313838481903\n",
      "Epoch 2442, Loss: 0.09928716719150543\n",
      "Epoch 2443, Loss: 0.03529047593474388\n",
      "Epoch 2444, Loss: 0.03733108192682266\n",
      "Epoch 2445, Loss: 0.01295058149844408\n",
      "Epoch 2446, Loss: 0.16891005635261536\n",
      "Epoch 2447, Loss: 0.0005617636488750577\n",
      "Epoch 2448, Loss: 0.001959621673449874\n",
      "Epoch 2449, Loss: 0.03873192146420479\n",
      "Epoch 2450, Loss: 0.011354448273777962\n",
      "Epoch 2451, Loss: 0.10970845073461533\n",
      "Epoch 2452, Loss: 0.01079112570732832\n",
      "Epoch 2453, Loss: 0.002365102991461754\n",
      "Epoch 2454, Loss: 0.02502003312110901\n",
      "Epoch 2455, Loss: 0.00332178408280015\n",
      "Epoch 2456, Loss: 0.002102899132296443\n",
      "Epoch 2457, Loss: 0.020702404901385307\n",
      "Epoch 2458, Loss: 0.008596973493695259\n",
      "Epoch 2459, Loss: 0.009124603122472763\n",
      "Epoch 2460, Loss: 0.11648274958133698\n",
      "Epoch 2461, Loss: 0.004504689946770668\n",
      "Epoch 2462, Loss: 0.013948865234851837\n",
      "Epoch 2463, Loss: 0.013286672532558441\n",
      "Epoch 2464, Loss: 0.003608963219448924\n",
      "Epoch 2465, Loss: 0.11357524245977402\n",
      "Epoch 2466, Loss: 0.01648380607366562\n",
      "Epoch 2467, Loss: 0.0007689232588745654\n",
      "Epoch 2468, Loss: 0.06427367776632309\n",
      "Epoch 2469, Loss: 0.014261896722018719\n",
      "Epoch 2470, Loss: 0.009101716801524162\n",
      "Epoch 2471, Loss: 0.016635417938232422\n",
      "Epoch 2472, Loss: 0.10820259898900986\n",
      "Epoch 2473, Loss: 0.09053502976894379\n",
      "Epoch 2474, Loss: 0.3085945248603821\n",
      "Epoch 2475, Loss: 0.007944958284497261\n",
      "Epoch 2476, Loss: 0.0031920329201966524\n",
      "Epoch 2477, Loss: 0.00824991799890995\n",
      "Epoch 2478, Loss: 0.008332489989697933\n",
      "Epoch 2479, Loss: 0.013743221759796143\n",
      "Epoch 2480, Loss: 0.0011127300094813108\n",
      "Epoch 2481, Loss: 0.024067748337984085\n",
      "Epoch 2482, Loss: 0.01558743230998516\n",
      "Epoch 2483, Loss: 0.005488946568220854\n",
      "Epoch 2484, Loss: 0.11446762084960938\n",
      "Epoch 2485, Loss: 0.01238735020160675\n",
      "Epoch 2486, Loss: 0.0012800174299627542\n",
      "Epoch 2487, Loss: 0.06216318532824516\n",
      "Epoch 2488, Loss: 0.02105599083006382\n",
      "Epoch 2489, Loss: 0.048687808215618134\n",
      "Epoch 2490, Loss: 0.16676071286201477\n",
      "Epoch 2491, Loss: 0.006330417934805155\n",
      "Epoch 2492, Loss: 0.1832551658153534\n",
      "Epoch 2493, Loss: 0.0038413391448557377\n",
      "Epoch 2494, Loss: 0.0034544195514172316\n",
      "Epoch 2495, Loss: 0.010614120401442051\n",
      "Epoch 2496, Loss: 0.10672050714492798\n",
      "Epoch 2497, Loss: 0.010873598977923393\n",
      "Epoch 2498, Loss: 0.0017915265634655952\n",
      "Epoch 2499, Loss: 0.00235930597409606\n",
      "Epoch 2500, Loss: 0.015117818489670753\n",
      "Epoch 2501, Loss: 0.09447816014289856\n",
      "Epoch 2502, Loss: 0.01468273252248764\n",
      "Epoch 2503, Loss: 0.0017348146066069603\n",
      "Epoch 2504, Loss: 0.007371271960437298\n",
      "Epoch 2505, Loss: 0.009298809804022312\n",
      "Epoch 2506, Loss: 0.09232382476329803\n",
      "Epoch 2507, Loss: 0.0137959448620677\n",
      "Epoch 2508, Loss: 0.014283274300396442\n",
      "Epoch 2509, Loss: 0.003004559548571706\n",
      "Epoch 2510, Loss: 0.01743520423769951\n",
      "Epoch 2511, Loss: 0.10885240137577057\n",
      "Epoch 2512, Loss: 0.008997611701488495\n",
      "Epoch 2513, Loss: 0.1700662076473236\n",
      "Epoch 2514, Loss: 0.030947541818022728\n",
      "Epoch 2515, Loss: 0.02630053460597992\n",
      "Epoch 2516, Loss: 0.262317419052124\n",
      "Epoch 2517, Loss: 0.0009191900608129799\n",
      "Epoch 2518, Loss: 0.002575487829744816\n",
      "Epoch 2519, Loss: 0.08568016439676285\n",
      "Epoch 2520, Loss: 0.005492076277732849\n",
      "Epoch 2521, Loss: 0.006242569535970688\n",
      "Epoch 2522, Loss: 0.00429181382060051\n",
      "Epoch 2523, Loss: 0.02625034749507904\n",
      "Epoch 2524, Loss: 0.009051863104104996\n",
      "Epoch 2525, Loss: 0.002936210250481963\n",
      "Epoch 2526, Loss: 0.04144590348005295\n",
      "Epoch 2527, Loss: 0.008294119499623775\n",
      "Epoch 2528, Loss: 0.019173506647348404\n",
      "Epoch 2529, Loss: 0.008712099865078926\n",
      "Epoch 2530, Loss: 0.002191105391830206\n",
      "Epoch 2531, Loss: 0.020547648891806602\n",
      "Epoch 2532, Loss: 0.06761882454156876\n",
      "Epoch 2533, Loss: 0.10269500315189362\n",
      "Epoch 2534, Loss: 0.0155323576182127\n",
      "Epoch 2535, Loss: 0.0012324074050411582\n",
      "Epoch 2536, Loss: 0.011955559253692627\n",
      "Epoch 2537, Loss: 0.018417993560433388\n",
      "Epoch 2538, Loss: 0.02695336565375328\n",
      "Epoch 2539, Loss: 0.028860654681921005\n",
      "Epoch 2540, Loss: 0.09224806725978851\n",
      "Epoch 2541, Loss: 0.01829838752746582\n",
      "Epoch 2542, Loss: 0.11586812883615494\n",
      "Epoch 2543, Loss: 0.06497097760438919\n",
      "Epoch 2544, Loss: 0.006621167995035648\n",
      "Epoch 2545, Loss: 0.019505325704813004\n",
      "Epoch 2546, Loss: 0.25124412775039673\n",
      "Epoch 2547, Loss: 0.014937827363610268\n",
      "Epoch 2548, Loss: 0.0070504313334822655\n",
      "Epoch 2549, Loss: 0.01493585854768753\n",
      "Epoch 2550, Loss: 0.020987991243600845\n",
      "Epoch 2551, Loss: 0.029238218441605568\n",
      "Epoch 2552, Loss: 0.006003586575388908\n",
      "Epoch 2553, Loss: 0.005223898217082024\n",
      "Epoch 2554, Loss: 0.011922039091587067\n",
      "Epoch 2555, Loss: 0.19491469860076904\n",
      "Epoch 2556, Loss: 0.06266972422599792\n",
      "Epoch 2557, Loss: 0.020347358658909798\n",
      "Epoch 2558, Loss: 0.011605789884924889\n",
      "Epoch 2559, Loss: 0.15358763933181763\n",
      "Epoch 2560, Loss: 0.0410061739385128\n",
      "Epoch 2561, Loss: 0.0013684537261724472\n",
      "Epoch 2562, Loss: 0.09219430387020111\n",
      "Epoch 2563, Loss: 0.004638773389160633\n",
      "Epoch 2564, Loss: 0.012111359275877476\n",
      "Epoch 2565, Loss: 0.00526107894256711\n",
      "Epoch 2566, Loss: 0.005898292176425457\n",
      "Epoch 2567, Loss: 0.0023851755540817976\n",
      "Epoch 2568, Loss: 0.0037926235236227512\n",
      "Epoch 2569, Loss: 0.0008879988454282284\n",
      "Epoch 2570, Loss: 0.019372202455997467\n",
      "Epoch 2571, Loss: 0.018984582275152206\n",
      "Epoch 2572, Loss: 0.010558719746768475\n",
      "Epoch 2573, Loss: 0.005539849866181612\n",
      "Epoch 2574, Loss: 0.011454658582806587\n",
      "Epoch 2575, Loss: 0.0026042615063488483\n",
      "Epoch 2576, Loss: 0.01417812891304493\n",
      "Epoch 2577, Loss: 0.004230419639497995\n",
      "Epoch 2578, Loss: 0.005580300465226173\n",
      "Epoch 2579, Loss: 0.015013868920505047\n",
      "Epoch 2580, Loss: 0.009236341342329979\n",
      "Epoch 2581, Loss: 0.0037984191440045834\n",
      "Epoch 2582, Loss: 0.02363981492817402\n",
      "Epoch 2583, Loss: 0.08497542887926102\n",
      "Epoch 2584, Loss: 0.009353546425700188\n",
      "Epoch 2585, Loss: 0.027072209864854813\n",
      "Epoch 2586, Loss: 0.0016641955589875579\n",
      "Epoch 2587, Loss: 0.010285555385053158\n",
      "Epoch 2588, Loss: 0.007964910008013248\n",
      "Epoch 2589, Loss: 0.029821297153830528\n",
      "Epoch 2590, Loss: 0.016053441911935806\n",
      "Epoch 2591, Loss: 0.010519706644117832\n",
      "Epoch 2592, Loss: 0.0037396750412881374\n",
      "Epoch 2593, Loss: 0.03779683634638786\n",
      "Epoch 2594, Loss: 0.03159830719232559\n",
      "Epoch 2595, Loss: 0.002801682334393263\n",
      "Epoch 2596, Loss: 0.0022488015238195658\n",
      "Epoch 2597, Loss: 0.006496870424598455\n",
      "Epoch 2598, Loss: 0.0018260814249515533\n",
      "Epoch 2599, Loss: 0.0028238631784915924\n",
      "Epoch 2600, Loss: 0.001531206420622766\n",
      "Epoch 2601, Loss: 0.05103409290313721\n",
      "Epoch 2602, Loss: 0.14534981548786163\n",
      "Epoch 2603, Loss: 0.31924253702163696\n",
      "Epoch 2604, Loss: 0.019704032689332962\n",
      "Epoch 2605, Loss: 0.01659182459115982\n",
      "Epoch 2606, Loss: 0.10178963094949722\n",
      "Epoch 2607, Loss: 0.007210366427898407\n",
      "Epoch 2608, Loss: 0.0082760751247406\n",
      "Epoch 2609, Loss: 0.02122321166098118\n",
      "Epoch 2610, Loss: 0.0014599279966205359\n",
      "Epoch 2611, Loss: 0.10831141471862793\n",
      "Epoch 2612, Loss: 0.00653147604316473\n",
      "Epoch 2613, Loss: 0.016704032197594643\n",
      "Epoch 2614, Loss: 0.01013519149273634\n",
      "Epoch 2615, Loss: 0.016613969579339027\n",
      "Epoch 2616, Loss: 0.005933723412454128\n",
      "Epoch 2617, Loss: 0.09059029072523117\n",
      "Epoch 2618, Loss: 0.00769939785823226\n",
      "Epoch 2619, Loss: 0.02364390343427658\n",
      "Epoch 2620, Loss: 0.0011581276776269078\n",
      "Epoch 2621, Loss: 0.0006043303292244673\n",
      "Epoch 2622, Loss: 0.011406749486923218\n",
      "Epoch 2623, Loss: 0.009929792024195194\n",
      "Epoch 2624, Loss: 0.2388978749513626\n",
      "Epoch 2625, Loss: 0.03142666816711426\n",
      "Epoch 2626, Loss: 0.01591603085398674\n",
      "Epoch 2627, Loss: 0.15621480345726013\n",
      "Epoch 2628, Loss: 0.0852460041642189\n",
      "Epoch 2629, Loss: 0.008926271460950375\n",
      "Epoch 2630, Loss: 0.11482705175876617\n",
      "Epoch 2631, Loss: 0.0024486551992595196\n",
      "Epoch 2632, Loss: 0.006393098272383213\n",
      "Epoch 2633, Loss: 0.05610571429133415\n",
      "Epoch 2634, Loss: 0.035020291805267334\n",
      "Epoch 2635, Loss: 0.12474001944065094\n",
      "Epoch 2636, Loss: 0.025193993002176285\n",
      "Epoch 2637, Loss: 0.002127020852640271\n",
      "Epoch 2638, Loss: 0.02034979686141014\n",
      "Epoch 2639, Loss: 0.024178722873330116\n",
      "Epoch 2640, Loss: 0.025440270081162453\n",
      "Epoch 2641, Loss: 0.005573211703449488\n",
      "Epoch 2642, Loss: 0.003136470913887024\n",
      "Epoch 2643, Loss: 0.02372417412698269\n",
      "Epoch 2644, Loss: 0.01748771406710148\n",
      "Epoch 2645, Loss: 0.009502061642706394\n",
      "Epoch 2646, Loss: 0.2241189181804657\n",
      "Epoch 2647, Loss: 0.006941401865333319\n",
      "Epoch 2648, Loss: 0.01474034320563078\n",
      "Epoch 2649, Loss: 0.109749935567379\n",
      "Epoch 2650, Loss: 0.007589972577989101\n",
      "Epoch 2651, Loss: 0.0067026689648628235\n",
      "Epoch 2652, Loss: 0.24502316117286682\n",
      "Epoch 2653, Loss: 0.01721104606986046\n",
      "Epoch 2654, Loss: 0.007802876643836498\n",
      "Epoch 2655, Loss: 0.01715843752026558\n",
      "Epoch 2656, Loss: 0.3337897062301636\n",
      "Epoch 2657, Loss: 0.005279521457850933\n",
      "Epoch 2658, Loss: 0.010493873618543148\n",
      "Epoch 2659, Loss: 0.0020616657566279173\n",
      "Epoch 2660, Loss: 0.02785574272274971\n",
      "Epoch 2661, Loss: 0.0016443922650068998\n",
      "Epoch 2662, Loss: 0.011104883626103401\n",
      "Epoch 2663, Loss: 0.011051824316382408\n",
      "Epoch 2664, Loss: 0.0025686773005872965\n",
      "Epoch 2665, Loss: 0.026020631194114685\n",
      "Epoch 2666, Loss: 0.004161642398685217\n",
      "Epoch 2667, Loss: 0.005067998543381691\n",
      "Epoch 2668, Loss: 0.017592748627066612\n",
      "Epoch 2669, Loss: 0.01191962044686079\n",
      "Epoch 2670, Loss: 0.08465725928544998\n",
      "Epoch 2671, Loss: 0.10012044757604599\n",
      "Epoch 2672, Loss: 0.010892027989029884\n",
      "Epoch 2673, Loss: 0.05573048070073128\n",
      "Epoch 2674, Loss: 0.0624755397439003\n",
      "Epoch 2675, Loss: 0.013848870992660522\n",
      "Epoch 2676, Loss: 0.10785956680774689\n",
      "Epoch 2677, Loss: 0.020230386406183243\n",
      "Epoch 2678, Loss: 0.014189185574650764\n",
      "Epoch 2679, Loss: 0.05793279409408569\n",
      "Epoch 2680, Loss: 0.0027097519487142563\n",
      "Epoch 2681, Loss: 0.00020211320952512324\n",
      "Epoch 2682, Loss: 0.005193532444536686\n",
      "Epoch 2683, Loss: 0.014462670311331749\n",
      "Epoch 2684, Loss: 0.2245475798845291\n",
      "Epoch 2685, Loss: 0.006955391261726618\n",
      "Epoch 2686, Loss: 0.15574593842029572\n",
      "Epoch 2687, Loss: 0.0180901400744915\n",
      "Epoch 2688, Loss: 0.0003850233624689281\n",
      "Epoch 2689, Loss: 0.0019352348754182458\n",
      "Epoch 2690, Loss: 0.04153520241379738\n",
      "Epoch 2691, Loss: 0.008111010305583477\n",
      "Epoch 2692, Loss: 0.010815458372235298\n",
      "Epoch 2693, Loss: 0.0007696800166741014\n",
      "Epoch 2694, Loss: 0.011153919622302055\n",
      "Epoch 2695, Loss: 0.01733526960015297\n",
      "Epoch 2696, Loss: 0.001957185100764036\n",
      "Epoch 2697, Loss: 0.013871205039322376\n",
      "Epoch 2698, Loss: 0.24596424400806427\n",
      "Epoch 2699, Loss: 0.019948003813624382\n",
      "Epoch 2700, Loss: 0.017725033685564995\n",
      "Epoch 2701, Loss: 0.01516810804605484\n",
      "Epoch 2702, Loss: 0.0005126589676365256\n",
      "Epoch 2703, Loss: 0.010480102151632309\n",
      "Epoch 2704, Loss: 0.047307007014751434\n",
      "Epoch 2705, Loss: 0.011581920087337494\n",
      "Epoch 2706, Loss: 0.03652644157409668\n",
      "Epoch 2707, Loss: 0.01158908847719431\n",
      "Epoch 2708, Loss: 0.06241576001048088\n",
      "Epoch 2709, Loss: 0.004443999845534563\n",
      "Epoch 2710, Loss: 0.07833834737539291\n",
      "Epoch 2711, Loss: 0.013185235671699047\n",
      "Epoch 2712, Loss: 0.09634430706501007\n",
      "Epoch 2713, Loss: 0.011108514852821827\n",
      "Epoch 2714, Loss: 0.024404771625995636\n",
      "Epoch 2715, Loss: 0.122450090944767\n",
      "Epoch 2716, Loss: 0.17332151532173157\n",
      "Epoch 2717, Loss: 0.007699265144765377\n",
      "Epoch 2718, Loss: 0.006298474036157131\n",
      "Epoch 2719, Loss: 0.01086254883557558\n",
      "Epoch 2720, Loss: 0.008326428011059761\n",
      "Epoch 2721, Loss: 0.01332355011254549\n",
      "Epoch 2722, Loss: 0.01371686439961195\n",
      "Epoch 2723, Loss: 0.007253651507198811\n",
      "Epoch 2724, Loss: 0.02800537273287773\n",
      "Epoch 2725, Loss: 0.1114121526479721\n",
      "Epoch 2726, Loss: 0.003355561289936304\n",
      "Epoch 2727, Loss: 0.0027266403194516897\n",
      "Epoch 2728, Loss: 0.010899241082370281\n",
      "Epoch 2729, Loss: 0.01946307346224785\n",
      "Epoch 2730, Loss: 0.0025819079019129276\n",
      "Epoch 2731, Loss: 0.013796068727970123\n",
      "Epoch 2732, Loss: 0.07237106561660767\n",
      "Epoch 2733, Loss: 0.004751541651785374\n",
      "Epoch 2734, Loss: 0.0353512242436409\n",
      "Epoch 2735, Loss: 0.02015458047389984\n",
      "Epoch 2736, Loss: 0.2440219223499298\n",
      "Epoch 2737, Loss: 0.007876528427004814\n",
      "Epoch 2738, Loss: 0.0981551855802536\n",
      "Epoch 2739, Loss: 0.0039986735209822655\n",
      "Epoch 2740, Loss: 0.013528655283153057\n",
      "Epoch 2741, Loss: 0.016478311270475388\n",
      "Epoch 2742, Loss: 0.001246600761078298\n",
      "Epoch 2743, Loss: 0.10191021859645844\n",
      "Epoch 2744, Loss: 0.001205476000905037\n",
      "Epoch 2745, Loss: 0.16019466519355774\n",
      "Epoch 2746, Loss: 0.001866928650997579\n",
      "Epoch 2747, Loss: 0.0043796636164188385\n",
      "Epoch 2748, Loss: 0.0010764218168333173\n",
      "Epoch 2749, Loss: 0.010822354815900326\n",
      "Epoch 2750, Loss: 0.2187356948852539\n",
      "Epoch 2751, Loss: 0.015986870974302292\n",
      "Epoch 2752, Loss: 0.08184506744146347\n",
      "Epoch 2753, Loss: 0.005931689403951168\n",
      "Epoch 2754, Loss: 0.03569646552205086\n",
      "Epoch 2755, Loss: 0.1555645912885666\n",
      "Epoch 2756, Loss: 0.015638817101716995\n",
      "Epoch 2757, Loss: 0.03049916960299015\n",
      "Epoch 2758, Loss: 0.001882506301626563\n",
      "Epoch 2759, Loss: 0.06382407248020172\n",
      "Epoch 2760, Loss: 0.010541407391428947\n",
      "Epoch 2761, Loss: 0.0018707604613155127\n",
      "Epoch 2762, Loss: 0.09616129100322723\n",
      "Epoch 2763, Loss: 0.03868403285741806\n",
      "Epoch 2764, Loss: 0.011295909993350506\n",
      "Epoch 2765, Loss: 0.000707046187017113\n",
      "Epoch 2766, Loss: 0.004233560990542173\n",
      "Epoch 2767, Loss: 0.017269527539610863\n",
      "Epoch 2768, Loss: 0.0030876051168888807\n",
      "Epoch 2769, Loss: 0.0009717652574181557\n",
      "Epoch 2770, Loss: 0.013752380385994911\n",
      "Epoch 2771, Loss: 0.003991969395428896\n",
      "Epoch 2772, Loss: 0.12153887748718262\n",
      "Epoch 2773, Loss: 0.022311773151159286\n",
      "Epoch 2774, Loss: 0.015253034420311451\n",
      "Epoch 2775, Loss: 0.0167241171002388\n",
      "Epoch 2776, Loss: 0.0011739985784515738\n",
      "Epoch 2777, Loss: 0.017219113186001778\n",
      "Epoch 2778, Loss: 0.04269234463572502\n",
      "Epoch 2779, Loss: 0.013307712972164154\n",
      "Epoch 2780, Loss: 0.017359230667352676\n",
      "Epoch 2781, Loss: 0.05815848708152771\n",
      "Epoch 2782, Loss: 0.22634851932525635\n",
      "Epoch 2783, Loss: 0.006629273295402527\n",
      "Epoch 2784, Loss: 0.11314757913351059\n",
      "Epoch 2785, Loss: 0.01165203657001257\n",
      "Epoch 2786, Loss: 0.05159112066030502\n",
      "Epoch 2787, Loss: 0.021549027413129807\n",
      "Epoch 2788, Loss: 0.012770605273544788\n",
      "Epoch 2789, Loss: 0.016305256634950638\n",
      "Epoch 2790, Loss: 0.2678390443325043\n",
      "Epoch 2791, Loss: 0.006298245396465063\n",
      "Epoch 2792, Loss: 0.002811382757499814\n",
      "Epoch 2793, Loss: 0.003589774016290903\n",
      "Epoch 2794, Loss: 0.07615451514720917\n",
      "Epoch 2795, Loss: 0.48212069272994995\n",
      "Epoch 2796, Loss: 0.2016475945711136\n",
      "Epoch 2797, Loss: 0.012523775920271873\n",
      "Epoch 2798, Loss: 0.011024633422493935\n",
      "Epoch 2799, Loss: 0.01628512144088745\n",
      "Epoch 2800, Loss: 0.0014607965713366866\n",
      "Epoch 2801, Loss: 0.23603837192058563\n",
      "Epoch 2802, Loss: 0.025232097133994102\n",
      "Epoch 2803, Loss: 0.0034004617482423782\n",
      "Epoch 2804, Loss: 0.00603987742215395\n",
      "Epoch 2805, Loss: 0.08809639513492584\n",
      "Epoch 2806, Loss: 0.09612739086151123\n",
      "Epoch 2807, Loss: 0.10570305585861206\n",
      "Epoch 2808, Loss: 0.10212469100952148\n",
      "Epoch 2809, Loss: 0.004457375966012478\n",
      "Epoch 2810, Loss: 0.0047493791207671165\n",
      "Epoch 2811, Loss: 0.001079389825463295\n",
      "Epoch 2812, Loss: 0.09506751596927643\n",
      "Epoch 2813, Loss: 0.062229909002780914\n",
      "Epoch 2814, Loss: 0.0491488091647625\n",
      "Epoch 2815, Loss: 0.012328974902629852\n",
      "Epoch 2816, Loss: 0.0006871736841276288\n",
      "Epoch 2817, Loss: 0.012215503491461277\n",
      "Epoch 2818, Loss: 0.00010967520211124793\n",
      "Epoch 2819, Loss: 0.009136760607361794\n",
      "Epoch 2820, Loss: 0.21505141258239746\n",
      "Epoch 2821, Loss: 0.012520174495875835\n",
      "Epoch 2822, Loss: 0.023710306733846664\n",
      "Epoch 2823, Loss: 0.035114042460918427\n",
      "Epoch 2824, Loss: 0.11946187913417816\n",
      "Epoch 2825, Loss: 0.25422778725624084\n",
      "Epoch 2826, Loss: 0.019234782084822655\n",
      "Epoch 2827, Loss: 0.0005795933539047837\n",
      "Epoch 2828, Loss: 0.0012286724522709846\n",
      "Epoch 2829, Loss: 0.005477347876876593\n",
      "Epoch 2830, Loss: 0.021130353212356567\n",
      "Epoch 2831, Loss: 0.023080457001924515\n",
      "Epoch 2832, Loss: 0.09493611752986908\n",
      "Epoch 2833, Loss: 0.015594805590808392\n",
      "Epoch 2834, Loss: 0.01550863403826952\n",
      "Epoch 2835, Loss: 0.0011426345445215702\n",
      "Epoch 2836, Loss: 0.021983278915286064\n",
      "Epoch 2837, Loss: 0.0037230488378554583\n",
      "Epoch 2838, Loss: 0.07764933258295059\n",
      "Epoch 2839, Loss: 0.00995622482150793\n",
      "Epoch 2840, Loss: 0.0014357728650793433\n",
      "Epoch 2841, Loss: 0.17281927168369293\n",
      "Epoch 2842, Loss: 0.0011552523355931044\n",
      "Epoch 2843, Loss: 0.006406144704669714\n",
      "Epoch 2844, Loss: 0.004618982784450054\n",
      "Epoch 2845, Loss: 0.02276151068508625\n",
      "Epoch 2846, Loss: 0.057771891355514526\n",
      "Epoch 2847, Loss: 0.0046366071328520775\n",
      "Epoch 2848, Loss: 0.06633225083351135\n",
      "Epoch 2849, Loss: 0.004517621826380491\n",
      "Epoch 2850, Loss: 0.020375540480017662\n",
      "Epoch 2851, Loss: 0.07560844719409943\n",
      "Epoch 2852, Loss: 0.12759354710578918\n",
      "Epoch 2853, Loss: 0.007970472797751427\n",
      "Epoch 2854, Loss: 0.007280743680894375\n",
      "Epoch 2855, Loss: 0.007839027792215347\n",
      "Epoch 2856, Loss: 0.02039986103773117\n",
      "Epoch 2857, Loss: 0.001258455216884613\n",
      "Epoch 2858, Loss: 0.010171574540436268\n",
      "Epoch 2859, Loss: 0.01185423694550991\n",
      "Epoch 2860, Loss: 0.004746349062770605\n",
      "Epoch 2861, Loss: 0.002041257917881012\n",
      "Epoch 2862, Loss: 0.0011506435694172978\n",
      "Epoch 2863, Loss: 0.198181614279747\n",
      "Epoch 2864, Loss: 0.02845030650496483\n",
      "Epoch 2865, Loss: 0.07764436304569244\n",
      "Epoch 2866, Loss: 0.005071169696748257\n",
      "Epoch 2867, Loss: 0.011494958773255348\n",
      "Epoch 2868, Loss: 0.010454910807311535\n",
      "Epoch 2869, Loss: 0.004438085947185755\n",
      "Epoch 2870, Loss: 0.01753847673535347\n",
      "Epoch 2871, Loss: 0.013043692335486412\n",
      "Epoch 2872, Loss: 0.0019874421413987875\n",
      "Epoch 2873, Loss: 0.07407978177070618\n",
      "Epoch 2874, Loss: 0.0006548658711835742\n",
      "Epoch 2875, Loss: 0.022034497931599617\n",
      "Epoch 2876, Loss: 0.21108153462409973\n",
      "Epoch 2877, Loss: 0.0045368243008852005\n",
      "Epoch 2878, Loss: 0.013368573971092701\n",
      "Epoch 2879, Loss: 0.008504407480359077\n",
      "Epoch 2880, Loss: 0.22261950373649597\n",
      "Epoch 2881, Loss: 0.15843991935253143\n",
      "Epoch 2882, Loss: 0.00498552992939949\n",
      "Epoch 2883, Loss: 0.00917675718665123\n",
      "Epoch 2884, Loss: 0.0328640379011631\n",
      "Epoch 2885, Loss: 0.00926254503428936\n",
      "Epoch 2886, Loss: 0.02225533500313759\n",
      "Epoch 2887, Loss: 0.02361181750893593\n",
      "Epoch 2888, Loss: 0.16503337025642395\n",
      "Epoch 2889, Loss: 0.02230050601065159\n",
      "Epoch 2890, Loss: 0.010623352602124214\n",
      "Epoch 2891, Loss: 0.02356773428618908\n",
      "Epoch 2892, Loss: 0.062463678419589996\n",
      "Epoch 2893, Loss: 0.08442407101392746\n",
      "Epoch 2894, Loss: 0.004902941174805164\n",
      "Epoch 2895, Loss: 0.01612413302063942\n",
      "Epoch 2896, Loss: 0.007630865089595318\n",
      "Epoch 2897, Loss: 0.0024634466972202063\n",
      "Epoch 2898, Loss: 0.12320166826248169\n",
      "Epoch 2899, Loss: 0.002391006564721465\n",
      "Epoch 2900, Loss: 0.0037877720315009356\n",
      "Epoch 2901, Loss: 0.03242200240492821\n",
      "Epoch 2902, Loss: 0.00926473829895258\n",
      "Epoch 2903, Loss: 0.00682311225682497\n",
      "Epoch 2904, Loss: 1.581136712047737e-05\n",
      "Epoch 2905, Loss: 0.01912054792046547\n",
      "Epoch 2906, Loss: 0.0599823072552681\n",
      "Epoch 2907, Loss: 0.202656552195549\n",
      "Epoch 2908, Loss: 0.0022255554795265198\n",
      "Epoch 2909, Loss: 0.08883150666952133\n",
      "Epoch 2910, Loss: 0.4472213387489319\n",
      "Epoch 2911, Loss: 0.022413713857531548\n",
      "Epoch 2912, Loss: 0.003497196827083826\n",
      "Epoch 2913, Loss: 0.17436277866363525\n",
      "Epoch 2914, Loss: 0.08354867994785309\n",
      "Epoch 2915, Loss: 0.058035194873809814\n",
      "Epoch 2916, Loss: 0.011688909493386745\n",
      "Epoch 2917, Loss: 0.010223658755421638\n",
      "Epoch 2918, Loss: 0.002089380519464612\n",
      "Epoch 2919, Loss: 0.00026948191225528717\n",
      "Epoch 2920, Loss: 0.014930414035916328\n",
      "Epoch 2921, Loss: 0.0196310356259346\n",
      "Epoch 2922, Loss: 0.16003482043743134\n",
      "Epoch 2923, Loss: 0.0008143195882439613\n",
      "Epoch 2924, Loss: 0.00235797930508852\n",
      "Epoch 2925, Loss: 0.002420139731839299\n",
      "Epoch 2926, Loss: 0.009789319708943367\n",
      "Epoch 2927, Loss: 2.3898172003100626e-05\n",
      "Epoch 2928, Loss: 0.0037375930696725845\n",
      "Epoch 2929, Loss: 0.03647995740175247\n",
      "Epoch 2930, Loss: 0.0005514554213732481\n",
      "Epoch 2931, Loss: 0.04461493343114853\n",
      "Epoch 2932, Loss: 0.015282375738024712\n",
      "Epoch 2933, Loss: 0.01164722628891468\n",
      "Epoch 2934, Loss: 0.0017627158667892218\n",
      "Epoch 2935, Loss: 0.09349004924297333\n",
      "Epoch 2936, Loss: 0.10566814988851547\n",
      "Epoch 2937, Loss: 0.09581386297941208\n",
      "Epoch 2938, Loss: 0.01201778557151556\n",
      "Epoch 2939, Loss: 0.009842070750892162\n",
      "Epoch 2940, Loss: 0.01446774136275053\n",
      "Epoch 2941, Loss: 0.018892038613557816\n",
      "Epoch 2942, Loss: 0.0021023177541792393\n",
      "Epoch 2943, Loss: 0.029168937355279922\n",
      "Epoch 2944, Loss: 0.08143313229084015\n",
      "Epoch 2945, Loss: 0.00723548699170351\n",
      "Epoch 2946, Loss: 0.030735772103071213\n",
      "Epoch 2947, Loss: 0.032808173447847366\n",
      "Epoch 2948, Loss: 0.018876854330301285\n",
      "Epoch 2949, Loss: 0.24863295257091522\n",
      "Epoch 2950, Loss: 0.006577913649380207\n",
      "Epoch 2951, Loss: 0.004028501454740763\n",
      "Epoch 2952, Loss: 0.004365934524685144\n",
      "Epoch 2953, Loss: 0.03766746073961258\n",
      "Epoch 2954, Loss: 0.022432949393987656\n",
      "Epoch 2955, Loss: 0.01030970923602581\n",
      "Epoch 2956, Loss: 0.03363097459077835\n",
      "Epoch 2957, Loss: 0.0072484202682971954\n",
      "Epoch 2958, Loss: 0.0034882843028753996\n",
      "Epoch 2959, Loss: 0.004456091206520796\n",
      "Epoch 2960, Loss: 0.04308771342039108\n",
      "Epoch 2961, Loss: 0.015500105917453766\n",
      "Epoch 2962, Loss: 0.13308851420879364\n",
      "Epoch 2963, Loss: 0.00124246790073812\n",
      "Epoch 2964, Loss: 0.008456326089799404\n",
      "Epoch 2965, Loss: 0.003261736361309886\n",
      "Epoch 2966, Loss: 0.004225048236548901\n",
      "Epoch 2967, Loss: 0.014506613835692406\n",
      "Epoch 2968, Loss: 0.016251610592007637\n",
      "Epoch 2969, Loss: 0.0052267881110310555\n",
      "Epoch 2970, Loss: 0.09995447099208832\n",
      "Epoch 2971, Loss: 0.2834324836730957\n",
      "Epoch 2972, Loss: 0.345775842666626\n",
      "Epoch 2973, Loss: 0.005695293191820383\n",
      "Epoch 2974, Loss: 0.017358412966132164\n",
      "Epoch 2975, Loss: 0.005291122943162918\n",
      "Epoch 2976, Loss: 0.0007373878033831716\n",
      "Epoch 2977, Loss: 0.09980224072933197\n",
      "Epoch 2978, Loss: 0.014836643822491169\n",
      "Epoch 2979, Loss: 0.011845959350466728\n",
      "Epoch 2980, Loss: 0.013536890968680382\n",
      "Epoch 2981, Loss: 0.011005466803908348\n",
      "Epoch 2982, Loss: 0.024399349465966225\n",
      "Epoch 2983, Loss: 0.006563510745763779\n",
      "Epoch 2984, Loss: 0.012042311951518059\n",
      "Epoch 2985, Loss: 0.010911418125033379\n",
      "Epoch 2986, Loss: 0.004355997778475285\n",
      "Epoch 2987, Loss: 0.001321341609582305\n",
      "Epoch 2988, Loss: 0.2216034233570099\n",
      "Epoch 2989, Loss: 0.001211862196214497\n",
      "Epoch 2990, Loss: 0.10961637645959854\n",
      "Epoch 2991, Loss: 0.10958913713693619\n",
      "Epoch 2992, Loss: 0.004661696497350931\n",
      "Epoch 2993, Loss: 0.27221086621284485\n",
      "Epoch 2994, Loss: 0.06146220117807388\n",
      "Epoch 2995, Loss: 0.013127818703651428\n",
      "Epoch 2996, Loss: 0.002477026544511318\n",
      "Epoch 2997, Loss: 0.0012338102096691728\n",
      "Epoch 2998, Loss: 0.0311686210334301\n",
      "Epoch 2999, Loss: 0.11217603832483292\n",
      "Epoch 3000, Loss: 0.021687325090169907\n",
      "Epoch 3001, Loss: 0.022112250328063965\n",
      "Epoch 3002, Loss: 0.0157869141548872\n",
      "Epoch 3003, Loss: 0.0004072386655025184\n",
      "Epoch 3004, Loss: 0.0013328969944268465\n",
      "Epoch 3005, Loss: 0.0013776056002825499\n",
      "Epoch 3006, Loss: 0.12484587728977203\n",
      "Epoch 3007, Loss: 0.00021420244593173265\n",
      "Epoch 3008, Loss: 0.06297331303358078\n",
      "Epoch 3009, Loss: 0.011879809200763702\n",
      "Epoch 3010, Loss: 0.0005719533655792475\n",
      "Epoch 3011, Loss: 0.001278688432648778\n",
      "Epoch 3012, Loss: 0.024039169773459435\n",
      "Epoch 3013, Loss: 0.011354448273777962\n",
      "Epoch 3014, Loss: 0.012941630557179451\n",
      "Epoch 3015, Loss: 0.01247907243669033\n",
      "Epoch 3016, Loss: 0.0023322796914726496\n",
      "Epoch 3017, Loss: 0.006413660012185574\n",
      "Epoch 3018, Loss: 0.002604567678645253\n",
      "Epoch 3019, Loss: 0.011404488235712051\n",
      "Epoch 3020, Loss: 0.027969229966402054\n",
      "Epoch 3021, Loss: 0.1710284799337387\n",
      "Epoch 3022, Loss: 0.00989880133420229\n",
      "Epoch 3023, Loss: 0.011328192427754402\n",
      "Epoch 3024, Loss: 0.0118728531524539\n",
      "Epoch 3025, Loss: 0.014874893240630627\n",
      "Epoch 3026, Loss: 0.010369449853897095\n",
      "Epoch 3027, Loss: 0.011564805172383785\n",
      "Epoch 3028, Loss: 0.009947994723916054\n",
      "Epoch 3029, Loss: 0.026270512491464615\n",
      "Epoch 3030, Loss: 0.023495594039559364\n",
      "Epoch 3031, Loss: 0.013012414798140526\n",
      "Epoch 3032, Loss: 0.12158755958080292\n",
      "Epoch 3033, Loss: 0.011231753043830395\n",
      "Epoch 3034, Loss: 0.024465147405862808\n",
      "Epoch 3035, Loss: 0.004180486313998699\n",
      "Epoch 3036, Loss: 0.25516074895858765\n",
      "Epoch 3037, Loss: 0.00774444779381156\n",
      "Epoch 3038, Loss: 0.09693687409162521\n",
      "Epoch 3039, Loss: 0.0011971474159508944\n",
      "Epoch 3040, Loss: 0.0139061463996768\n",
      "Epoch 3041, Loss: 0.005613507702946663\n",
      "Epoch 3042, Loss: 0.11276189982891083\n",
      "Epoch 3043, Loss: 0.015347217209637165\n",
      "Epoch 3044, Loss: 0.007145399693399668\n",
      "Epoch 3045, Loss: 0.003398971166461706\n",
      "Epoch 3046, Loss: 0.013460199348628521\n",
      "Epoch 3047, Loss: 0.014936099760234356\n",
      "Epoch 3048, Loss: 0.11677990108728409\n",
      "Epoch 3049, Loss: 0.004681597929447889\n",
      "Epoch 3050, Loss: 0.018254810944199562\n",
      "Epoch 3051, Loss: 0.059527892619371414\n",
      "Epoch 3052, Loss: 0.011451697908341885\n",
      "Epoch 3053, Loss: 0.011455075815320015\n",
      "Epoch 3054, Loss: 0.005378854461014271\n",
      "Epoch 3055, Loss: 0.0026223284658044577\n",
      "Epoch 3056, Loss: 0.012786832638084888\n",
      "Epoch 3057, Loss: 0.10508066415786743\n",
      "Epoch 3058, Loss: 0.0038129198364913464\n",
      "Epoch 3059, Loss: 0.020464809611439705\n",
      "Epoch 3060, Loss: 0.001879396615549922\n",
      "Epoch 3061, Loss: 0.1290174424648285\n",
      "Epoch 3062, Loss: 0.020616544410586357\n",
      "Epoch 3063, Loss: 0.0018412219360470772\n",
      "Epoch 3064, Loss: 0.00022177216305863112\n",
      "Epoch 3065, Loss: 0.011022801510989666\n",
      "Epoch 3066, Loss: 0.015419064089655876\n",
      "Epoch 3067, Loss: 0.038671158254146576\n",
      "Epoch 3068, Loss: 0.10974401235580444\n",
      "Epoch 3069, Loss: 0.0033053315710276365\n",
      "Epoch 3070, Loss: 0.15106351673603058\n",
      "Epoch 3071, Loss: 0.009909451007843018\n",
      "Epoch 3072, Loss: 0.026605483144521713\n",
      "Epoch 3073, Loss: 0.019501810893416405\n",
      "Epoch 3074, Loss: 0.09631403535604477\n",
      "Epoch 3075, Loss: 0.008035954087972641\n",
      "Epoch 3076, Loss: 0.0013164796400815248\n",
      "Epoch 3077, Loss: 0.1295025646686554\n",
      "Epoch 3078, Loss: 0.10888233035802841\n",
      "Epoch 3079, Loss: 0.015215081162750721\n",
      "Epoch 3080, Loss: 0.01211643498390913\n",
      "Epoch 3081, Loss: 0.007550855632871389\n",
      "Epoch 3082, Loss: 0.15303564071655273\n",
      "Epoch 3083, Loss: 0.005687540862709284\n",
      "Epoch 3084, Loss: 0.10798738896846771\n",
      "Epoch 3085, Loss: 0.004812709521502256\n",
      "Epoch 3086, Loss: 0.08310124278068542\n",
      "Epoch 3087, Loss: 0.004971678368747234\n",
      "Epoch 3088, Loss: 0.0015447246842086315\n",
      "Epoch 3089, Loss: 0.015886731445789337\n",
      "Epoch 3090, Loss: 0.0014306855155155063\n",
      "Epoch 3091, Loss: 0.0064517124556005\n",
      "Epoch 3092, Loss: 0.009577495977282524\n",
      "Epoch 3093, Loss: 0.011319276876747608\n",
      "Epoch 3094, Loss: 0.09924963861703873\n",
      "Epoch 3095, Loss: 0.01878141425549984\n",
      "Epoch 3096, Loss: 0.027153348550200462\n",
      "Epoch 3097, Loss: 0.15797652304172516\n",
      "Epoch 3098, Loss: 0.09802214056253433\n",
      "Epoch 3099, Loss: 0.09349094331264496\n",
      "Epoch 3100, Loss: 0.008553569205105305\n",
      "Epoch 3101, Loss: 0.13591471314430237\n",
      "Epoch 3102, Loss: 0.0016720207640901208\n",
      "Epoch 3103, Loss: 0.10454638302326202\n",
      "Epoch 3104, Loss: 0.026839474216103554\n",
      "Epoch 3105, Loss: 0.02633005380630493\n",
      "Epoch 3106, Loss: 0.2923070788383484\n",
      "Epoch 3107, Loss: 0.02275204285979271\n",
      "Epoch 3108, Loss: 0.1900707334280014\n",
      "Epoch 3109, Loss: 0.0037529952824115753\n",
      "Epoch 3110, Loss: 0.009353063069283962\n",
      "Epoch 3111, Loss: 0.009446508251130581\n",
      "Epoch 3112, Loss: 0.011851521208882332\n",
      "Epoch 3113, Loss: 0.006408370099961758\n",
      "Epoch 3114, Loss: 0.008592590689659119\n",
      "Epoch 3115, Loss: 0.00710793724283576\n",
      "Epoch 3116, Loss: 0.05710495635867119\n",
      "Epoch 3117, Loss: 0.0039666020311415195\n",
      "Epoch 3118, Loss: 0.0013947432162240148\n",
      "Epoch 3119, Loss: 0.14532893896102905\n",
      "Epoch 3120, Loss: 0.003740631742402911\n",
      "Epoch 3121, Loss: 0.0017944624414667487\n",
      "Epoch 3122, Loss: 0.018554778769612312\n",
      "Epoch 3123, Loss: 0.0035667461343109608\n",
      "Epoch 3124, Loss: 0.00036649545654654503\n",
      "Epoch 3125, Loss: 0.02009761892259121\n",
      "Epoch 3126, Loss: 0.017602093517780304\n",
      "Epoch 3127, Loss: 0.004132227040827274\n",
      "Epoch 3128, Loss: 0.011638784781098366\n",
      "Epoch 3129, Loss: 0.0024922576267272234\n",
      "Epoch 3130, Loss: 0.06456344574689865\n",
      "Epoch 3131, Loss: 0.014352260157465935\n",
      "Epoch 3132, Loss: 0.15706025063991547\n",
      "Epoch 3133, Loss: 0.026716584339737892\n",
      "Epoch 3134, Loss: 0.012027619406580925\n",
      "Epoch 3135, Loss: 0.003117774846032262\n",
      "Epoch 3136, Loss: 0.0013479867484420538\n",
      "Epoch 3137, Loss: 0.0060869865119457245\n",
      "Epoch 3138, Loss: 0.024944830685853958\n",
      "Epoch 3139, Loss: 0.029847433790564537\n",
      "Epoch 3140, Loss: 0.013746926560997963\n",
      "Epoch 3141, Loss: 0.10963849723339081\n",
      "Epoch 3142, Loss: 0.0029224404133856297\n",
      "Epoch 3143, Loss: 0.00074492342537269\n",
      "Epoch 3144, Loss: 0.013061833567917347\n",
      "Epoch 3145, Loss: 0.011558420956134796\n",
      "Epoch 3146, Loss: 0.0036867368035018444\n",
      "Epoch 3147, Loss: 0.0011249234667047858\n",
      "Epoch 3148, Loss: 0.2623773217201233\n",
      "Epoch 3149, Loss: 0.01834638975560665\n",
      "Epoch 3150, Loss: 0.0023490290623158216\n",
      "Epoch 3151, Loss: 0.01583031564950943\n",
      "Epoch 3152, Loss: 0.014941012486815453\n",
      "Epoch 3153, Loss: 0.002617953810840845\n",
      "Epoch 3154, Loss: 0.006721814163029194\n",
      "Epoch 3155, Loss: 0.09773868322372437\n",
      "Epoch 3156, Loss: 0.016930662095546722\n",
      "Epoch 3157, Loss: 0.17703865468502045\n",
      "Epoch 3158, Loss: 0.014775350689888\n",
      "Epoch 3159, Loss: 0.004797494970262051\n",
      "Epoch 3160, Loss: 0.0033321816008538008\n",
      "Epoch 3161, Loss: 0.0020767590031027794\n",
      "Epoch 3162, Loss: 0.008003557100892067\n",
      "Epoch 3163, Loss: 0.01545523852109909\n",
      "Epoch 3164, Loss: 0.08579720556735992\n",
      "Epoch 3165, Loss: 0.011911268346011639\n",
      "Epoch 3166, Loss: 0.020113933831453323\n",
      "Epoch 3167, Loss: 0.025288734585046768\n",
      "Epoch 3168, Loss: 0.10530854761600494\n",
      "Epoch 3169, Loss: 0.0008392402669414878\n",
      "Epoch 3170, Loss: 0.009567171335220337\n",
      "Epoch 3171, Loss: 0.01804547943174839\n",
      "Epoch 3172, Loss: 0.002225229050964117\n",
      "Epoch 3173, Loss: 0.07326691597700119\n",
      "Epoch 3174, Loss: 0.02944476343691349\n",
      "Epoch 3175, Loss: 0.02625015377998352\n",
      "Epoch 3176, Loss: 0.08935490995645523\n",
      "Epoch 3177, Loss: 0.020673206076025963\n",
      "Epoch 3178, Loss: 0.011508038267493248\n",
      "Epoch 3179, Loss: 0.14981582760810852\n",
      "Epoch 3180, Loss: 0.0002802073140628636\n",
      "Epoch 3181, Loss: 0.007589745335280895\n",
      "Epoch 3182, Loss: 0.0010857877787202597\n",
      "Epoch 3183, Loss: 0.0927664190530777\n",
      "Epoch 3184, Loss: 0.020205611363053322\n",
      "Epoch 3185, Loss: 0.025032926350831985\n",
      "Epoch 3186, Loss: 0.030854400247335434\n",
      "Epoch 3187, Loss: 0.003635275410488248\n",
      "Epoch 3188, Loss: 0.01474996842443943\n",
      "Epoch 3189, Loss: 0.018901359289884567\n",
      "Epoch 3190, Loss: 0.019076388329267502\n",
      "Epoch 3191, Loss: 0.0005449436139315367\n",
      "Epoch 3192, Loss: 0.0011343880323693156\n",
      "Epoch 3193, Loss: 0.001280579250305891\n",
      "Epoch 3194, Loss: 0.0222279354929924\n",
      "Epoch 3195, Loss: 0.08668467402458191\n",
      "Epoch 3196, Loss: 0.04681837186217308\n",
      "Epoch 3197, Loss: 0.02900569513440132\n",
      "Epoch 3198, Loss: 0.033952727913856506\n",
      "Epoch 3199, Loss: 0.00019084566156379879\n",
      "Epoch 3200, Loss: 0.010613331571221352\n",
      "Epoch 3201, Loss: 0.044469673186540604\n",
      "Epoch 3202, Loss: 0.024745535105466843\n",
      "Epoch 3203, Loss: 0.0011753838043659925\n",
      "Epoch 3204, Loss: 0.0993412584066391\n",
      "Epoch 3205, Loss: 0.003915212117135525\n",
      "Epoch 3206, Loss: 0.00011861677921842784\n",
      "Epoch 3207, Loss: 0.012384932488203049\n",
      "Epoch 3208, Loss: 0.010780560784041882\n",
      "Epoch 3209, Loss: 0.24506540596485138\n",
      "Epoch 3210, Loss: 0.01819468103349209\n",
      "Epoch 3211, Loss: 0.16159673035144806\n",
      "Epoch 3212, Loss: 0.007068700157105923\n",
      "Epoch 3213, Loss: 0.0160005372017622\n",
      "Epoch 3214, Loss: 0.018216736614704132\n",
      "Epoch 3215, Loss: 0.05486177280545235\n",
      "Epoch 3216, Loss: 0.012680347077548504\n",
      "Epoch 3217, Loss: 0.001582103781402111\n",
      "Epoch 3218, Loss: 0.027722883969545364\n",
      "Epoch 3219, Loss: 0.019162986427545547\n",
      "Epoch 3220, Loss: 0.004461838863790035\n",
      "Epoch 3221, Loss: 0.0070431469939649105\n",
      "Epoch 3222, Loss: 0.007281044963747263\n",
      "Epoch 3223, Loss: 0.0015884659951552749\n",
      "Epoch 3224, Loss: 0.01086507923901081\n",
      "Epoch 3225, Loss: 0.010610817931592464\n",
      "Epoch 3226, Loss: 0.2136516124010086\n",
      "Epoch 3227, Loss: 0.10550536215305328\n",
      "Epoch 3228, Loss: 0.21726186573505402\n",
      "Epoch 3229, Loss: 0.038657139986753464\n",
      "Epoch 3230, Loss: 0.015152690932154655\n",
      "Epoch 3231, Loss: 0.0021904343739151955\n",
      "Epoch 3232, Loss: 0.00968923605978489\n",
      "Epoch 3233, Loss: 0.012626280076801777\n",
      "Epoch 3234, Loss: 0.01245343778282404\n",
      "Epoch 3235, Loss: 0.09241611510515213\n",
      "Epoch 3236, Loss: 0.011148209683597088\n",
      "Epoch 3237, Loss: 0.007838503457605839\n",
      "Epoch 3238, Loss: 0.0046546277590096\n",
      "Epoch 3239, Loss: 0.0012493834365159273\n",
      "Epoch 3240, Loss: 0.02334839291870594\n",
      "Epoch 3241, Loss: 0.06658194214105606\n",
      "Epoch 3242, Loss: 0.02206902764737606\n",
      "Epoch 3243, Loss: 0.020123714581131935\n",
      "Epoch 3244, Loss: 0.010777057148516178\n",
      "Epoch 3245, Loss: 0.12207744270563126\n",
      "Epoch 3246, Loss: 0.07049809396266937\n",
      "Epoch 3247, Loss: 0.0007330297958105803\n",
      "Epoch 3248, Loss: 0.022865304723381996\n",
      "Epoch 3249, Loss: 0.04949518293142319\n",
      "Epoch 3250, Loss: 0.0015541469911113381\n",
      "Epoch 3251, Loss: 0.013338720425963402\n",
      "Epoch 3252, Loss: 0.16212420165538788\n",
      "Epoch 3253, Loss: 0.07190286368131638\n",
      "Epoch 3254, Loss: 0.11435540020465851\n",
      "Epoch 3255, Loss: 0.10491566359996796\n",
      "Epoch 3256, Loss: 0.13154058158397675\n",
      "Epoch 3257, Loss: 0.11600573360919952\n",
      "Epoch 3258, Loss: 0.0031938571482896805\n",
      "Epoch 3259, Loss: 0.0034039518795907497\n",
      "Epoch 3260, Loss: 0.007059771567583084\n",
      "Epoch 3261, Loss: 0.12358871847391129\n",
      "Epoch 3262, Loss: 0.008912398479878902\n",
      "Epoch 3263, Loss: 0.002373876515775919\n",
      "Epoch 3264, Loss: 0.0020287916995584965\n",
      "Epoch 3265, Loss: 0.03840755298733711\n",
      "Epoch 3266, Loss: 0.11299370229244232\n",
      "Epoch 3267, Loss: 0.03228289261460304\n",
      "Epoch 3268, Loss: 0.002173819113522768\n",
      "Epoch 3269, Loss: 0.024843653663992882\n",
      "Epoch 3270, Loss: 0.011687234975397587\n",
      "Epoch 3271, Loss: 0.09404319524765015\n",
      "Epoch 3272, Loss: 0.004025104455649853\n",
      "Epoch 3273, Loss: 0.028608987107872963\n",
      "Epoch 3274, Loss: 0.010146399028599262\n",
      "Epoch 3275, Loss: 0.020208440721035004\n",
      "Epoch 3276, Loss: 0.03273514285683632\n",
      "Epoch 3277, Loss: 0.01753336563706398\n",
      "Epoch 3278, Loss: 0.01227953378111124\n",
      "Epoch 3279, Loss: 0.009892134927213192\n",
      "Epoch 3280, Loss: 0.0010048389667645097\n",
      "Epoch 3281, Loss: 0.009229904040694237\n",
      "Epoch 3282, Loss: 0.10006622970104218\n",
      "Epoch 3283, Loss: 0.09114015847444534\n",
      "Epoch 3284, Loss: 0.0044407835230231285\n",
      "Epoch 3285, Loss: 0.005963417701423168\n",
      "Epoch 3286, Loss: 0.08816979825496674\n",
      "Epoch 3287, Loss: 0.15349571406841278\n",
      "Epoch 3288, Loss: 0.20159921050071716\n",
      "Epoch 3289, Loss: 0.08364395797252655\n",
      "Epoch 3290, Loss: 0.005696997977793217\n",
      "Epoch 3291, Loss: 0.07173357903957367\n",
      "Epoch 3292, Loss: 0.02012604847550392\n",
      "Epoch 3293, Loss: 0.011239925399422646\n",
      "Epoch 3294, Loss: 0.0002830729354172945\n",
      "Epoch 3295, Loss: 0.06659723818302155\n",
      "Epoch 3296, Loss: 0.10184134542942047\n",
      "Epoch 3297, Loss: 0.005234267562627792\n",
      "Epoch 3298, Loss: 0.0029112468473613262\n",
      "Epoch 3299, Loss: 0.1541057527065277\n",
      "Epoch 3300, Loss: 0.009371594525873661\n",
      "Epoch 3301, Loss: 0.08193428814411163\n",
      "Epoch 3302, Loss: 0.0027463312726467848\n",
      "Epoch 3303, Loss: 0.018426645547151566\n",
      "Epoch 3304, Loss: 0.020263412967324257\n",
      "Epoch 3305, Loss: 0.0013823951594531536\n",
      "Epoch 3306, Loss: 0.03436131030321121\n",
      "Epoch 3307, Loss: 0.0023069076705724\n",
      "Epoch 3308, Loss: 0.007623243145644665\n",
      "Epoch 3309, Loss: 0.01582867093384266\n",
      "Epoch 3310, Loss: 0.006066689267754555\n",
      "Epoch 3311, Loss: 0.01634332165122032\n",
      "Epoch 3312, Loss: 0.008971565403044224\n",
      "Epoch 3313, Loss: 0.004569035954773426\n",
      "Epoch 3314, Loss: 0.0005035873618908226\n",
      "Epoch 3315, Loss: 0.016961893066763878\n",
      "Epoch 3316, Loss: 0.0010774394031614065\n",
      "Epoch 3317, Loss: 0.001129627926275134\n",
      "Epoch 3318, Loss: 0.002704498590901494\n",
      "Epoch 3319, Loss: 0.006566028110682964\n",
      "Epoch 3320, Loss: 0.02861104905605316\n",
      "Epoch 3321, Loss: 0.0014240071177482605\n",
      "Epoch 3322, Loss: 0.025307565927505493\n",
      "Epoch 3323, Loss: 0.009847563691437244\n",
      "Epoch 3324, Loss: 0.1554526686668396\n",
      "Epoch 3325, Loss: 0.02116224355995655\n",
      "Epoch 3326, Loss: 0.01195166539400816\n",
      "Epoch 3327, Loss: 0.01559013593941927\n",
      "Epoch 3328, Loss: 0.01112971268594265\n",
      "Epoch 3329, Loss: 0.002583918161690235\n",
      "Epoch 3330, Loss: 0.0035953994374722242\n",
      "Epoch 3331, Loss: 0.05592012405395508\n",
      "Epoch 3332, Loss: 0.02362213283777237\n",
      "Epoch 3333, Loss: 0.00954667292535305\n",
      "Epoch 3334, Loss: 0.007925024256110191\n",
      "Epoch 3335, Loss: 0.009119702503085136\n",
      "Epoch 3336, Loss: 0.030301138758659363\n",
      "Epoch 3337, Loss: 0.0017805795650929213\n",
      "Epoch 3338, Loss: 0.0037976359017193317\n",
      "Epoch 3339, Loss: 0.050238847732543945\n",
      "Epoch 3340, Loss: 0.018442045897245407\n",
      "Epoch 3341, Loss: 0.012634256854653358\n",
      "Epoch 3342, Loss: 0.015239836648106575\n",
      "Epoch 3343, Loss: 0.08723977953195572\n",
      "Epoch 3344, Loss: 0.0010966856498271227\n",
      "Epoch 3345, Loss: 0.07626180350780487\n",
      "Epoch 3346, Loss: 0.001098170760087669\n",
      "Epoch 3347, Loss: 0.0048049320466816425\n",
      "Epoch 3348, Loss: 0.026496941223740578\n",
      "Epoch 3349, Loss: 0.00823073647916317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 86\u001B[0m\n\u001B[0;32m     84\u001B[0m X_batch, y_batch \u001B[38;5;241m=\u001B[39m X_batch\u001B[38;5;241m.\u001B[39mto(device), y_batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     85\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 86\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(X_batch)\n\u001B[0;32m     87\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, y_batch)\n\u001B[0;32m     88\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[3], line 41\u001B[0m, in \u001B[0;36mEnhancedNN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m     40\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(x))\n\u001B[1;32m---> 41\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout1(x)\n\u001B[0;32m     42\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(x))\n\u001B[0;32m     43\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout2(x)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:58\u001B[0m, in \u001B[0;36mDropout.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m---> 58\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mdropout(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minplace)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\class\\Lib\\site-packages\\torch\\nn\\functional.py:1266\u001B[0m, in \u001B[0;36mdropout\u001B[1;34m(input, p, training, inplace)\u001B[0m\n\u001B[0;32m   1264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m p \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n\u001B[0;32m   1265\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdropout probability has to be between 0 and 1, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1266\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _VF\u001B[38;5;241m.\u001B[39mdropout_(\u001B[38;5;28minput\u001B[39m, p, training) \u001B[38;5;28;01mif\u001B[39;00m inplace \u001B[38;5;28;01melse\u001B[39;00m _VF\u001B[38;5;241m.\u001B[39mdropout(\u001B[38;5;28minput\u001B[39m, p, training)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "# 检查GPU是否可用并设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载数据集\n",
    "df = pd.read_csv('Resources/Data/Encoded_Resampled_HR_Analytics.csv')\n",
    "X = df.drop('Attrition', axis=1).values\n",
    "y = df['Attrition'].values\n",
    "\n",
    "# 数据预处理\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 定义神经网络模型\n",
    "class EnhancedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(34, 64)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 32)\n",
    "        self.fc7 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x\n",
    "\n",
    "# 将模型移动到设备并显示模型摘要\n",
    "model = EnhancedNN().to(device)\n",
    "print(\"Model Summary:\")\n",
    "summary(model, input_size=(1, 34))\n",
    "\n",
    "# 初始化K折交叉验证\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_roc_aucs = []\n",
    "all_train_loss = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # 将数据转换为PyTorch张量并移动到设备\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.LongTensor(y_train).to(device)\n",
    "    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "    y_test_tensor = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32, shuffle=False)\n",
    "\n",
    "    model = EnhancedNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_loss = []\n",
    "    for epoch in range(10000):\n",
    "        for batch in train_loader:\n",
    "            X_batch, y_batch = batch\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "    all_train_loss.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            X_batch, y_batch = batch\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            y_true.extend(y_batch.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_f1s.append(f1)\n",
    "    fold_roc_aucs.append(roc_auc)\n",
    "\n",
    "print(f\"Average Accuracy: {np.mean(fold_accuracies)}, Average F1 Score: {np.mean(fold_f1s)}, Average ROC AUC: {np.mean(fold_roc_aucs)}\")\n",
    "\n",
    "for i, train_loss in enumerate(all_train_loss):\n",
    "    plt.plot(train_loss, label=f\"Fold {i+1}\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss for Each Fold')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T07:22:49.584126Z",
     "start_time": "2023-11-01T06:44:15.254616200Z"
    }
   },
   "id": "4420f2e1352d63bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
